{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W08_RNN1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IOWH50jwPmJP",
        "nRQzZYC8h2-2",
        "AZarlInYiQIH",
        "_vlMHDxmh3eg",
        "cjWmzM1HPAEh",
        "BcqCckcEh31X",
        "GIjoeDI7Wi-i",
        "IDUAQkA6h4Fj",
        "UOj9savt91Y0",
        "XutHJeZ1MKzT",
        "pHaCl0ERPKy8",
        "XXJyaEuuR2vl",
        "nWWVMWHjS7pE"
      ],
      "toc_visible": true,
      "background_execution": "on",
      "mount_file_id": "1XsuxnIvvuwoYF-ZZfKNcEkF_9L-WB41-",
      "authorship_tag": "ABX9TyOELJuvs1WuC82pndrNTdjq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taitip-supha/DeepLearn-Keras/blob/main/03_Sequence/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Prepar the Enviroment"
      ],
      "metadata": {
        "id": "IOWH50jwPmJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all NVIDIA GPUs as avaiable in this computer (or colub's session)\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D06BOUquRcO3",
        "outputId": "807b321f-1e44-4b9e-fe32-231dcd9ee24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-6acfbb78-cd9c-7879-e3c2-b269d971277c)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import package\n",
        "import sys,os,time,datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "eVJEQaCmWoS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "print(f\"Python {sys.version}\")\n",
        "print(f\"NumPy {np.__version__}\")\n",
        "print(f\"tf.keras.backend.image_data_format() = {tf.keras.backend.image_data_format()}\")\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f\"Tensorflow detected : {len(gpus)} GPU(s)\")\n",
        "for i,gpu in enumerate(gpus):\n",
        "  print(f\" GPU No. {i} : Name = {gpu.name} , Type = {gpu.device_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhlSpBLWX-QG",
        "outputId": "e7204910-2572-4c81-b87c-ad0d91f57101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0]\n",
            "NumPy 1.21.5\n",
            "tf.keras.backend.image_data_format() = channels_last\n",
            "Tensorflow detected : 1 GPU(s)\n",
            " GPU No. 0 : Name = /physical_device:GPU:0 , Type = GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set fixed seeding values for reproducability during experiments\n",
        "#to guarantee reproducability, make sure valuesfor any randomize poperation are all set\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(5678)"
      ],
      "metadata": {
        "id": "co7T4MtgjBcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex1 Guess the next number (Simple RNN)\n",
        "we use RNN to predict number of sequence of x_n = x_n-1 +2"
      ],
      "metadata": {
        "id": "nRQzZYC8h2-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1) Create the simple 1-layer RNN model"
      ],
      "metadata": {
        "id": "AZarlInYiQIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_rnn = tf.keras.models.Sequential()\n",
        "\n",
        "#batch_size=None, time_steps=None, input_dim=1\n",
        "#output from this layer is (batch_size,units) which equals to (batch_size,20)\n",
        "my_rnn.add(tf.keras.layers.SimpleRNN(units=20, input_shape=(None,1)))\n",
        "\n",
        "# Use the default 'linear activation'\n",
        "my_rnn.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "my_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJxJTizojnDo",
        "outputId": "4d974aa9-a83d-465b-b96c-f5fd4ae01b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 20)                440       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2) Create Train/val/test set using TimeseriesGenerator"
      ],
      "metadata": {
        "id": "f5KM_dZ-iZa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_data = 200 #Number of genarate data\n",
        "\n",
        "#TimeseriesGenerator\n",
        "sampling_rate = 2     #for 2 consecutive numbers, sample only one\n",
        "n_input_timesteps = 5 #How many timestep for the input sequence\n",
        "\n",
        "dataset = np.array([ i for i in range(n_data*-sampling_rate, n_data*sampling_rate)])\n",
        "\n",
        "gen_dataset = tf.keras.preprocessing.sequence.TimeseriesGenerator( dataset, dataset, length=sampling_rate*n_input_timesteps, batch_size=n_data, sampling_rate=sampling_rate)\n",
        "\n",
        "x, y = gen_dataset[0]"
      ],
      "metadata": {
        "id": "kV3cIKB2k9vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview the first five rows and the last five rows\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4TkmkJ3k94A",
        "outputId": "b4dac656-b44d-48a9-b875-2dc8222954c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(200, 5), y-shape:(200,)\n",
            "0 : [-400 -398 -396 -394 -392] , -390\n",
            "1 : [-399 -397 -395 -393 -391] , -389\n",
            "2 : [-398 -396 -394 -392 -390] , -388\n",
            "3 : [-397 -395 -393 -391 -389] , -387\n",
            "4 : [-396 -394 -392 -390 -388] , -386\n",
            "-1 : [-201 -199 -197 -195 -193] , -191\n",
            "-2 : [-202 -200 -198 -196 -194] , -192\n",
            "-3 : [-203 -201 -199 -197 -195] , -193\n",
            "-4 : [-204 -202 -200 -198 -196] , -194\n",
            "-5 : [-205 -203 -201 -199 -197] , -195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data (before splitting it in to train/val/test sets later inthe next cell)\n",
        "\n",
        "#Shuffle the data\n",
        "seed=1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(x)\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(y)\n",
        "\n",
        "# Preview the first five rows of data\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v2keczepAjC",
        "outputId": "69652a7f-cb8c-46ac-ab62-05cabfb22dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(200, 5), y-shape:(200,)\n",
            "0 : [-371 -369 -367 -365 -363] , -361\n",
            "1 : [-283 -281 -279 -277 -275] , -273\n",
            "2 : [-331 -329 -327 -325 -323] , -321\n",
            "3 : [-226 -224 -222 -220 -218] , -216\n",
            "4 : [-303 -301 -299 -297 -295] , -293\n",
            "-1 : [-249 -247 -245 -243 -241] , -239\n",
            "-2 : [-211 -209 -207 -205 -203] , -201\n",
            "-3 : [-308 -306 -304 -302 -300] , -298\n",
            "-4 : [-233 -231 -229 -227 -225] , -223\n",
            "-5 : [-204 -202 -200 -198 -196] , -194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = int(n_data * 0.8)       # Split 80% to train set\n",
        "n_test = int(n_data * 0.1)        # Split 10% to test set\n",
        "n_val = n_data -n_train -n_test   # 10% to validate set\n",
        "\n",
        "x_train, y_train = x[:n_train] , y[:n_train] \n",
        "x_val, y_val = x[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "x_test, y_test = x[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"x_train-shape:{x_train.shape}, y_train-shape:{y_train.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train[i]} , {y_train[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"x_val-shape:{x_val.shape}, y_val-shape:{y_val.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val[i]} , {y_val[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"x_test-shape:{x_test.shape}, y_test-shape:{y_test.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test[i]} , {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMMLw64xp_Zz",
        "outputId": "d6e9fba4-79d6-4f98-ef88-b40e59b97297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "x_train-shape:(160, 5), y_train-shape:(160,)\n",
            "0 : [-371 -369 -367 -365 -363] , -361\n",
            "1 : [-283 -281 -279 -277 -275] , -273\n",
            "2 : [-331 -329 -327 -325 -323] , -321\n",
            "3 : [-226 -224 -222 -220 -218] , -216\n",
            "4 : [-303 -301 -299 -297 -295] , -293\n",
            "\n",
            "===== Validation data =====\n",
            "x_val-shape:(20, 5), y_val-shape:(20,)\n",
            "0 : [-324 -322 -320 -318 -316] , -314\n",
            "1 : [-263 -261 -259 -257 -255] , -253\n",
            "2 : [-230 -228 -226 -224 -222] , -220\n",
            "3 : [-278 -276 -274 -272 -270] , -268\n",
            "4 : [-329 -327 -325 -323 -321] , -319\n",
            "\n",
            "===== Test data =====\n",
            "x_test-shape:(20, 5), y_test-shape:(20,)\n",
            "0 : [-394 -392 -390 -388 -386] , -384\n",
            "1 : [-307 -305 -303 -301 -299] , -297\n",
            "2 : [-373 -371 -369 -367 -365] , -363\n",
            "3 : [-271 -269 -267 -265 -263] , -261\n",
            "4 : [-248 -246 -244 -242 -240] , -238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max scaling to normalize the data to range [0, 1]\n",
        "#.fit_transfrom expects 2D input\n",
        "minmax_norm = MinMaxScaler().fit(x_train.reshape(-1,1))\n",
        "print(f\"Dataset min-max: {minmax_norm.data_min_}, {minmax_norm.data_max_}\")\n",
        "\n",
        "x_train_norm = minmax_norm.transform( x_train.reshape(-1,1)).reshape(-1,5)\n",
        "y_train_norm = minmax_norm.transform( y_train.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "x_val_norm = minmax_norm.transform( x_val.reshape(-1,1)).reshape(-1,5)\n",
        "y_val_norm = minmax_norm.transform( y_val.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "x_test_norm = minmax_norm.transform( x_test.reshape(-1,1)).reshape(-1,5)\n",
        "y_test_norm = minmax_norm.transform( y_test.reshape(-1,1)).reshape(-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRWIFMGytPHb",
        "outputId": "b8ff60ae-e12e-48f7-91aa-4e0d7fb1af85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset min-max: [-400.], [-193.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into (batch_size, time_step, input_dim) as required by the SimpleRNN layer\n",
        "print(\"\\n===== Train data after normalization =====\")\n",
        "print(f\"x_train_norm:{x_train_norm.shape}, y_train_norm:{y_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train_norm[i]} , {y_train_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data after normalization =====\")\n",
        "print(f\"x_val_norm:{x_val_norm.shape}, y_val_norm:{y_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val_norm[i]} , {y_val_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data after normalization =====\")\n",
        "print(f\"x_test_norm:{x_test_norm.shape}, y_test_norm:{y_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test_norm[i]} , {y_test_norm[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj9023bxtWcR",
        "outputId": "e3a508ea-359d-4813-d7e3-9ff29775135c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data after normalization =====\n",
            "x_train_norm:(160, 5), y_train_norm:(160,)\n",
            "0 : [0.14009662 0.14975845 0.15942029 0.16908213 0.17874396] , 0.18840579710144922\n",
            "1 : [0.56521739 0.57487923 0.58454106 0.5942029  0.60386473] , 0.6135265700483092\n",
            "2 : [0.33333333 0.34299517 0.352657   0.36231884 0.37198068] , 0.3816425120772946\n",
            "3 : [0.84057971 0.85024155 0.85990338 0.86956522 0.87922705] , 0.8888888888888888\n",
            "4 : [0.46859903 0.47826087 0.48792271 0.49758454 0.50724638] , 0.5169082125603865\n",
            "\n",
            "===== Validation data after normalization =====\n",
            "x_val_norm:(20, 5), y_val_norm:(20,)\n",
            "0 : [0.36714976 0.37681159 0.38647343 0.39613527 0.4057971 ] , 0.4154589371980677\n",
            "1 : [0.66183575 0.67149758 0.68115942 0.69082126 0.70048309] , 0.7101449275362319\n",
            "2 : [0.82125604 0.83091787 0.84057971 0.85024155 0.85990338] , 0.8695652173913042\n",
            "3 : [0.58937198 0.59903382 0.60869565 0.61835749 0.62801932] , 0.6376811594202898\n",
            "4 : [0.34299517 0.352657   0.36231884 0.37198068 0.38164251] , 0.3913043478260869\n",
            "\n",
            "===== Test data after normalization =====\n",
            "x_test_norm:(20, 5), y_test_norm:(20,)\n",
            "0 : [0.02898551 0.03864734 0.04830918 0.05797101 0.06763285] , 0.07729468599033829\n",
            "1 : [0.44927536 0.4589372  0.46859903 0.47826087 0.48792271] , 0.4975845410628019\n",
            "2 : [0.13043478 0.14009662 0.14975845 0.15942029 0.16908213] , 0.1787439613526569\n",
            "3 : [0.62318841 0.63285024 0.64251208 0.65217391 0.66183575] , 0.6714975845410627\n",
            "4 : [0.73429952 0.74396135 0.75362319 0.76328502 0.77294686] , 0.7826086956521738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the third dimension of input_dim=1\n",
        "x_train_norm  = x_train_norm[..., np.newaxis]\n",
        "x_val_norm    = x_val_norm[..., np.newaxis]\n",
        "x_test_norm   = x_test_norm[..., np.newaxis]\n",
        "\n",
        "print(\"\\nDimension after changed:\")\n",
        "print(f\"x_train_norm : {x_train_norm.shape}\")\n",
        "print(f\"x_val_norm : {x_val_norm.shape}\")\n",
        "print(f\"x_test_norm : {x_test_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGGjNDY6yjyM",
        "outputId": "c95537f1-cc0e-4bf7-a8fe-3153f1954004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension after changed:\n",
            "x_train_norm : (160, 5, 1)\n",
            "x_val_norm : (20, 5, 1)\n",
            "x_test_norm : (20, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Covert everything  to the defalt of float32\n",
        "\n",
        "x_train_norm = x_train_norm.astype(np.float32)\n",
        "y_train_norm = y_train_norm.astype(np.float32)\n",
        "x_val_norm = x_val_norm.astype(np.float32)\n",
        "y_val_norm = y_val_norm.astype(np.float32)\n",
        "x_test_norm = x_test_norm.astype(np.float32)\n",
        "y_test_norm = y_test_norm.astype(np.float32)"
      ],
      "metadata": {
        "id": "0jWQi7WH08sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3) Compile and Train the model"
      ],
      "metadata": {
        "id": "sIDxMRcJit24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# For regression, the loss can be used as the evaluation metric as well\n",
        "my_rnn.compile(loss='mse', optimizer=adam, metrics=[])\n",
        "\n",
        "checkpoint_filepath = \"RNN_ex1_bestmodel_epoch{epoch:03d}.hdf5\"\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)"
      ],
      "metadata": {
        "id": "R8dRTwd51rGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = my_rnn.fit(x_train_norm, y_train_norm,\n",
        "                  validation_data=(x_val_norm, y_val_norm),\n",
        "                  batch_size=64, epochs=300,\n",
        "                  callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kVDDhY11rKD",
        "outputId": "e8aa0eed-2328-46b8-ce90-6f9fe9f27d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 3s 126ms/step - loss: 0.9185 - val_loss: 0.6980\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.6467 - val_loss: 0.4703\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4360 - val_loss: 0.2980\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2759 - val_loss: 0.1753\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1648 - val_loss: 0.0950\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0916 - val_loss: 0.0505\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0509 - val_loss: 0.0332\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0361 - val_loss: 0.0332\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0402\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0395 - val_loss: 0.0461\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0424 - val_loss: 0.0466\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0409 - val_loss: 0.0421\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - val_loss: 0.0348\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0294 - val_loss: 0.0277\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0235 - val_loss: 0.0224\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0197 - val_loss: 0.0190\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0178 - val_loss: 0.0171\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0167 - val_loss: 0.0160\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0161 - val_loss: 0.0153\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0154 - val_loss: 0.0144\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0143 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0132 - val_loss: 0.0126\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0120 - val_loss: 0.0118\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0109 - val_loss: 0.0112\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0107\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0092 - val_loss: 0.0103\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0087 - val_loss: 0.0099\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0081 - val_loss: 0.0095\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0076 - val_loss: 0.0090\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0071 - val_loss: 0.0085\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0080\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0063 - val_loss: 0.0075\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0070\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0067\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0064\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0053 - val_loss: 0.0061\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0051 - val_loss: 0.0059\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0049 - val_loss: 0.0058\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0056\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0055\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0046 - val_loss: 0.0054\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0053\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0044 - val_loss: 0.0051\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0044 - val_loss: 0.0050\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0043 - val_loss: 0.0050\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0042 - val_loss: 0.0049\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0042 - val_loss: 0.0047\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0041 - val_loss: 0.0046\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0041 - val_loss: 0.0046\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0041 - val_loss: 0.0045\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0040 - val_loss: 0.0044\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0037 - val_loss: 0.0041\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0032 - val_loss: 0.0035\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 0.0033\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0030 - val_loss: 0.0033\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0030 - val_loss: 0.0033\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0028 - val_loss: 0.0031\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0028 - val_loss: 0.0031\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0031\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0010 - val_loss: 0.0012\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 9.9778e-04 - val_loss: 0.0011\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 9.8970e-04 - val_loss: 0.0011\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 9.8133e-04 - val_loss: 0.0011\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 9.7394e-04 - val_loss: 0.0011\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 9.6887e-04 - val_loss: 0.0011\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 9.5864e-04 - val_loss: 0.0011\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 9.5111e-04 - val_loss: 0.0011\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 9.4528e-04 - val_loss: 0.0011\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 9.3647e-04 - val_loss: 0.0011\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.2897e-04 - val_loss: 0.0010\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 9.2316e-04 - val_loss: 0.0010\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 9.1873e-04 - val_loss: 0.0010\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 9.1064e-04 - val_loss: 0.0010\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 8.9973e-04 - val_loss: 0.0010\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 8.9212e-04 - val_loss: 0.0010\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 8.8710e-04 - val_loss: 0.0010\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.8217e-04 - val_loss: 0.0010\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 8.7554e-04 - val_loss: 9.8265e-04\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 8.6558e-04 - val_loss: 9.7323e-04\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 8.5917e-04 - val_loss: 9.6046e-04\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.5254e-04 - val_loss: 9.5264e-04\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 8.4817e-04 - val_loss: 9.4436e-04\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.4042e-04 - val_loss: 9.2771e-04\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 8.3234e-04 - val_loss: 9.2890e-04\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 8.2815e-04 - val_loss: 9.3791e-04\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 8.2000e-04 - val_loss: 9.2821e-04\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.1416e-04 - val_loss: 9.2094e-04\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.0674e-04 - val_loss: 9.1813e-04\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 8.0125e-04 - val_loss: 9.1219e-04\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 8.0070e-04 - val_loss: 9.0381e-04\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 7.9635e-04 - val_loss: 9.2131e-04\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.8663e-04 - val_loss: 8.9390e-04\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 7.7509e-04 - val_loss: 8.6116e-04\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 7.7277e-04 - val_loss: 8.3481e-04\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 7.7477e-04 - val_loss: 8.3269e-04\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 7.7201e-04 - val_loss: 8.4754e-04\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 7.5189e-04 - val_loss: 8.5440e-04\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 7.4787e-04 - val_loss: 8.6061e-04\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 7.4542e-04 - val_loss: 8.5084e-04\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 7.3950e-04 - val_loss: 8.4781e-04\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 7.3280e-04 - val_loss: 8.2207e-04\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 7.2416e-04 - val_loss: 8.0154e-04\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 7.3394e-04 - val_loss: 7.8430e-04\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 7.1622e-04 - val_loss: 7.9617e-04\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 7.1040e-04 - val_loss: 8.1974e-04\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 7.1303e-04 - val_loss: 8.2610e-04\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 7.0208e-04 - val_loss: 7.9399e-04\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 7.0082e-04 - val_loss: 7.5798e-04\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 6.9674e-04 - val_loss: 7.5250e-04\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 6.8899e-04 - val_loss: 7.5980e-04\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 6.8054e-04 - val_loss: 7.7430e-04\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 6.7443e-04 - val_loss: 7.6811e-04\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 6.6758e-04 - val_loss: 7.4892e-04\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 6.6244e-04 - val_loss: 7.3482e-04\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 6.6386e-04 - val_loss: 7.2612e-04\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 6.5532e-04 - val_loss: 7.4328e-04\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 6.5000e-04 - val_loss: 7.5091e-04\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 6.4602e-04 - val_loss: 7.4075e-04\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 6.4027e-04 - val_loss: 7.2481e-04\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 6.3832e-04 - val_loss: 7.1004e-04\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 6.2877e-04 - val_loss: 7.1089e-04\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 6.2641e-04 - val_loss: 7.1314e-04\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 6.2146e-04 - val_loss: 7.0193e-04\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 6.1562e-04 - val_loss: 6.8108e-04\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 6.1863e-04 - val_loss: 6.6447e-04\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 6.1192e-04 - val_loss: 6.6834e-04\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 6.0564e-04 - val_loss: 6.7905e-04\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.9811e-04 - val_loss: 6.7900e-04\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 5.9492e-04 - val_loss: 6.7133e-04\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 5.8968e-04 - val_loss: 6.5525e-04\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 5.8753e-04 - val_loss: 6.5158e-04\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.8069e-04 - val_loss: 6.4172e-04\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.7983e-04 - val_loss: 6.4191e-04\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 5.7355e-04 - val_loss: 6.3532e-04\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.6991e-04 - val_loss: 6.3675e-04\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.6443e-04 - val_loss: 6.5571e-04\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 5.6422e-04 - val_loss: 6.5295e-04\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 5.5685e-04 - val_loss: 6.2739e-04\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 5.5369e-04 - val_loss: 6.1026e-04\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 5.5252e-04 - val_loss: 6.0730e-04\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.4152e-04 - val_loss: 6.2149e-04\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.4032e-04 - val_loss: 6.3683e-04\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.4224e-04 - val_loss: 6.2243e-04\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 5.3200e-04 - val_loss: 5.9129e-04\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 5.2933e-04 - val_loss: 5.7270e-04\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 5.3256e-04 - val_loss: 5.7152e-04\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.2257e-04 - val_loss: 5.8550e-04\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.1847e-04 - val_loss: 6.0354e-04\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.1721e-04 - val_loss: 5.9238e-04\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 5.1203e-04 - val_loss: 5.7751e-04\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 5.0543e-04 - val_loss: 5.6778e-04\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 5.0134e-04 - val_loss: 5.5938e-04\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 5.0242e-04 - val_loss: 5.4877e-04\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.9394e-04 - val_loss: 5.5922e-04\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 4.9187e-04 - val_loss: 5.6724e-04\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 4.8850e-04 - val_loss: 5.5111e-04\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.8160e-04 - val_loss: 5.3273e-04\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.8299e-04 - val_loss: 5.2442e-04\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.8012e-04 - val_loss: 5.3031e-04\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4.7343e-04 - val_loss: 5.4611e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rfn1vpTR1rNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4) Evaluate the model"
      ],
      "metadata": {
        "id": "uMKbLoTIizkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the best epoch (minimum val_loss)\n",
        "bestmodel_file = max([ f for f in os.listdir(\".\") if f.startswith('RNN_ex1_bestmodel_') and f.endswith(\".hdf5\")])\n",
        "print( f\"The best model : {bestmodel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzBF-gS1pBL",
        "outputId": "5b20983a-f36f-4dbb-902e-c7c58c61d49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model : RNN_ex1_bestmodel_epoch298.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_rnn_best = tf.keras.models.load_model(bestmodel_file, compile=True)"
      ],
      "metadata": {
        "id": "IdjYUdoV1pcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from last epoch\n",
        "score = my_rnn.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the last epoch) :{[(my_rnn.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the last epoch) :{[(my_rnn.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6Cg_GI1pjg",
        "outputId": "7ace2e14-5c73-49ae-8a4e-5c99f4d07adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 0.0007443480426445603)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from best epoch\n",
        "score = my_rnn_best.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the last epoch) :{[(my_rnn_best.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the last epoch) :{[(my_rnn_best.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WlJJp_i71ab",
        "outputId": "bec94c21-008f-422e-e5c3-e96b2e309f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 0.0007851850241422653)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5) Inference"
      ],
      "metadata": {
        "id": "o7_2kXsIi5Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_predict = my_rnn.predict(x_test_norm)\n",
        "y2_test_predict = my_rnn_best.predict(x_test_norm)\n",
        "\n",
        "# Denormalize to raw value\n",
        "y1_inv = minmax_norm.inverse_transform(y1_test_predict)\n",
        "y2_inv = minmax_norm.inverse_transform(y2_test_predict)"
      ],
      "metadata": {
        "id": "Po2QsRI28BQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(f\"x_test[{i}] = {x_test[i].reshape(1,-1)}, y_test[{i}] = {y_test[i]}, predict--> last_epoch({np.around(y1_inv[i])}) best_epoch({np.around(y2_inv[i])})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeU5rt728BWM",
        "outputId": "d78833ed-02ba-4e1b-ac21-b06c5b035fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test[0] = [[-394 -392 -390 -388 -386]], y_test[0] = -384, predict--> last_epoch([-390.]) best_epoch([-390.])\n",
            "x_test[1] = [[-307 -305 -303 -301 -299]], y_test[1] = -297, predict--> last_epoch([-292.]) best_epoch([-292.])\n",
            "x_test[2] = [[-373 -371 -369 -367 -365]], y_test[2] = -363, predict--> last_epoch([-365.]) best_epoch([-366.])\n",
            "x_test[3] = [[-271 -269 -267 -265 -263]], y_test[3] = -261, predict--> last_epoch([-257.]) best_epoch([-258.])\n",
            "x_test[4] = [[-248 -246 -244 -242 -240]], y_test[4] = -238, predict--> last_epoch([-237.]) best_epoch([-238.])\n",
            "x_test[5] = [[-377 -375 -373 -371 -369]], y_test[5] = -367, predict--> last_epoch([-370.]) best_epoch([-370.])\n",
            "x_test[6] = [[-206 -204 -202 -200 -198]], y_test[6] = -196, predict--> last_epoch([-207.]) best_epoch([-207.])\n",
            "x_test[7] = [[-218 -216 -214 -212 -210]], y_test[7] = -208, predict--> last_epoch([-215.]) best_epoch([-215.])\n",
            "x_test[8] = [[-266 -264 -262 -260 -258]], y_test[8] = -256, predict--> last_epoch([-252.]) best_epoch([-253.])\n",
            "x_test[9] = [[-391 -389 -387 -385 -383]], y_test[9] = -381, predict--> last_epoch([-386.]) best_epoch([-387.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex2 Guess the next number(Stacked RNN)"
      ],
      "metadata": {
        "id": "_vlMHDxmh3eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Create the deep RNN model"
      ],
      "metadata": {
        "id": "a0FfRqzBOsDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex2_rnn = tf.keras.models.Sequential()\n",
        "\n",
        "# batch_size=None, time_steps=None, input_dim=1\n",
        "ex2_rnn.add( tf.keras.layers.SimpleRNN(units=20, input_shape=(None,1), return_sequences=True) ) # RNN Layer 1st\n",
        "ex2_rnn.add( tf.keras.layers.SimpleRNN(units=20, return_sequences=True) ) #RNN Layer 2nd\n",
        "ex2_rnn.add( tf.keras.layers.SimpleRNN(units=10) ) #RNN layer 3\n",
        "\n",
        "#Use the defult 'linear activation'\n",
        "ex2_rnn.add( tf.keras.layers.Dense(1))\n",
        "\n",
        "ex2_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl8CI95DOlAf",
        "outputId": "96f5e973-f9d3-41a1-8ffc-b56164a35c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, None, 20)          440       \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, None, 20)          820       \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 10)                310       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,581\n",
            "Trainable params: 1,581\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Create Train/val/test set using TimeseriesGenerator"
      ],
      "metadata": {
        "id": "dWLGK3GIO53m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_data = 200 #Number of genarate data\n",
        "\n",
        "#TimeseriesGenerator\n",
        "sampling_rate = 2     #for 2 consecutive numbers, sample only one\n",
        "n_input_timesteps = 5 #How many timestep for the input sequence\n",
        "\n",
        "dataset = np.array([ i for i in range(n_data*-sampling_rate, n_data*sampling_rate)])\n",
        "\n",
        "gen_dataset = tf.keras.preprocessing.sequence.TimeseriesGenerator( dataset, dataset, length=sampling_rate*n_input_timesteps, batch_size=n_data, sampling_rate=sampling_rate)\n",
        "\n",
        "x, y = gen_dataset[0]"
      ],
      "metadata": {
        "id": "iydiCUbNO53m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview the first five rows and the last five rows\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5253d98-7cec-441a-86f6-520a2e2f0c12",
        "id": "6-bfpyqZO53n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(200, 5), y-shape:(200,)\n",
            "0 : [-400 -398 -396 -394 -392] , -390\n",
            "1 : [-399 -397 -395 -393 -391] , -389\n",
            "2 : [-398 -396 -394 -392 -390] , -388\n",
            "3 : [-397 -395 -393 -391 -389] , -387\n",
            "4 : [-396 -394 -392 -390 -388] , -386\n",
            "-1 : [-201 -199 -197 -195 -193] , -191\n",
            "-2 : [-202 -200 -198 -196 -194] , -192\n",
            "-3 : [-203 -201 -199 -197 -195] , -193\n",
            "-4 : [-204 -202 -200 -198 -196] , -194\n",
            "-5 : [-205 -203 -201 -199 -197] , -195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data (before splitting it in to train/val/test sets later inthe next cell)\n",
        "\n",
        "#Shuffle the data\n",
        "seed=1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(x)\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(y)\n",
        "\n",
        "# Preview the first five rows of data\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2c4c4c-07bc-48a5-a309-337226cee7a7",
        "id": "AOjL2uL2O53n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(200, 5), y-shape:(200,)\n",
            "0 : [-371 -369 -367 -365 -363] , -361\n",
            "1 : [-283 -281 -279 -277 -275] , -273\n",
            "2 : [-331 -329 -327 -325 -323] , -321\n",
            "3 : [-226 -224 -222 -220 -218] , -216\n",
            "4 : [-303 -301 -299 -297 -295] , -293\n",
            "-1 : [-249 -247 -245 -243 -241] , -239\n",
            "-2 : [-211 -209 -207 -205 -203] , -201\n",
            "-3 : [-308 -306 -304 -302 -300] , -298\n",
            "-4 : [-233 -231 -229 -227 -225] , -223\n",
            "-5 : [-204 -202 -200 -198 -196] , -194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = int(n_data * 0.8)       # Split 80% to train set\n",
        "n_test = int(n_data * 0.1)        # Split 10% to test set\n",
        "n_val = n_data -n_train -n_test   # 10% to validate set\n",
        "\n",
        "x_train, y_train = x[:n_train] , y[:n_train] \n",
        "x_val, y_val = x[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "x_test, y_test = x[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"x_train-shape:{x_train.shape}, y_train-shape:{y_train.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train[i]} , {y_train[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"x_val-shape:{x_val.shape}, y_val-shape:{y_val.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val[i]} , {y_val[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"x_test-shape:{x_test.shape}, y_test-shape:{y_test.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test[i]} , {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd46dde-22f9-4ffd-c78e-dec9d450c8b0",
        "id": "en7K3urRO53n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "x_train-shape:(160, 5), y_train-shape:(160,)\n",
            "0 : [-371 -369 -367 -365 -363] , -361\n",
            "1 : [-283 -281 -279 -277 -275] , -273\n",
            "2 : [-331 -329 -327 -325 -323] , -321\n",
            "3 : [-226 -224 -222 -220 -218] , -216\n",
            "4 : [-303 -301 -299 -297 -295] , -293\n",
            "\n",
            "===== Validation data =====\n",
            "x_val-shape:(20, 5), y_val-shape:(20,)\n",
            "0 : [-324 -322 -320 -318 -316] , -314\n",
            "1 : [-263 -261 -259 -257 -255] , -253\n",
            "2 : [-230 -228 -226 -224 -222] , -220\n",
            "3 : [-278 -276 -274 -272 -270] , -268\n",
            "4 : [-329 -327 -325 -323 -321] , -319\n",
            "\n",
            "===== Test data =====\n",
            "x_test-shape:(20, 5), y_test-shape:(20,)\n",
            "0 : [-394 -392 -390 -388 -386] , -384\n",
            "1 : [-307 -305 -303 -301 -299] , -297\n",
            "2 : [-373 -371 -369 -367 -365] , -363\n",
            "3 : [-271 -269 -267 -265 -263] , -261\n",
            "4 : [-248 -246 -244 -242 -240] , -238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max scaling to normalize the data to range [0, 1]\n",
        "#.fit_transfrom expects 2D input\n",
        "minmax_norm = MinMaxScaler().fit(x_train.reshape(-1,1))\n",
        "print(f\"Dataset min-max: {minmax_norm.data_min_}, {minmax_norm.data_max_}\")\n",
        "\n",
        "x_train_norm = minmax_norm.transform( x_train.reshape(-1,1)).reshape(-1,5)\n",
        "y_train_norm = minmax_norm.transform( y_train.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "x_val_norm = minmax_norm.transform( x_val.reshape(-1,1)).reshape(-1,5)\n",
        "y_val_norm = minmax_norm.transform( y_val.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "x_test_norm = minmax_norm.transform( x_test.reshape(-1,1)).reshape(-1,5)\n",
        "y_test_norm = minmax_norm.transform( y_test.reshape(-1,1)).reshape(-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742d3ed4-fb36-4b4d-c868-938e92856b60",
        "id": "kFbIo1weO53n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset min-max: [-400.], [-193.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into (batch_size, time_step, input_dim) as required by the SimpleRNN layer\n",
        "print(\"\\n===== Train data after normalization =====\")\n",
        "print(f\"x_train_norm:{x_train_norm.shape}, y_train_norm:{y_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train_norm[i]} , {y_train_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data after normalization =====\")\n",
        "print(f\"x_val_norm:{x_val_norm.shape}, y_val_norm:{y_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val_norm[i]} , {y_val_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data after normalization =====\")\n",
        "print(f\"x_test_norm:{x_test_norm.shape}, y_test_norm:{y_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test_norm[i]} , {y_test_norm[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42d2447-dcaf-46d9-ec9a-885961dfc84b",
        "id": "ymV3p3yxO53n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data after normalization =====\n",
            "x_train_norm:(160, 5), y_train_norm:(160,)\n",
            "0 : [0.14009662 0.14975845 0.15942029 0.16908213 0.17874396] , 0.18840579710144922\n",
            "1 : [0.56521739 0.57487923 0.58454106 0.5942029  0.60386473] , 0.6135265700483092\n",
            "2 : [0.33333333 0.34299517 0.352657   0.36231884 0.37198068] , 0.3816425120772946\n",
            "3 : [0.84057971 0.85024155 0.85990338 0.86956522 0.87922705] , 0.8888888888888888\n",
            "4 : [0.46859903 0.47826087 0.48792271 0.49758454 0.50724638] , 0.5169082125603865\n",
            "\n",
            "===== Validation data after normalization =====\n",
            "x_val_norm:(20, 5), y_val_norm:(20,)\n",
            "0 : [0.36714976 0.37681159 0.38647343 0.39613527 0.4057971 ] , 0.4154589371980677\n",
            "1 : [0.66183575 0.67149758 0.68115942 0.69082126 0.70048309] , 0.7101449275362319\n",
            "2 : [0.82125604 0.83091787 0.84057971 0.85024155 0.85990338] , 0.8695652173913042\n",
            "3 : [0.58937198 0.59903382 0.60869565 0.61835749 0.62801932] , 0.6376811594202898\n",
            "4 : [0.34299517 0.352657   0.36231884 0.37198068 0.38164251] , 0.3913043478260869\n",
            "\n",
            "===== Test data after normalization =====\n",
            "x_test_norm:(20, 5), y_test_norm:(20,)\n",
            "0 : [0.02898551 0.03864734 0.04830918 0.05797101 0.06763285] , 0.07729468599033829\n",
            "1 : [0.44927536 0.4589372  0.46859903 0.47826087 0.48792271] , 0.4975845410628019\n",
            "2 : [0.13043478 0.14009662 0.14975845 0.15942029 0.16908213] , 0.1787439613526569\n",
            "3 : [0.62318841 0.63285024 0.64251208 0.65217391 0.66183575] , 0.6714975845410627\n",
            "4 : [0.73429952 0.74396135 0.75362319 0.76328502 0.77294686] , 0.7826086956521738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the third dimension of input_dim=1\n",
        "x_train_norm  = x_train_norm[..., np.newaxis]\n",
        "x_val_norm    = x_val_norm[..., np.newaxis]\n",
        "x_test_norm   = x_test_norm[..., np.newaxis]\n",
        "\n",
        "print(\"\\nDimension after changed:\")\n",
        "print(f\"x_train_norm : {x_train_norm.shape}\")\n",
        "print(f\"x_val_norm : {x_val_norm.shape}\")\n",
        "print(f\"x_test_norm : {x_test_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19512af0-4d7b-4849-eb4f-51e456a7b2cc",
        "id": "GBgxNEPcO53n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension after changed:\n",
            "x_train_norm : (160, 5, 1)\n",
            "x_val_norm : (20, 5, 1)\n",
            "x_test_norm : (20, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Covert everything  to the defalt of float32\n",
        "\n",
        "x_train_norm = x_train_norm.astype(np.float32)\n",
        "y_train_norm = y_train_norm.astype(np.float32)\n",
        "x_val_norm = x_val_norm.astype(np.float32)\n",
        "y_val_norm = y_val_norm.astype(np.float32)\n",
        "x_test_norm = x_test_norm.astype(np.float32)\n",
        "y_test_norm = y_test_norm.astype(np.float32)"
      ],
      "metadata": {
        "id": "O7ajoOkEO53n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Compile and train the model"
      ],
      "metadata": {
        "id": "cjWmzM1HPAEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# For regression, the loss can be used as the evaluation metric as well\n",
        "ex2_rnn.compile(loss='mse', optimizer=adam, metrics=[])\n",
        "\n",
        "checkpoint_filepath = \"RNN_ex2_bestmodel_epoch{epoch:03d}.hdf5\"\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)"
      ],
      "metadata": {
        "id": "oIfBe91ORb4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_ex2 = ex2_rnn.fit(x_train_norm, y_train_norm,\n",
        "                  validation_data=(x_val_norm, y_val_norm),\n",
        "                  batch_size=64, epochs=300,\n",
        "                  callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "aATQ_kuCRb4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training and validation loss values\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot( hist_ex2.history['loss'])\n",
        "plt.plot( hist_ex2.history['val_loss'])\n",
        "plt.title('Model loss mean squared error')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train','val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZC4lL9sSruI",
        "outputId": "ec1803df-af93-45e4-e46a-6d589de565d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAFNCAYAAACpPfrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde7xddX3n/9dnX845uSckh1sCJlwVREFTtKO1WqqCVbH1Qqi1OEOlndGxtrVT6Ewd66/OaG9WptoOKq3iBSmWmo6xjBeqdbiUgIgGQQKEJuEWkpD7uey9P78/9jrJ5uQknAA7a5/k9Xw8Dmet7/qu7/6uvQ/n5L2/3/XdkZlIkiRJktSpUnYHJEmSJEm9x7AoSZIkSdqLYVGSJEmStBfDoiRJkiRpL4ZFSZIkSdJeDIuSJEmSpL0YFiVJXRURiyMiI6I2ibrvjIjvPdN21Fsi4pURsa7sfkiSDoxhUZK0W0SsiYiRiFgwrvz7RVBbXE7PJEnSwWZYlCSN9wBw4dhORJwBTC+vO+o1EVHtlcc+0JFmR6YlafIMi5Kk8a4CfrVj/yLgc50VImJORHwuIjZExIMR8d8iolIcq0bEn0bE4xFxP/ALE5z7mYh4OCLWR8QfPZ3wERHHRsTyiNgUEasj4l0dx86OiJURsTUiHo2IPy/KByLi8xGxMSKeiIhbI+KofbS/JiJ+NyLujIgdRZ+PioivR8S2iPhmRMzrqP/SiLixaPcHEfHKjmP/PiJ+XJx3f0T8esexV0bEuoj4nYh4rHhe/v1+rvudRRvbIuKBiHj7RM97RLy7c9pucT0/39HOByPi8x37fxcRj0TEloj4bkSc3nHsbyPiryJiRUTsAF5VPP9fKX4GHoiI93bUn1acszki7gJ+6iley+dGxDeK1/KeiHjbUzz2moj4vYi4E9gREbWIeGNErCqe/3+OiOeNey2fVH9//ZEktRkWJUnj3QzMjojnFSFuGfD5cXX+FzAHOAH4WdrhcizgvAt4PXAWsBR4y7hz/xZoACcVdV4D/NrT6OfVwDrg2OIx/kdE/Fxx7OPAxzNzNnAicE1RflHR7+OA+cBvALv28xhvBl4NnAK8Afg68PvAIO2/oe8FiIiFwNeAPwKOAN4PfCUiBot2HqP9nMym/Tx9LCJe1PE4Rxf9WghcDHyiM4iOiYgZwOXAeZk5C/h3wB3F4ad63p/K14GTgSOB24EvjDv+y8CHgVnAjcA/Aj8o+nwO8L6IeG1R97/Tft5PBF5L+3mfUHFN3wC+WDz2MuCTEXHaPh577J7WC2m/ETGX9s/hl4D30X5tVgD/GBF9HW3srp+Zjad8NiRJhkVJ0oTGRhdfDfwYWD92oCNAXpaZ2zJzDfBnwDuKKm8D/iIz12bmJuB/dpx7FPA64H2ZuSMzHwM+VrQ3aRFxHPAy4Pcycygz7wA+zZ4R0VHgpIhYkJnbM/PmjvL5wEmZ2czM2zJz634e6n9l5qOZuR74F+CWzPx+Zg4B19EOZgC/AqzIzBWZ2crMbwAri2slM7+Wmfdl23eA/wv8TMfjjAIfyszRzFwBbAdO3UefWsDzI2JaZj6cmauK8n0+75ORmVcWr+cw8EHghRExp6PKVzPz/2VmCzgDGMzMD2XmSGbeD3yKPa/j24APZ+amzFxLO+Duy+uBNZn5N5nZyMzvA18B3jrRYxfPPcDlxbXuAi4AvpaZ38jMUeBPgWm0wzQT1JckTYJhUZI0katoj+a8k3FTUIEFQB14sKPsQdojTNAe6Vs77tiY5xTnPlxMF3wC+N+0R5QOxLHApszcto8+XEx7NPDuYqrp6zuu63rg6oh4KCL+OCLq+3mcRzu2d02wP7Pjut46dk3Fdb0cOAYgIs6LiJuLaZZP0A6RnYsIbRw32rWzo+3dMnMH7WD0G7Sfw69FxHM7npN9Pe/7VUxh/UhE3BcRW4E1xaHOPna2/Rzg2HHX+/vA2JTeA+nLc4CXjGvr7bRHWyd67InKju18jCLQrmXPz8O+2pAk7Ydz9iVJe8nMByPiAdqh5uJxhx+nPRL2HOCuoux49ow+Pkx7micdx8asBYaBBc9wKuBDwBERMasjMO7uQ2beC1wY7fsofwm4NiLmF2HrD4E/jPbKriuAe4DPPIO+QPu6rsrMd40/EBH9tEfKfpX2CNloRPwDEE/ngTLzeuD6iJhGe9rrp2iPUu7veQfYwZMXKuoMY78MnA/8PO2gOAfYPK6P2bG9FnggM0/eRzfH+jI26jm+L53WAt/JzFfvp04+RdlDtEc7AYiIKB5//T7qS5ImwZFFSdK+XAz8XBGwdsvMJu17AD8cEbMi4jnAb7PnvsZrgPdGxKLivrtLO859mPYUzD+LiNkRUYmIEyPiZw+kY8XUxhuB/xntRWteUPT38wAR8SsRMViMMD1RnNaKiFdFxBnFVNqttENv60Aeex8+D7whIl5bjNINRHvhmkVAH9APbAAaEXEe7fs0D1i0F9g5v7jPb5j2dNWx/u/zeS/cASyLiHpEjL+ncVbR3kbagfJ/PEVX/hXYViwaM6245udHxNhCNtcAl0XEvOI5+M/7aev/AKdExDuKvtUj4qc6F6iZhGuAX4iIc4qR4t8prufGA2hDkjSOYVGSNKHiHruV+zj8n2mPVN1Pe8GRLwJXFsc+RXuq5w9oL5Ty9+PO/VXaAeou2qNX11JM1zxAFwKLaY8qXQf898z8ZnHsXGBVRGynvdjNsuJetaOLx9tK+17M79CemvqMFOH1fNpTMTfQHi37XaBSjHy+l3ag2Ux7FG/503yoCu1g/hCwifbiQv+xOPZUz/sf0F5wZjPt0dUvdhz7HO1pnOtpvy43sx/FGwavB86k/VErj9O+Z3TsHsc/LNp7gPabA/t8jovn5zW073d8CHgE+CjtgD0pmXkP7ftG/1fRlzcAb8jMkcm2IUnaW2Q6K0OSpENNMc32AaDu6p+SpKfDkUVJkiRJ0l4Mi5IkSZKkvTgNVZIkSZK0F0cWJUmSJEl7MSxKkiRJkvZSK7sDZVqwYEEuXry47G5IkiRJUiluu+22xzNzcKJjh3VYXLx4MStX7usjxCRJkiTp0BYRD+7rmNNQJUmSJEl7MSxKkiRJkvZiWJQkSZIk7eWwvmdRkiRJ0uFtdHSUdevWMTQ0VHZXumpgYIBFixZRr9cnfY5hUZIkSdJha926dcyaNYvFixcTEWV3pysyk40bN7Ju3TqWLFky6fOchipJkiTpsDU0NMT8+fMP2aAIEBHMnz//gEdPDYuSJEmSDmuHclAc83Su0bAoSZIkSSV54okn+OQnP3nA573uda/jiSee6EKP9jAsSpIkSVJJ9hUWG43Gfs9bsWIFc+fO7Va3ABe46Tk33beRx7YNcf6ZC8vuiiRJkqQuu/TSS7nvvvs488wzqdfrDAwMMG/ePO6++25+8pOf8KY3vYm1a9cyNDTEb/7mb3LJJZcAsHjxYlauXMn27ds577zzePnLX86NN97IwoUL+epXv8q0adOecd8cWewxf3fbWv7k+nvK7oYkSZKkg+AjH/kIJ554InfccQd/8id/wu23387HP/5xfvKTnwBw5ZVXctttt7Fy5Uouv/xyNm7cuFcb9957L+9+97tZtWoVc+fO5Stf+cqz0jdHFntMNYJmK8vuhiRJknTY+cN/XMVdD219Vts87djZ/Pc3nD7p+mefffaTPt7i8ssv57rrrgNg7dq13HvvvcyfP/9J5yxZsoQzzzwTgBe/+MWsWbPmmXccw2LPqVUNi5IkSdLhasaMGbu3//mf/5lvfvOb3HTTTUyfPp1XvvKVE378RX9//+7tarXKrl27npW+GBZ7TLViWJQkSZLKcCAjgM+WWbNmsW3btgmPbdmyhXnz5jF9+nTuvvtubr755oPaN8Nij6lG0DAsSpIkSYeF+fPn87KXvYznP//5TJs2jaOOOmr3sXPPPZe//uu/5nnPex6nnnoqL33pSw9q3wyLPaZaqdAyLEqSJEmHjS9+8YsTlvf39/P1r399wmNj9yUuWLCAH/3oR7vL3//+9z9r/XI11B5TqzqyKEmSJKl8hsUeU3E1VEmSJEk9wLDYY2qVoJmGRUmSJEnlMiz2mLHVUNPAKEmSJKlEhsUeU60EgFNRJUmSJJXKsNhjdodFRxYlSZIklairYTEizo2IeyJidURcOsHx/oj4cnH8lohYXJTPj4gbImJ7RPxlR/1ZEXFHx9fjEfEXxbF3RsSGjmO/1s1r6xZHFiVJkiTty8yZMw/aY3XtcxYjogp8Ang1sA64NSKWZ+ZdHdUuBjZn5kkRsQz4KHABMAT8AfD84guAzNwGnNnxGLcBf9/R3pcz8z1duqSDolaERT8+Q5IkSVKZujmyeDawOjPvz8wR4Grg/HF1zgc+W2xfC5wTEZGZOzLze7RD44Qi4hTgSOBfnv2ul2dsZLFlWJQkSZIOeZdeeimf+MQndu9/8IMf5I/+6I8455xzeNGLXsQZZ5zBV7/61VL61s2wuBBY27G/riibsE5mNoAtwPxJtr+M9khiZ6p6c0TcGRHXRsRxT6/b5ao6sihJkiQdNi644AKuueaa3fvXXHMNF110Eddddx233347N9xwA7/zO79TyqcldG0a6kGwDHhHx/4/Al/KzOGI+HXaI5Y/N/6kiLgEuATg+OOPPxj9PCDesyhJkiSV5OuXwiM/fHbbPPoMOO8j+zx81lln8dhjj/HQQw+xYcMG5s2bx9FHH81v/dZv8d3vfpdKpcL69et59NFHOfroo5/dvj2FbobF9UDn6N6iomyiOusiogbMATY+VcMR8UKglpm3jZVlZud5nwb+eKJzM/MK4AqApUuX9lwiqxkWJUmSpMPKW9/6Vq699loeeeQRLrjgAr7whS+wYcMGbrvtNur1OosXL2ZoaJ936HVNN8PircDJEbGEdihcBvzyuDrLgYuAm4C3AN/OyY2vXgh8qbMgIo7JzIeL3TcCP34GfS9NJQyLkiRJUin2MwLYTRdccAHvete7ePzxx/nOd77DNddcw5FHHkm9XueGG27gwQcfLKVfXQuLmdmIiPcA1wNV4MrMXBURHwJWZuZy4DPAVRGxGthEO1ACEBFrgNlAX0S8CXhNx0qqbwNeN+4h3xsRbwQaRVvv7Na1dVOt6j2LkiRJ0uHk9NNPZ9u2bSxcuJBjjjmGt7/97bzhDW/gjDPOYOnSpTz3uc8tpV9dvWcxM1cAK8aVfaBjewh46z7OXbyfdk+YoOwy4LKn29deUa201xxyZFGSJEk6fPzwh3vulVywYAE33XTThPW2b99+sLrU1dVQ9TRUnYYqSZIkqQcYFnvMno/OaJXcE0mSJEmHM8NijxlbDdWsKEmSJKlMhsUe48iiJEmSdHCV8YH3B9vTuUbDYo+p+jmLkiRJ0kEzMDDAxo0bD+nAmJls3LiRgYGBAzqvq6uh6sDVDIuSJEnSQbNo0SLWrVvHhg0byu5KVw0MDLBo0aIDOsew2GMqhkVJkiTpoKnX6yxZsqTsbvQkp6H2mNruexYNi5IkSZLKY1jsMbvvWTyE50xLkiRJ6n2GxR6zOyw2DYuSJEmSymNY7DFVp6FKkiRJ6gGGxR5Tq7RfkpbTUCVJkiSVyLDYY6rFK+LIoiRJkqQyGRZ7THVsZNGwKEmSJKlEhsUe40dnSJIkSeoFhsUeUxlbDbXVKrknkiRJkg5nhsUeU9sdFkvuiCRJkqTDmmGxx1QdWZQkSZLUAwyLPaYa3rMoSZIkqXyGxR5TrY6NLBoWJUmSJJXHsNhj9tyzaFiUJEmSVB7DYo+pOA1VkiRJUg8wLPaYsZHFlmFRkiRJUokMiz1mbDVURxYlSZIklamrYTEizo2IeyJidURcOsHx/oj4cnH8lohYXJTPj4gbImJ7RPzluHP+uWjzjuLryP21NdVEBJXwnkVJkiRJ5epaWIyIKvAJ4DzgNODCiDhtXLWLgc2ZeRLwMeCjRfkQ8AfA+/fR/Nsz88zi67GnaGvKqVUqNNOwKEmSJKk83RxZPBtYnZn3Z+YIcDVw/rg65wOfLbavBc6JiMjMHZn5PdqhcbImbOvpd7881Uo4sihJkiSpVN0MiwuBtR3764qyCetkZgPYAsyfRNt/U0xB/YOOQPh02+o51UrQaBoWJUmSJJVnKi5w8/bMPAP4meLrHQdyckRcEhErI2Llhg0butLBZ6paCVpOQ5UkSZJUom6GxfXAcR37i4qyCetERA2YA2zcX6OZub74vg34Iu3prpNuKzOvyMylmbl0cHDwAC/p4KhVgkarVXY3JEmSJB3GuhkWbwVOjoglEdEHLAOWj6uzHLio2H4L8O3MfQ+pRUQtIhYU23Xg9cCPnk5bvaziPYuSJEmSSlbrVsOZ2YiI9wDXA1XgysxcFREfAlZm5nLgM8BVEbEa2EQ7UAIQEWuA2UBfRLwJeA3wIHB9ERSrwDeBTxWn7LOtqaZmWJQkSZJUsq6FRYDMXAGsGFf2gY7tIeCt+zh38T6affE+6u+zrammWgkahkVJkiRJJZqKC9wc8vzoDEmSJEllMyz2IMOiJEmSpLIZFnuQ9yxKkiRJKpthsQdVwnsWJUmSJJXLsNiDatWgZViUJEmSVCLDYg+qViqOLEqSJEkqlWGxB1UD71mUJEmSVCrDYg+qVSqGRUmSJEmlMiz2ID86Q5IkSVLZDIs9qFoJGq1W2d2QJEmSdBgzLPagaiVoOrAoSZIkqUSGxR5UqwRNRxYlSZIklciw2IMqlaDh0KIkSZKkEhkWe1CtErTSsChJkiSpPIbFHlSpBA1XQ5UkSZJUIsNiD6r50RmSJEmSSmZY7EF+zqIkSZKkshkWe1A1DIuSJEmSymVY7EG1qvcsSpIkSSqXYbEHVStBy7AoSZIkqUSGxR5UDUcWJUmSJJXLsNiDqpWK9yxKkiRJKpVhsQfVqi5wI0mSJKlchsUeVHE1VEmSJEkl62pYjIhzI+KeiFgdEZdOcLw/Ir5cHL8lIhYX5fMj4oaI2B4Rf9lRf3pEfC0i7o6IVRHxkY5j74yIDRFxR/H1a928tm6qVYJGq1V2NyRJkiQdxroWFiOiCnwCOA84DbgwIk4bV+1iYHNmngR8DPhoUT4E/AHw/gma/tPMfC5wFvCyiDiv49iXM/PM4uvTz+LlHFTVStBKyHR0UZIkSVI5ujmyeDawOjPvz8wR4Grg/HF1zgc+W2xfC5wTEZGZOzLze7RD426ZuTMzbyi2R4DbgUVdvIZSVCsB4FRUSZIkSaXpZlhcCKzt2F9XlE1YJzMbwBZg/mQaj4i5wBuAb3UUvzki7oyIayPiuKfb8bKNhUU/PkOSJElSWabkAjcRUQO+BFyemfcXxf8ILM7MFwDfYM+I5fhzL4mIlRGxcsOGDQenwweoVoTFltNQJUmSJJWkm2FxPdA5ureoKJuwThEA5wAbJ9H2FcC9mfkXYwWZuTEzh4vdTwMvnujEzLwiM5dm5tLBwcFJXcjB5siiJEmSpLJ1MyzeCpwcEUsiog9YBiwfV2c5cFGx/Rbg2/kUq7pExB/RDpXvG1d+TMfuG4EfP4O+l2r3PYtNw6IkSZKkctS61XBmNiLiPcD1QBW4MjNXRcSHgJWZuRz4DHBVRKwGNtEOlABExBpgNtAXEW8CXgNsBf4rcDdwe0QA/GWx8ul7I+KNQKNo653durZuG5uG2nQaqiRJkqSSdC0sAmTmCmDFuLIPdGwPAW/dx7mL99Fs7KP+ZcBlT6ujPabiaqiSJEmSSjYlF7g51NW8Z1GSJElSyQyLPahaab8sLcOiJEmSpJIYFntQtXhVHFmUJEmSVBbDYg8aG1lstlol90SSJEnS4cqw2IN2r4ZqVpQkSZJUEsNiD6rE2AI3pkVJkiRJ5TAs9qCaH50hSZIkqWSGxR5UrRoWJUmSJJXLsNiDqmFYlCRJklQuw2IPGpuG6kdnSJIkSSqLYbEHVYuw2DIsSpIkSSqJYbEHVR1ZlCRJklQyw2IPqroaqiRJkqSSGRZ7UK3SflkMi5IkSZLKYljsQUVWdBqqJEmSpNIYFnvQ2MhiKw2LkiRJksphWOxBLnAjSZIkqWyGxR60Z4GbVsk9kSRJknS4Miz2oNrusFhyRyRJkiQdtgyLPciRRUmSJEllMyz2IO9ZlCRJklQ2w2IPGguLLcOiJEmSpJIYFntQzZFFSZIkSSUzLPagyu57Fg2LkiRJksphWOxBNcOiJEmSpJJ1NSxGxLkRcU9ErI6ISyc43h8RXy6O3xIRi4vy+RFxQ0Rsj4i/HHfOiyPih8U5l0dEFOVHRMQ3IuLe4vu8bl5bN7nAjSRJkqSydS0sRkQV+ARwHnAacGFEnDau2sXA5sw8CfgY8NGifAj4A+D9EzT9V8C7gJOLr3OL8kuBb2XmycC3iv0pqRqOLEqSJEkqVzdHFs8GVmfm/Zk5AlwNnD+uzvnAZ4vta4FzIiIyc0dmfo92aNwtIo4BZmfmzZmZwOeAN03Q1mc7yqecqtNQJUmSJJVsUmExImZERKXYPiUi3hgR9ac4bSGwtmN/XVE2YZ3MbABbgPlP0ea6fbR5VGY+XGw/Ahy1j2u5JCJWRsTKDRs2PMUllCMiqFbCsChJkiSpNJMdWfwuMBARC4H/C7wD+NtudeqZKkYdJ0xamXlFZi7NzKWDg4MHuWeTV43wnkVJkiRJpZlsWIzM3An8EvDJzHwrcPpTnLMeOK5jf1FRNmGdiKgBc4CNT9Hmon20+WgxTXVsuupjT9G/nlatBK00LEqSJEkqx6TDYkT8NPB24GtFWfUpzrkVODkilkREH7AMWD6uznLgomL7LcC3i1HBCRXTTLdGxEuLVVB/FfjqBG1d1FE+JdUqQaNpWJQkSZJUjtok670PuAy4LjNXRcQJwA37OyEzGxHxHuB62sHyyuLcDwErM3M58BngqohYDWyiHSgBiIg1wGygLyLeBLwmM+8C/hPtKbDTgK8XXwAfAa6JiIuBB4G3TfLaelKlEjRbrbK7IUmSJOkwNamwmJnfAb4DUCx083hmvncS560AVowr+0DH9hDw1n2cu3gf5SuB509QvhE456n6NFXUKkHTaaiSJEmSSjLZ1VC/GBGzI2IG8CPgroj43e527fDmaqiSJEmSyjTZexZPy8yttD+78OvAEtoroqpLqt6zKEmSJKlEkw2L9eJzFd8ELM/MUfbx0RR6dlSdhipJkiSpRJMNi/8bWAPMAL4bEc8BtnarUyruWXQaqiRJkqSSTHaBm8uByzuKHoyIV3WnS4L2aqgNw6IkSZKkkkx2gZs5EfHnEbGy+Poz2qOM6pJaJWgZFiVJkiSVZLLTUK8EttH+7MK30Z6C+jfd6pSgEo4sSpIkSSrPpKahAidm5ps79v8wIu7oRofUVqt6z6IkSZKk8kx2ZHFXRLx8bCciXgbs6k6XBFCtVAyLkiRJkkoz2ZHF3wA+FxFziv3NwEXd6ZIAqoFhUZIkSVJpJrsa6g+AF0bE7GJ/a0S8D7izm507nNUqFRqtVtndkCRJknSYmuw0VKAdEjNz7PMVf7sL/VGhWgnMipIkSZLKckBhcZx41nqhvVQr4ciiJEmSpNI8k7DoDXVdVK24GqokSZKk8uz3nsWI2MbEoTCAaV3pkQCoVYJmGhYlSZIklWO/YTEzZx2sjujJKpWg0TQsSpIkSSrHM5mGqi6qOQ1VkiRJUokMiz2q6jRUSZIkSSUyLPYoF7iRJEmSVCbDYo+qes+iJEmSpBIZFntUrRK0nIYqSZIkqSSGxR5VrQQNp6FKkiRJKolhsUd5z6IkSZKkMhkWe1StUjEsSpIkSSpNV8NiRJwbEfdExOqIuHSC4/0R8eXi+C0Rsbjj2GVF+T0R8dqi7NSIuKPja2tEvK849sGIWN9x7HXdvLZuq4Qji5IkSZLKU+tWwxFRBT4BvBpYB9waEcsz866OahcDmzPzpIhYBnwUuCAiTgOWAacDxwLfjIhTMvMe4MyO9tcD13W097HM/NNuXdPBVKsGjVar7G5IkiRJOkx1c2TxbGB1Zt6fmSPA1cD54+qcD3y22L4WOCcioii/OjOHM/MBYHXRXqdzgPsy88GuXUGJqpXArChJkiSpLN0MiwuBtR3764qyCetkZgPYAsyf5LnLgC+NK3tPRNwZEVdGxLyJOhURl0TEyohYuWHDhgO5noOqGo4sSpIkSSrPlFzgJiL6gDcCf9dR/FfAibSnqT4M/NlE52bmFZm5NDOXDg4Odr2vT1e1ErQS0s9alCRJklSCbobF9cBxHfuLirIJ60REDZgDbJzEuecBt2fmo2MFmfloZjYzswV8ir2nrU4ptUoAuMiNJEmSpFJ0MyzeCpwcEUuKkcBlwPJxdZYDFxXbbwG+ne2htOXAsmK11CXAycC/dpx3IeOmoEbEMR27vwj86Fm7khJUirDYMCxKkiRJKkHXVkPNzEZEvAe4HqgCV2bmqoj4ELAyM5cDnwGuiojVwCbagZKi3jXAXUADeHdmNgEiYgbtFVZ/fdxD/nFEnAkksGaC41OKI4uSJEmSytS1sAiQmSuAFePKPtCxPQS8dR/nfhj48ATlO2gvgjO+/B3PtL+9pDoWFr1nUZIkSVIJpuQCN4eD3WGxaViUJEmSdPAZFntUzXsWJUmSJJXIsNijqpX2S9NyGqokSZKkEhgWe1S1eGUcWZQkSZJUBsNijxobWfSeRUmSJEllMCz2qJqroUqSJEkqkWGxR1V2f85iq+SeSJIkSTocGRZ7lKuhSpIkSSqTYbFH7f6cRcOiJEmSpBIYFntUNQyLkiRJkspjWOxR1arTUCVJkiSVx7DYo8buWWwZFiVJkiSVwLDYo8amoTqyKEmSJKkMhsUe5QI3kiRJkspkWOxRtaphUZIkSVJ5DIs9quJqqJIkSZJKZFjsUbVK+6XxnkVJkiRJZTAs9ijvWZQkSZJUJsNij9odFptNuOUK+Nb/V3KPJEmSJB1OamV3QBOrVoJj2MjZ3/sPsOFmiCr83H+D4l5GSZIkSeomRxZ7VN/QRr7WfxnzNv0AjnspZBOaI2V3S5IkSdJhwrDYo+be+SnmsoNvv+wqOP1N7cKRHeV2SpIkSdJhw7DYi4a2MPPOv2VF62w2zzoV6tPb5YZFSZIkSedPTLwAACAASURBVAeJYbEX3fppKiPb+KvG+e2Pzuib0S4f3VluvyRJkiQdNroaFiPi3Ii4JyJWR8SlExzvj4gvF8dviYjFHccuK8rviYjXdpSviYgfRsQdEbGyo/yIiPhGRNxbfJ/XzWvrmpGdcNMnaZzw86zKxWzd1XBkUZIkSdJB17WwGBFV4BPAecBpwIURcdq4ahcDmzPzJOBjwEeLc08DlgGnA+cCnyzaG/OqzDwzM5d2lF0KfCszTwa+VexPPd+/CnY+Tu1n38+Cmf088Ph2RxYlSZIkHXTdHFk8G1idmfdn5ghwNXD+uDrnA58ttq8FzomIKMqvzszhzHwAWF20tz+dbX0WeNOzcA0H39b1sPhn4Dk/zYmDM7h/w449YdGRRUmSJEkHSTfD4kJgbcf+uqJswjqZ2QC2APOf4twE/m9E3BYRl3TUOSozHy62HwGOmqhTEXFJRKyMiJUbNmw48Kvqtld/CN7xDwCcMDiT+zZsdxqqJEmSpINuKi5w8/LMfBHt6a3vjohXjK+QmUk7VO4lM6/IzKWZuXRwcLDLXX2aqjUAThycweado2xp1NvlTkOVJEmSdJB0MyyuB47r2F9UlE1YJyJqwBxg4/7Ozcyx748B17FneuqjEXFM0dYxwGPP4rWU4oTB9vTTNduLghHDoiRJkqSDo5th8Vbg5IhYEhF9tBesWT6uznLgomL7LcC3i1HB5cCyYrXUJcDJwL9GxIyImAUQETOA1wA/mqCti4Cvdum6DpoTFswEYPUTxSDpyPb91JYkSZKkZ0+tWw1nZiMi3gNcD1SBKzNzVUR8CFiZmcuBzwBXRcRqYBPtQElR7xrgLqABvDszmxFxFHBdew0casAXM/Ofiof8CHBNRFwMPAi8rVvXdrAsmjeNvmqFn2xsAOE0VEmSJEkHTdfCIkBmrgBWjCv7QMf2EPDWfZz7YeDD48ruB164j/obgXOeYZd7Sq1a4Tnzp3P/4zvbi9w4DVWSJEnSQTIVF7g5rJwwOIP7NxSftTjqaqiSJEmSDg7DYo87YXAm/7ZpJ9nnyKIkSZKkg8ew2ONOWDCD0WYyUpnm5yxKkiRJOmgMiz3uxCPbK6Luot9pqJIkSZIOGsNijzux+PiM7a1+p6FKkiRJOmgMiz1uzvQ682f0saVZ96MzJEmSJB00hsUp4ITBGWwaqcPI9rK7IkmSJOkwYVicAk5YMJNHhyq0hr1nUZIkSdLBYVicAi44+zi2t/oY2rmdjduHy+6OJEmSpMOAYXEKeNHx8zjnBScwkEP88hU3s2nHSNldkiRJknSIMyxOEccdtYBKJGs3bOSzN64puzuSJEmSDnGGxamibwYAJ8wJHtzovYuSJEmSusuwOFXUpwOweBasf2JXyZ2RJEmSdKgzLE4VxcjicbNg/WbDoiRJkqTuMixOFWNhcUbyyNYhRputkjskSZIk6VBmWJwqimmox0xv0kp4ZMtQyR2SJEmSdCgzLE4Vfe2weNRAe0TR+xYlSZIkdZNhcaromwnAgv4G4H2LkiRJkrrLsDhVFNNQ59VHAUcWJUmSJHWXYXGqKBa4qTd3sWBmvyOLkiRJkrrKsDhVFCOLjOxg4bxpjixKkiRJ6irD4lRR64eowuhOFs01LEqSJEnqLsPiVBHRnoo6snP3yGKrlWX3SpIkSdIhyrA4ldSnw8h2Fs6dxkijxeM7hsvukSRJkqRDVFfDYkScGxH3RMTqiLh0guP9EfHl4vgtEbG449hlRfk9EfHaouy4iLghIu6KiFUR8Zsd9T8YEesj4o7i63XdvLZS9E2H0Z0snDsN8OMzJEmSJHVP18JiRFSBTwDnAacBF0bEaeOqXQxszsyTgI8BHy3OPQ1YBpwOnAt8smivAfxOZp4GvBR497g2P5aZZxZfK7p1baXpmIYKfnyGJEmSpO7p5sji2cDqzLw/M0eAq4Hzx9U5H/hssX0tcE5ERFF+dWYOZ+YDwGrg7Mx8ODNvB8jMbcCPgYVdvIbeUp8Bozv2hEVHFiVJkiR1STfD4kJgbcf+OvYOdrvrZGYD2ALMn8y5xZTVs4BbOorfExF3RsSVETFvok5FxCURsTIiVm7YsOFAr6lcfdNhZCezB+rMGqg5sihJkiSpa6bkAjcRMRP4CvC+zNxaFP8VcCJwJvAw8GcTnZuZV2Tm0sxcOjg4eFD6+6ypT4eRHQAsnDvNkUVJkiRJXdPNsLgeOK5jf1FRNmGdiKgBc4CN+zs3Iuq0g+IXMvPvxypk5qOZ2czMFvAp2tNgDy19M2G0HRYXzfOzFiVJkiR1TzfD4q3AyRGxJCL6aC9Ys3xcneXARcX2W4BvZ2YW5cuK1VKXACcD/1rcz/gZ4MeZ+eedDUXEMR27vwj86Fm/orIV01ChGFk0LEqSJEnqklq3Gs7MRkS8B7geqAJXZuaqiPgQsDIzl9MOfldFxGpgE+1ASVHvGuAu2iugvjszmxHxcuAdwA8j4o7ioX6/WPn0jyPiTCCBNcCvd+vaSlNvf3QGwJIFM9g21OD7/7aZs46f8PZMSZIkSXraoj2Qd3haunRprly5suxuTN4N/wO+81H4wGa2j7Y458/+mSNnDfAP734Z1UqU3TtJkiRJU0xE3JaZSyc6NiUXuDls1ae3v4/uZGZ/jd9/3fP44fotXH3rv5XbL0mSJEmHHMPiVNI3o/29mIr6xhcey0uWHMGfXH8Pm3aMlNgxSZIkSYcaw+JUMhYWi4/PiGzxkVf084qRf+FvVnyvxI5JkiRJOtR0bYEbdUHHNFTuuwGu+VWWDG/l8hr8/Q9/wMbzXsb8mf3l9lGSJEnSIcGRxamkc2Txex+D/llw/icZOvJMTmAtn7vpwXL7J0mSJOmQYVicSsbC4sbV8MB34axfgbPezsDiszm1+gifu/EBdo40yu2jJEmSpEOCYXEqGZuGevvngIQz3tbeX3AK03In/bse5e9Wriute5IkSZIOHYbFqWRsZPHfboKFL4YFJ7X3B08F4Lyjt/Kpf7mfRrNVUgclSZIkHSoMi1PJ2MgiwAsu2LO9oB0W33z8DtZt3sUP1j1xkDsmSZIk6VBjWJxKxkYWowqn/9Ke8plHwsAcTor1APzrA5tL6JwkSZKkQ4lhcSoZC4snnQMzB/eUR8CCUxjYcj8nDs7g1jWbyumfJEmSpEOGYXEqqdbhlb8Pr/r9vY8tOBU23MPZS45g5ZpNtFp58PsnSZIk6ZBhWJxqXvl7cOxZe5cPngI7HuOnj6mydajBPY9uO/h9kyRJknTIMCweKopFbl4y+3EAp6JKkiRJekYMi4eKwVMAOHJoDUfPHuBfHzAsSpIkSXr6DIuHirnPgWo/8fhP+KklRzDvvq+Sq/4B0nsXJUmSJB24Wtkd0LOkUoUFJ8PjP+HNM27jlc2/gL8DTv9F+IU/h+lHlN1DSZIkSVOIYfFQsuAUuP8GXjH6PW5vnUTfab/A6T/+BKMP3MSdP/8FNvYv4vkL57Bw7rSyeypJkiSpxzkN9VCy4BTYtZmYNpffrfwX3viDl/CGXR9k545t9P/Dxfznq27m9Zf/Cw89savsnkqSJEnqcYbFQ8nil8H0BcSyz/Mf3/Ay3vHS5/Dm17+eB3/mTzmjsoYbXvgtRhot/svnv8voPd+AkZ1l91iSJElSj4o8jBdAWbp0aa5cubLsbjy7MiFi7/J/ugxu/iSPHv1KZj98I9NiBI5+AVz4JZiz6OD3U5IkSVLpIuK2zFw60TFHFg81EwVFgJ//Q1i4lKM23caqwddx2ejFbH/4XjZ+7N/xX//8k3z8m/ey6qEtNFuH75sHkiRJkvZwZPFQG1ncn8YIkIxQ5wu3PMjIIz/mzff8LgtG1nFH60Q+3/x5HqsMctzsOovm1Fg0q8bCmclzhu5h3qM3UhnaAj/33+CsX9l3KJUkSZI0ZexvZNGweDiFxYkMb4Pvf4HGLZ+itnn1hFV2Zj8r8xTm1UY5o3U3a2a9iHsXv53W3CXUB0/khSccw/yZ/Qe545IkSdIEWi146Puw4W544bL2R8yV7eE729+PeUG5/ZhAaWExIs4FPg5UgU9n5kfGHe8HPge8GNgIXJCZa4pjlwEXA03gvZl5/f7ajIglwNXAfOA24B2ZObK//hkWO2TCQ7fD6C6o9kG1znDWWL+twY+H5rH68VHue2wrJ667jnfuuJI5sWP3qY/mXB6rLWT7jOPYMnAcozOP5eiZFRZNbzJnzhz6jzyF6vzF0GrA8HaoT4cjlvTG/7iSJEk6NAxvh+/+Cdx5DWx7CID/N3gBq874PV56wnxesGhuOf3ash4+fQ4MzIX/eCNUeutOwFLCYkRUgZ8ArwbWAbcCF2bmXR11/hPwgsz8jYhYBvxiZl4QEacBXwLOBo4FvgmcUpw2YZsRcQ3w95l5dUT8NfCDzPyr/fXRsPj0tIa2s+uRHzP86Gp2PnIv2x6+l9h8PwtG1rMgN0+qjV0xwPr6YoZqc8haP1T7oTZApd4PtX6i1k/0zaA1bT45Yz7VvpnU+vrp6++jr95Pva/9Va33Uav1UanVqff1E9U+qNSgWm+HXgOpJEmHnrF/v3pbzMQyoTnafqO+Pu3Jz9PwNqjUoT5QXv+eZZnJznu+xYx/+i14Yi1rj3oVf7H+ubykfh9vy+u5dPTXuLr5Kn712Id55/xVTDv5FUx/3muZNm0areJnaaBehZ2bIFswYwG7RpoM1CtExL4XkJyM4W1w5XnkE2vYsuz/MHfJmc/ilT879hcWa1183LOB1Zl5f9GJq4Hzgbs66pwPfLDYvhb4y4iIovzqzBwGHoiI1UV7TNRmRPwY+Dngl4s6ny3a3W9Y1NNTGZjJjMU/xYzFP8UR4w+O7KC55SHWbWtx96Ymmzdtom/rGvq3r2Nns8K2Vj8xvI1jdt3LsSP30ze0kXqOUMsR6jlKH+2vfkbpj8Yz7muLoEGVBjUa1GhGlSY1mlGjEe3vSYVWVGlRgQhaVGlFhRZVMiq0qJBRpRnt/QCmt3YwvbmVjArbq/PYUZtDi+qTfo8EtH+xRLT3xr4X2wHkuGOVbDB75DFmjz5GM+ps6TuK7X2DNKKPVtSo0qC/uZ2+5k6q2SCyRSVbBE0CGKrOYKg2h+HqTFqV9vXVW8NF/VFGqtMZrs4ggFpziGqOFtdYXGtUCZJpo08wfbQd/Ifqc9hVm0Mrqrv7mlSAaPc/giQYWy8ro0JGUMkmA42tDIxupVmpM1Sfx1B9dnHunmdpz3O215O39/ZYwQTnxET1Os4fO5Idj1lpNai2hqm2RtrXUbzGGbX2dypkpdq+vrHXjNjdWkbs9Yg5rh97ujpB2b7Kn1TW3q62hukf2cjA8EaiNUqTKs2os7M2l521uWQE9eYQ1RwhK300qwNUSOrNndRbu6g1dlJv7iSjxtDAIEMDg2RUiysae2ay+AkttqPzmZtYMNk3HJ+6XiZ7PVqOO2/3vw+L8vHvd070KJXWCPXRbdQbO2hVajSq02hWB2hUp9GoTiOpELSITCKbQIvIFmQW5e1tsrW7Hk/6XtQtjrc71SQyaVSnM1qfWTxOxzM89v98JahUqlQrQSUqVCqx97Xknr0nXd8E5WNvAI9/XfLJje313I1/3pJ4UoUnPUp2PP9j/52g/X09RtJ5jRNcb2d5jv2ebDfW+dPazBbNVlKvVumvVeir7f1OfWSLWnMntdHtBEmzOkCr0ke0GlRaI1RaI1Rbw0SrAVGhFbX274FKrb1dae/v3q7U2v9P7P710u5Ro5U0mkmz1dr9az8IKkXVKL5XaVIrHrdJlUbUaGS0/1HfGGGEOsOVfrLaT3+twkC9QjXiSc/O7td23A//k17zvX4OJv65mKjuaDNpNJu0EuoVqNcqkEkrodVqP+etTIZGG+wYbjI6MsRRuYEjm49BBI/Vj+OR6tFQ7aNWrVCr1ahXK9RqVWrVCvVKUOscVen8fTf2u7k5QrW5i2iOMlrtZzT6yeYotZFt9A1tYMETP2T+E3cyGnXu7DuL740+l9mzZrF4Xh9HzOgjK3ValXr7b2RrlMgGlVaDyAatSh+N2nQyKvQPb6J/ZDMjWWF7ZTY7Yzq1SlKPZCCHmN7cQq2xi03M4uHGbPpHNrF4110cOfQAT9SPZl3/ErbUFtAXTeo0mVZLpleTKk2Gh4cYHhlhuDabkYEFRN8M5uQWZrW20qgMsKN+BMPVmcyMIWbkdkYbTbaMVhgaHmXhyAMcs+teRlvJvXkcd40cydHTmiyetouBvjqbqoNsrsxjXm5hsPkItdYwD8dRrG3O4/jGGk7ZeTvzd9y3+3ldx5HcVHkRj9UX8qrKHZw6dActqtxdPZVbGicyc+YcjjliFtOnT6ORVRpU6KdBP8MEMEwfQ9RpVacR9YH2G/SVpBZJrbGT2ug2aI6yPQfYkf0MtHYwp7mZvuYONuUsHm3NIap15vUnc6rD9G99kGnb/43hrLK+djyPVI9msD7EMZUt9O16jNz2MP3DT7CldgQ7ZhxPTp9PvbmLemuIXdVZbK0vIKv9HNnawLzGY8SWtUzb+RCDbOZBjuWTsz/Klx9cxCtPHeS1bzsDrvsV/uf9f8tvz7yJIzetorUxqNz7N2z62ky+0zqFUWpUaXF6bR2L8hFaBHdVT2XF0As5uX8Tr6j+iNnNzdw340xWVs+iVu/nuPpm5lWGGKrNZmdtLsPRzwh1yGRuPsGc5iaGm7C+MYfjN93IacOr+A8j/4Wh63dxzW/s/b9hL+vmyOJbgHMz89eK/XcAL8nM93TU+VFRZ12xfx/wEtpB7+bM/HxR/hng68Vpe7XZUf+kovw44OuZ+fwJ+nUJcAnA8ccf/+IHH3zwWb5yPV2ZydBoi6HRJkONJrt27aKx7XGa2zfQGNrO6OgIoyMjNEbbX63GMNkcJZsNaI5As0G2RonmSPudtNYoNBtEa7T4arT/aBR/MKpjf0CyRYVm+48KLSKbVGjtLq8U5RWaVLNFkmyPGWyLWUS2mJtbmJNbqdB60p/h9j8k9/zju3M76fgHefEPviBpUuVRjuBRjqBOg2N4nCPZTJ0GVVo0qLCd6exgGg2qNHf3rEICs9jFPLYxk53UownAaFbZwQANakxniOkxDMBw1hmlRtCiRvsa69GklcETzORx5pAE89jGXLZRpUU1Duz3xVDW2cIM+hllbsfUZT1923Iao1Sp0mKAUfpjdFLnDWedHfTTR4OZMdTlXvam4axRp0nlAH+OJe3fSFZ5OOdTjRbHsrGr/4+1MrgnF/H91snMiCF+traKubmla483nLUnvXm9jiP5SR7PwtjAEtbTx95vbI9k+03qjAoz2PWkY82Mp/xbuilnsqq1mAg4rbqOI/IJmlTYnDOp0OKI2L677uM5m2HqHMMmKpHsoo9bm6dyZ57AtOkzOWbOdE4Y+TEnbF1JXw6xNo5lxeiL6a8mr+i7h8Wj91Gh9Qyfpb2NZpVd9DM79v5M7805kwfzKPqiyYmxnn7af8e25HQezXlsqy8gph/B9JENzB9ez+zczg4GGKKPuWzv+HdMjYdyPo/GIK3Zi2gdeRor+s/j7sdHefnJg/zmOSdTrQQMbYG/eR0MbaX50+/htjmvpfXg/2Pw/n9gzo4H2m/4kayJRdw8dDy0Rnl9fSXPGbmPXZUZ3Nw6nfWNWbyitorjeQSARlbYzjRms3PCn/ed2U+V1u6/0dcc9dusO3EZzztmNuedccyz/nw/U2WNLPakzLwCuALa01BL7o46RATT+qpM6yumjs6ZBkcfwZ4ZyIeHQWCvdzkK/cCMyTZUjITUo8LcziHPZgMi6K9U2WtZokwqmRxRqew9ajxB27u/k+O2W1CpMVCfxgDtNwKyOQrD23aPfLRHCcY29/yhyrH2d3/LPaNLmfsZIel4B/1J53cOeuSexyfbIwX1aWSlb0//W02i1YRWg8wmZPuNhHb27xzn6mxrzwjLhO+/5Z6RlyeNnjzp/NyrrFMrarSmL6BVm061EtQqQaMSDDV2UR3aSARkbRrNaj8xOkyO7my/BdA3g2ZtOlTqJDCSsH1kG7H9MSKbxdsUnW9l7NlPYp/9ebLJTc3JeOp6e48Q79367maKjfGjn3uNTlbrtPpmQ62/PQLYHKLS2EmM7iIaO9tl/3979xsj13XWcfz7u3NnZmf/emMbk9YujhojmgpqIqgCVCgEAWnfhKpR66iCUEVqVSWoSAg18IY/ygtAgqJAqdSqoaEqpFEhqoWqtlESUSSgSaBuEqeqMG0qYjmJkzhx1t7d+XMfXtyz69mdGTexd3Z2d34faTR3zr1z55l55tyZM+fcM1kFlBHKQBnqWkYZkKFMa8qkSuqRXlnftb1U/mDUXiRbfg21zkN6ZVfqSURQFAVFEbQ6ndVeG/Xtbb5wa01v9prXS2ten1j3yqzsV316cta8fnFhl+WPW+rZVqujJrqi6gq2+5HLzVLv1YWu4QtlXb2YZSfaur7Hrp7FlX5FBHmWURE0O+WPjMutTp8nI4raDEV1ugyxvYQ6TSIrT1UoKnWolD1RRIGiDUW7/FGxWFnuEEUrHRuaK6EQK9eCXGXPZp6V9aegnF+DSMupZw5ldCoTdLKcnA55tMkFldoElWqVvGiRF4tEa5nFVsFiq0NRdI+SWNsbu5KD7n7H9etYfdXUs836OhmIaiWjnmdUsoxmu2C5Ux6fK1mFPBOViqhkGVP1nMlaBWVVqlN72bVc9jhGtQNnT0LRIqKg1Slotto0251yuV3QXv2brt6ebkVQVGpEdZLIcqpFk7yzSJbXUGMOGnPsyhtcHzA/WaORC858HyI438l4+XyTrNNKea6Ux74sX71WZxm1zqEIOo0rKCbmqVcKporXqHXO0SpEqxDNrMFSZZZCFfbUW0w3X4L6DPtn9rH679Tpc41KdXX/C62gUwRzjWr53u204NyLFMsLLNXmOadp6CxTX34ZNc9yXpOcY5KJeo3d9YJ6JWN24gquWWozVc/LoZHLC1Sqk8wUUfbmVppUz59muT5Puz1R9vw2IDv3HI3ZN/GzRc7homB2onohue1lWHieA3MH+K1OUdafLNW9TovFpSXOLS5Ro01GmyY1zlMlQkxlLeo06TSXaC+fp91qlq9TQFGdImrTZPkE05UlplmmXZ3iNc3SLkQ+CZPNM0TR4mwr40yrytTsFbytkVPPK1B0YOF5YmKOVjPnRzLx45O1nqq8+n0lovwu0TpPM58nX+xw7ezE6siCd/XcE5iYg498A1T21L8T4G0HgQ+u2Ww35SQqqxZO02jMc31WYalVlN9PX30Wshw19hDLBQsqqDbPkheL5NGBKFisX8FCNJis5dSLstf1/TP7+kW2LQyzsXgSONB1e38q67fNs5JyYI5yopuL3bdf+UvALkl5RLQHPJbZeJFAfc7ZrFyk2nd9AbykfQ/cXJDXIN/9OpsV9vrVgTd6wv4E7N07jGC2iSnKrwWboQEX/+nFLlMdmBl1EEMwPeoA3gABc5NdBXuuXi2vpctQ7X4rAJPpcmnK4+jgWOd7iypVmLxQvwXMrP9orFRh9kqyNfFNUH7l7f/ezYHd0107qpfvhnpG2cCiBhPT1IEf7b5j/SqgPOo0WBdIXoddbyk3y7vWpc/nxnSNxvTsmrtczpFrzfNqTJbvEVaedZesArNvQsCe1/NGkWBiFk3MMgPMNF5nQJcyh8V0+Tkp6OrIKH8qqADzK1+nJtee+7n2fbj9j//DnIrnMeCQpKsk1YAjwNF12xwFbk3LNwMPR/kz9lHgiKR6muX0EPDooH2m+zyS9kHa55eH+NzMzMzMzMx2tKH1LEZEW9IdwNcoG+D3RMRxSX8CPB4RR4HPAp9PE9i8TNn4I213P+VkOG3g9ojoAPTbZ3rIjwP3SboL+Fbat5mZmZmZmV2Cof7P4lbnv84wMzMzM7NxdrEJbrbWP0KamZmZmZnZluDGopmZmZmZmfVwY9HMzMzMzMx6uLFoZmZmZmZmPdxYNDMzMzMzsx5uLJqZmZmZmVkPNxbNzMzMzMysx1j/z6Kk08APRh1HH3uAF0cdhI2Ecz/enP/x5dyPL+d+fDn3420r5f/HImJvvxVj3VjcqiQ9PuiPMW1nc+7Hm/M/vpz78eXcjy/nfrxtl/x7GKqZmZmZmZn1cGPRzMzMzMzMerixuDV9etQB2Mg49+PN+R9fzv34cu7Hl3M/3rZF/n3OopmZmZmZmfVwz6KZmZmZmZn1cGNxi5F0o6TvSjoh6c5Rx2PDJekZSU9KOibp8VR2haQHJf1Pup4fdZx2+STdI+kFSU91lfXNtUp3p+PAE5KuHV3kdrkG5P6PJJ1Mdf+YpPd0rfv9lPvvSvq10URtG0HSAUmPSHpa0nFJH0vlrvtj4CL5d/3f4SRNSHpU0rdT7v84lV8l6Zspx1+UVEvl9XT7RFp/cJTxd3NjcQuRVAE+CbwbuAa4RdI1o43KNsEvRcThrumT7wQeiohDwEPptm1/nwNuXFc2KNfvBg6ly4eBT21SjDYcn6M39wCfSHX/cER8BSAd848Ab0/3+dv02WDbUxv43Yi4BrgOuD3l2HV/PAzKP7j+73TLwA0R8Q7gMHCjpOuAP6PM/dXAGeC2tP1twJlU/om03ZbgxuLW8k7gRER8LyKawH3ATSOOyTbfTcC9afle4NdHGIttkIj4BvDyuuJBub4J+Pso/SewS9KVmxOpbbQBuR/kJuC+iFiOiO8DJyg/G2wbiohTEfHfafk14DvAm3HdHwsXyf8grv87RKrDC+lmNV0CuAH4UipfX/dXjglfAn5ZkjYp3ItyY3FreTPwf123n+XiBxXb/gL4uqT/kvThVLYvIk6l5eeAfaMJzTbBoFz7WDAe7khDDe/pGm7u3O9QaVjZTwPfxHV/7KzLP7j+73iSKpKOAS8ADwL/C7wSEe20SXd+V3Of1r8K7N7ciPtzY9FstN4VEddSDj26XdIvdq+McrpiT1k8Gha8IgAAA+5JREFUBpzrsfMp4K2Uw5NOAX8x2nBsmCRNA/8E/E5EnO1e57q/8/XJv+v/GIiITkQcBvZT9hD/xIhDuiRuLG4tJ4EDXbf3pzLboSLiZLp+AXiA8mDy/Mqwo3T9wugitCEblGsfC3a4iHg+fZEogM9wYaiZc7/DSKpSNhS+EBH/nIpd98dEv/y7/o+XiHgFeAT4Ocqh5Xla1Z3f1dyn9XPAS5scal9uLG4tjwGH0kxJNcqTnI+OOCYbEklTkmZWloFfBZ6izPmtabNbgS+PJkLbBINyfRT4zTQz4nXAq11D1mwHWHce2nsp6z6UuT+SZsa7inKik0c3Oz7bGOmco88C34mIv+xa5bo/Bgbl3/V/55O0V9KutNwAfoXynNVHgJvTZuvr/sox4Wbg4TTqYOTyH76JbZaIaEu6A/gaUAHuiYjjIw7Lhmcf8EA6fzkH/iEivirpMeB+SbcBPwDeP8IYbYNI+kfgemCPpGeBPwT+lP65/grwHsrJDc4DH9r0gG3DDMj99ZIOUw4/fAb4CEBEHJd0P/A05UyKt0dEZxRx24b4BeA3gCfTuUsAf4Dr/rgYlP9bXP93vCuBe9Nsthlwf0T8i6Sngfsk3QV8i/LHBNL15yWdoJwQ7cgogu5HW6TRamZmZmZmZluIh6GamZmZmZlZDzcWzczMzMzMrIcbi2ZmZmZmZtbDjUUzMzMzMzPr4caimZmZmZmZ9XBj0czM7DJJ6kg61nW5cwP3fVDSUz98SzMzs43l/1k0MzO7fIsRcXjUQZiZmW0k9yyamZkNiaRnJP25pCclPSrp6lR+UNLDkp6Q9JCkt6TyfZIekPTtdPn5tKuKpM9IOi7p65IaI3tSZmY2NtxYNDMzu3yNdcNQP9C17tWI+Engb4C/SmV/DdwbET8FfAG4O5XfDfxrRLwDuBY4nsoPAZ+MiLcDrwDvG/LzMTMzQxEx6hjMzMy2NUkLETHdp/wZ4IaI+J6kKvBcROyW9CJwZUS0UvmpiNgj6TSwPyKWu/ZxEHgwIg6l2x8HqhFx1/CfmZmZjTP3LJqZmQ1XDFh+I5a7ljt4zgEzM9sEbiyamZkN1we6rv8jLf87cCQtfxD4t7T8EPBRAEkVSXObFaSZmdl6/mXSzMzs8jUkHeu6/dWIWPn7jHlJT1D2Dt6Syn4b+DtJvwecBj6Uyj8GfFrSbZQ9iB8FTg09ejMzsz58zqKZmdmQpHMWfyYiXhx1LGZmZm+Uh6GamZmZmZlZD/csmpmZmZmZWQ/3LJqZmZmZmVkPNxbNzMzMzMyshxuLZmZmZmZm1sONRTMzMzMzM+vhxqKZmZmZmZn1cGPRzMzMzMzMevw/0ie6JNh748MAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Evaluate the model"
      ],
      "metadata": {
        "id": "RBEvAlGPPANY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the best epoch (minimum val_loss)\n",
        "bestmodel_file = max([ f for f in os.listdir(\".\") if f.startswith('RNN_ex2_bestmodel_') and f.endswith(\".hdf5\")])\n",
        "print( f\"The best model : {bestmodel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17060038-cafa-4826-ffe2-0908b8f2aa9f",
        "id": "Bh9SpiSDRuzt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model : RNN_ex2_bestmodel_epoch225.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex2_rnn_best = tf.keras.models.load_model(bestmodel_file, compile=True)"
      ],
      "metadata": {
        "id": "oywsLkq6Ruzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from last epoch\n",
        "score = ex2_rnn.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the last epoch) :{[(ex2_rnn.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the last epoch) :{[(ex2_rnn.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6302cb5f-b1c0-4c6d-e136-520c873ba3d8",
        "id": "gUt7ng_qRuzu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 0.00022981673828326166)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from best epoch\n",
        "score = ex2_rnn_best.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the best epoch) :{[(ex2_rnn_best.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the best epoch) :{[(ex2_rnn_best.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5ac852-1ce7-4539-92fa-efc23e0505f1",
        "id": "F4zHCQDORuzu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 1.4474404679276631e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Inference"
      ],
      "metadata": {
        "id": "ZAOqynAFPNwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_predict = ex2_rnn.predict(x_test_norm)\n",
        "y2_test_predict = ex2_rnn_best.predict(x_test_norm)\n",
        "\n",
        "# Denormalize to raw value\n",
        "y1_inv = minmax_norm.inverse_transform(y1_test_predict)\n",
        "y2_inv = minmax_norm.inverse_transform(y2_test_predict)"
      ],
      "metadata": {
        "id": "WmmIWYJSRx_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(f\"x_test[{i}] = {x_test[i].reshape(1,-1)}, y_test[{i}] = {y_test[i]}, predict--> last_epoch({np.around(y1_inv[i])}) best_epoch({np.around(y2_inv[i])})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc0716cc-0c3e-43af-d8d7-4a8f65f1debb",
        "id": "O2rFTqv_Rx_P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test[0] = [[-394 -392 -390 -388 -386]], y_test[0] = -384, predict--> last_epoch([-385.]) best_epoch([-384.])\n",
            "x_test[1] = [[-307 -305 -303 -301 -299]], y_test[1] = -297, predict--> last_epoch([-300.]) best_epoch([-297.])\n",
            "x_test[2] = [[-373 -371 -369 -367 -365]], y_test[2] = -363, predict--> last_epoch([-365.]) best_epoch([-363.])\n",
            "x_test[3] = [[-271 -269 -267 -265 -263]], y_test[3] = -261, predict--> last_epoch([-264.]) best_epoch([-261.])\n",
            "x_test[4] = [[-248 -246 -244 -242 -240]], y_test[4] = -238, predict--> last_epoch([-241.]) best_epoch([-238.])\n",
            "x_test[5] = [[-377 -375 -373 -371 -369]], y_test[5] = -367, predict--> last_epoch([-369.]) best_epoch([-367.])\n",
            "x_test[6] = [[-206 -204 -202 -200 -198]], y_test[6] = -196, predict--> last_epoch([-200.]) best_epoch([-196.])\n",
            "x_test[7] = [[-218 -216 -214 -212 -210]], y_test[7] = -208, predict--> last_epoch([-211.]) best_epoch([-208.])\n",
            "x_test[8] = [[-266 -264 -262 -260 -258]], y_test[8] = -256, predict--> last_epoch([-259.]) best_epoch([-256.])\n",
            "x_test[9] = [[-391 -389 -387 -385 -383]], y_test[9] = -381, predict--> last_epoch([-383.]) best_epoch([-381.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Save to Drive"
      ],
      "metadata": {
        "id": "23qGgoQHTwoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save file best model to google drive\n",
        "to_path = f\"/content/drive/MyDrive/Colab Notebooks/BADS7604_DL/data/{bestmodel_file}\"\n",
        "print(f\"from : {bestmodel_file}\")\n",
        "print(f\"to : {to_path}\")\n",
        "os.system(f\"cp '{bestmodel_file}' '{to_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blFGuTlqT15p",
        "outputId": "d12fe337-34c9-4912-9507-752c69b933d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from : RNN_ex2_bestmodel_epoch225.hdf5\n",
            "to : /content/drive/MyDrive/Colab Notebooks/BADS7604_DL/data/RNN_ex2_bestmodel_epoch225.hdf5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save last epoch to google drive\n",
        "to_path = f\"/content/drive/MyDrive/Colab Notebooks/BADS7604_DL/data/RNN_ex2_last_epoch.hdf5\"\n",
        "ex2_rnn.save(to_path)"
      ],
      "metadata": {
        "id": "sQjdRp9eVenX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex3 Guess the next three number ( Apple from ex2)"
      ],
      "metadata": {
        "id": "BcqCckcEh31X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Reuse the model of prediction the next number from example 2. Append one predicted number to input sequence, and feed the appended sequence back to the model to make another prediction repeatedly.\n",
        "*   Becareful, denomalize and normalize y properly before appending it to the end of the x input sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "GgqLj3ycXZqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Create Train/val/test set using TimeseriesGenerator"
      ],
      "metadata": {
        "id": "0nRPetjHZnqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_data = 200 #Number of genarate data\n",
        "\n",
        "#TimeseriesGenerator\n",
        "sampling_rate = 2     #for 2 consecutive numbers, sample only one\n",
        "n_input_timesteps = 5 #How many timestep for the input sequence\n",
        "\n",
        "dataset = np.array([ i for i in range(n_data*-sampling_rate, n_data*sampling_rate)])\n",
        "\n",
        "gen_dataset = tf.keras.preprocessing.sequence.TimeseriesGenerator( dataset, dataset, length=sampling_rate*n_input_timesteps, batch_size=n_data, sampling_rate=sampling_rate)\n",
        "\n",
        "x, y = gen_dataset[0]"
      ],
      "metadata": {
        "id": "dWsfubhdZnqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview the first five rows and the last five rows\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5253d98-7cec-441a-86f6-520a2e2f0c12",
        "id": "t97JG1qyZnqj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(200, 5), y-shape:(200,)\n",
            "0 : [-400 -398 -396 -394 -392] , -390\n",
            "1 : [-399 -397 -395 -393 -391] , -389\n",
            "2 : [-398 -396 -394 -392 -390] , -388\n",
            "3 : [-397 -395 -393 -391 -389] , -387\n",
            "4 : [-396 -394 -392 -390 -388] , -386\n",
            "-1 : [-201 -199 -197 -195 -193] , -191\n",
            "-2 : [-202 -200 -198 -196 -194] , -192\n",
            "-3 : [-203 -201 -199 -197 -195] , -193\n",
            "-4 : [-204 -202 -200 -198 -196] , -194\n",
            "-5 : [-205 -203 -201 -199 -197] , -195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data (before splitting it in to train/val/test sets later inthe next cell)\n",
        "\n",
        "#Shuffle the data\n",
        "seed=1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(x)\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(y)\n",
        "\n",
        "# Preview the first five rows of data\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2c4c4c-07bc-48a5-a309-337226cee7a7",
        "id": "3eSZIzkZZnqj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(200, 5), y-shape:(200,)\n",
            "0 : [-371 -369 -367 -365 -363] , -361\n",
            "1 : [-283 -281 -279 -277 -275] , -273\n",
            "2 : [-331 -329 -327 -325 -323] , -321\n",
            "3 : [-226 -224 -222 -220 -218] , -216\n",
            "4 : [-303 -301 -299 -297 -295] , -293\n",
            "-1 : [-249 -247 -245 -243 -241] , -239\n",
            "-2 : [-211 -209 -207 -205 -203] , -201\n",
            "-3 : [-308 -306 -304 -302 -300] , -298\n",
            "-4 : [-233 -231 -229 -227 -225] , -223\n",
            "-5 : [-204 -202 -200 -198 -196] , -194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = int(n_data * 0.8)       # Split 80% to train set\n",
        "n_test = int(n_data * 0.1)        # Split 10% to test set\n",
        "n_val = n_data -n_train -n_test   # 10% to validate set\n",
        "\n",
        "x_train, y_train = x[:n_train] , y[:n_train] \n",
        "x_val, y_val = x[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "x_test, y_test = x[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"x_train-shape:{x_train.shape}, y_train-shape:{y_train.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train[i]} , {y_train[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"x_val-shape:{x_val.shape}, y_val-shape:{y_val.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val[i]} , {y_val[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"x_test-shape:{x_test.shape}, y_test-shape:{y_test.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test[i]} , {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd46dde-22f9-4ffd-c78e-dec9d450c8b0",
        "id": "mb1u3bI9Znqj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "x_train-shape:(160, 5), y_train-shape:(160,)\n",
            "0 : [-371 -369 -367 -365 -363] , -361\n",
            "1 : [-283 -281 -279 -277 -275] , -273\n",
            "2 : [-331 -329 -327 -325 -323] , -321\n",
            "3 : [-226 -224 -222 -220 -218] , -216\n",
            "4 : [-303 -301 -299 -297 -295] , -293\n",
            "\n",
            "===== Validation data =====\n",
            "x_val-shape:(20, 5), y_val-shape:(20,)\n",
            "0 : [-324 -322 -320 -318 -316] , -314\n",
            "1 : [-263 -261 -259 -257 -255] , -253\n",
            "2 : [-230 -228 -226 -224 -222] , -220\n",
            "3 : [-278 -276 -274 -272 -270] , -268\n",
            "4 : [-329 -327 -325 -323 -321] , -319\n",
            "\n",
            "===== Test data =====\n",
            "x_test-shape:(20, 5), y_test-shape:(20,)\n",
            "0 : [-394 -392 -390 -388 -386] , -384\n",
            "1 : [-307 -305 -303 -301 -299] , -297\n",
            "2 : [-373 -371 -369 -367 -365] , -363\n",
            "3 : [-271 -269 -267 -265 -263] , -261\n",
            "4 : [-248 -246 -244 -242 -240] , -238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max scaling to normalize the data to range [0, 1]\n",
        "#.fit_transfrom expects 2D input\n",
        "minmax_norm = MinMaxScaler().fit(x_train.reshape(-1,1))\n",
        "print(f\"Dataset min-max: {minmax_norm.data_min_}, {minmax_norm.data_max_}\")\n",
        "\n",
        "x_train_norm = minmax_norm.transform( x_train.reshape(-1,1)).reshape(-1,5)\n",
        "y_train_norm = minmax_norm.transform( y_train.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "x_val_norm = minmax_norm.transform( x_val.reshape(-1,1)).reshape(-1,5)\n",
        "y_val_norm = minmax_norm.transform( y_val.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "x_test_norm = minmax_norm.transform( x_test.reshape(-1,1)).reshape(-1,5)\n",
        "y_test_norm = minmax_norm.transform( y_test.reshape(-1,1)).reshape(-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742d3ed4-fb36-4b4d-c868-938e92856b60",
        "id": "turr4j2OZnqj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset min-max: [-400.], [-193.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into (batch_size, time_step, input_dim) as required by the SimpleRNN layer\n",
        "print(\"\\n===== Train data after normalization =====\")\n",
        "print(f\"x_train_norm:{x_train_norm.shape}, y_train_norm:{y_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train_norm[i]} , {y_train_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data after normalization =====\")\n",
        "print(f\"x_val_norm:{x_val_norm.shape}, y_val_norm:{y_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val_norm[i]} , {y_val_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data after normalization =====\")\n",
        "print(f\"x_test_norm:{x_test_norm.shape}, y_test_norm:{y_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test_norm[i]} , {y_test_norm[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42d2447-dcaf-46d9-ec9a-885961dfc84b",
        "id": "uxdwk4GHZnqj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data after normalization =====\n",
            "x_train_norm:(160, 5), y_train_norm:(160,)\n",
            "0 : [0.14009662 0.14975845 0.15942029 0.16908213 0.17874396] , 0.18840579710144922\n",
            "1 : [0.56521739 0.57487923 0.58454106 0.5942029  0.60386473] , 0.6135265700483092\n",
            "2 : [0.33333333 0.34299517 0.352657   0.36231884 0.37198068] , 0.3816425120772946\n",
            "3 : [0.84057971 0.85024155 0.85990338 0.86956522 0.87922705] , 0.8888888888888888\n",
            "4 : [0.46859903 0.47826087 0.48792271 0.49758454 0.50724638] , 0.5169082125603865\n",
            "\n",
            "===== Validation data after normalization =====\n",
            "x_val_norm:(20, 5), y_val_norm:(20,)\n",
            "0 : [0.36714976 0.37681159 0.38647343 0.39613527 0.4057971 ] , 0.4154589371980677\n",
            "1 : [0.66183575 0.67149758 0.68115942 0.69082126 0.70048309] , 0.7101449275362319\n",
            "2 : [0.82125604 0.83091787 0.84057971 0.85024155 0.85990338] , 0.8695652173913042\n",
            "3 : [0.58937198 0.59903382 0.60869565 0.61835749 0.62801932] , 0.6376811594202898\n",
            "4 : [0.34299517 0.352657   0.36231884 0.37198068 0.38164251] , 0.3913043478260869\n",
            "\n",
            "===== Test data after normalization =====\n",
            "x_test_norm:(20, 5), y_test_norm:(20,)\n",
            "0 : [0.02898551 0.03864734 0.04830918 0.05797101 0.06763285] , 0.07729468599033829\n",
            "1 : [0.44927536 0.4589372  0.46859903 0.47826087 0.48792271] , 0.4975845410628019\n",
            "2 : [0.13043478 0.14009662 0.14975845 0.15942029 0.16908213] , 0.1787439613526569\n",
            "3 : [0.62318841 0.63285024 0.64251208 0.65217391 0.66183575] , 0.6714975845410627\n",
            "4 : [0.73429952 0.74396135 0.75362319 0.76328502 0.77294686] , 0.7826086956521738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the third dimension of input_dim=1\n",
        "x_train_norm  = x_train_norm[..., np.newaxis]\n",
        "x_val_norm    = x_val_norm[..., np.newaxis]\n",
        "x_test_norm   = x_test_norm[..., np.newaxis]\n",
        "\n",
        "print(\"\\nDimension after changed:\")\n",
        "print(f\"x_train_norm : {x_train_norm.shape}\")\n",
        "print(f\"x_val_norm : {x_val_norm.shape}\")\n",
        "print(f\"x_test_norm : {x_test_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19512af0-4d7b-4849-eb4f-51e456a7b2cc",
        "id": "L6gaSOTnZnqj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension after changed:\n",
            "x_train_norm : (160, 5, 1)\n",
            "x_val_norm : (20, 5, 1)\n",
            "x_test_norm : (20, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Covert everything  to the defalt of float32\n",
        "\n",
        "x_train_norm = x_train_norm.astype(np.float32)\n",
        "y_train_norm = y_train_norm.astype(np.float32)\n",
        "x_val_norm = x_val_norm.astype(np.float32)\n",
        "y_val_norm = y_val_norm.astype(np.float32)\n",
        "x_test_norm = x_test_norm.astype(np.float32)\n",
        "y_test_norm = y_test_norm.astype(np.float32)"
      ],
      "metadata": {
        "id": "0vJqwEEWZnqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 load model form ex2"
      ],
      "metadata": {
        "id": "GIjoeDI7Wi-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel_file = \"RNN_ex2_bestmodel_epoch225.hdf5\"\n",
        "lastepoch_file = \"RNN_ex2_last_epoch.hdf5\"\n",
        "ex2_rnn_best = tf.keras.models.load_model(f\"/content/drive/MyDrive/Colab Notebooks/BADS7604_DL/data/{bestmodel_file}\", compile=True)\n",
        "ex2_rnn_last = tf.keras.models.load_model(f\"/content/drive/MyDrive/Colab Notebooks/BADS7604_DL/data/{lastepoch_file}\", compile=True)"
      ],
      "metadata": {
        "id": "3SZEEhdxOlfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Inferene"
      ],
      "metadata": {
        "id": "2gxG1CLZYeDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how many steps ahead to predict numbers\n",
        "n_steps = 3"
      ],
      "metadata": {
        "id": "TVmS9TtkYu8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show resuts for the first 20 data in test set\n",
        "for i in range(20):\n",
        "  x_norm = np.copy(x_test_norm[i]).reshape(1,-1,1)\n",
        "\n",
        "  #Predict n_steps ahead\n",
        "  for step in range(n_steps):\n",
        "    y_pred_norm = ex2_rnn_best.predict(x_norm)\n",
        "    #Concatenate y_pred_norm to the end of x_norm\n",
        "    x_norm = np.concatenate( [x_norm, y_pred_norm.reshape(1,1,1)], axis=1)\n",
        "\n",
        "  # Denormailze\n",
        "  x = minmax_norm.inverse_transform(x_norm.reshape(1,-1))\n",
        "  print(f\"x_test[{i}] = {x_test[i]}, Predicted-{np.around(x[0,-n_steps:])}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y3XntgSYu_7",
        "outputId": "b69818f9-d182-462a-dc0f-a17ab7bebc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test[0] = [-394 -392 -390 -388 -386], Predicted-[-384. -392. -379.]\n",
            "x_test[1] = [-307 -305 -303 -301 -299], Predicted-[-297. -368. -243.]\n",
            "x_test[2] = [-373 -371 -369 -367 -365], Predicted-[-363. -400. -335.]\n",
            "x_test[3] = [-271 -269 -267 -265 -263], Predicted-[-261. -346. -214.]\n",
            "x_test[4] = [-248 -246 -244 -242 -240], Predicted-[-238. -334. -198.]\n",
            "x_test[5] = [-377 -375 -373 -371 -369], Predicted-[-367. -399. -343.]\n",
            "x_test[6] = [-206 -204 -202 -200 -198], Predicted-[-196. -316. -173.]\n",
            "x_test[7] = [-218 -216 -214 -212 -210], Predicted-[-208. -320. -180.]\n",
            "x_test[8] = [-266 -264 -262 -260 -258], Predicted-[-256. -343. -211.]\n",
            "x_test[9] = [-391 -389 -387 -385 -383], Predicted-[-381. -394. -372.]\n",
            "x_test[10] = [-328 -326 -324 -322 -320], Predicted-[-318. -382. -265.]\n",
            "x_test[11] = [-316 -314 -312 -310 -308], Predicted-[-306. -374. -252.]\n",
            "x_test[12] = [-318 -316 -314 -312 -310], Predicted-[-308. -376. -254.]\n",
            "x_test[13] = [-286 -284 -282 -280 -278], Predicted-[-276. -355. -226.]\n",
            "x_test[14] = [-310 -308 -306 -304 -302], Predicted-[-300. -370. -246.]\n",
            "x_test[15] = [-204 -202 -200 -198 -196], Predicted-[-195. -315. -172.]\n",
            "x_test[16] = [-233 -231 -229 -227 -225], Predicted-[-223. -327. -189.]\n",
            "x_test[17] = [-308 -306 -304 -302 -300], Predicted-[-298. -369. -244.]\n",
            "x_test[18] = [-211 -209 -207 -205 -203], Predicted-[-201. -318. -176.]\n",
            "x_test[19] = [-249 -247 -245 -243 -241], Predicted-[-239. -334. -199.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex4 Guess the next three number ( output = 3)"
      ],
      "metadata": {
        "id": "IDUAQkA6h4Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Create the deep RNN model"
      ],
      "metadata": {
        "id": "9SXQosAgfieD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex4_rnn = tf.keras.models.Sequential()\n",
        "# batch_size=None, time_steps=None, input_dim=1\n",
        "ex4_rnn.add( tf.keras.layers.SimpleRNN(units=20, input_shape=(None,1), return_sequences=True) ) # RNN Layer 1st\n",
        "ex4_rnn.add( tf.keras.layers.SimpleRNN(units=20, return_sequences=True) ) #RNN Layer 2nd\n",
        "ex4_rnn.add( tf.keras.layers.SimpleRNN(units=10) ) #RNN layer 3\n",
        "#Use the defult 'linear activation'\n",
        "ex4_rnn.add( tf.keras.layers.Dense(3))\n",
        "\n",
        "ex4_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a095cdc-5bc5-465b-f948-7c36aaeb7cf0",
        "id": "SluZICu7fieE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, None, 20)          440       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, None, 20)          820       \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 10)                310       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,603\n",
            "Trainable params: 1,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Prepare data with three-step output"
      ],
      "metadata": {
        "id": "q8q3jOmtfieF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_data = 2000 #Number of genarate data\n",
        "\n",
        "#TimeseriesGenerator\n",
        "sampling_rate = 2     #for 2 consecutive numbers, sample only one\n",
        "n_input_timesteps = 5 #How many timestep for the input sequence\n",
        "\n",
        "dataset = np.array([ i for i in range(n_data*-sampling_rate, n_data*sampling_rate)])\n",
        "\n",
        "gen_dataset = tf.keras.preprocessing.sequence.TimeseriesGenerator( dataset, dataset, length=sampling_rate*n_input_timesteps, batch_size=n_data, sampling_rate=sampling_rate)\n",
        "\n",
        "x, y = gen_dataset[0]"
      ],
      "metadata": {
        "id": "vYTBf-xhfieF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview the first five rows and the last five rows\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b5ac49-3a1e-4c02-de03-01b7e806d6ae",
        "id": "UhmSze-SfieF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(2000, 5), y-shape:(2000,)\n",
            "0 : [-4000 -3998 -3996 -3994 -3992] , -3990\n",
            "1 : [-3999 -3997 -3995 -3993 -3991] , -3989\n",
            "2 : [-3998 -3996 -3994 -3992 -3990] , -3988\n",
            "3 : [-3997 -3995 -3993 -3991 -3989] , -3987\n",
            "4 : [-3996 -3994 -3992 -3990 -3988] , -3986\n",
            "-1 : [-2001 -1999 -1997 -1995 -1993] , -1991\n",
            "-2 : [-2002 -2000 -1998 -1996 -1994] , -1992\n",
            "-3 : [-2003 -2001 -1999 -1997 -1995] , -1993\n",
            "-4 : [-2004 -2002 -2000 -1998 -1996] , -1994\n",
            "-5 : [-2005 -2003 -2001 -1999 -1997] , -1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data (before splitting it in to train/val/test sets later inthe next cell)\n",
        "\n",
        "#Shuffle the data\n",
        "seed=1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(x)\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(y)\n",
        "\n",
        "# Preview the first five rows of data\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e9f720-27db-4841-8910-6e07fb3b0768",
        "id": "K4AFEibvfieF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(2000, 5), y-shape:(2000,)\n",
            "0 : [-3033 -3031 -3029 -3027 -3025] , -3023\n",
            "1 : [-3372 -3370 -3368 -3366 -3364] , -3362\n",
            "2 : [-3423 -3421 -3419 -3417 -3415] , -3413\n",
            "3 : [-3911 -3909 -3907 -3905 -3903] , -3901\n",
            "4 : [-2829 -2827 -2825 -2823 -2821] , -2819\n",
            "-1 : [-2825 -2823 -2821 -2819 -2817] , -2815\n",
            "-2 : [-3811 -3809 -3807 -3805 -3803] , -3801\n",
            "-3 : [-3140 -3138 -3136 -3134 -3132] , -3130\n",
            "-4 : [-2744 -2742 -2740 -2738 -2736] , -2734\n",
            "-5 : [-2809 -2807 -2805 -2803 -2801] , -2799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = int(n_data * 0.8)       # Split 80% to train set\n",
        "n_test = int(n_data * 0.1)        # Split 10% to test set\n",
        "n_val = n_data -n_train -n_test   # 10% to validate set\n",
        "\n",
        "x_train, y_train = x[:n_train] , y[:n_train] \n",
        "x_val, y_val = x[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "x_test, y_test = x[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"x_train-shape:{x_train.shape}, y_train-shape:{y_train.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train[i]} , {y_train[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"x_val-shape:{x_val.shape}, y_val-shape:{y_val.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val[i]} , {y_val[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"x_test-shape:{x_test.shape}, y_test-shape:{y_test.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test[i]} , {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445af537-bab4-4842-c81a-4b68c3b44de5",
        "id": "9WQ0N7glfieF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "x_train-shape:(1600, 5), y_train-shape:(1600,)\n",
            "0 : [-3033 -3031 -3029 -3027 -3025] , -3023\n",
            "1 : [-3372 -3370 -3368 -3366 -3364] , -3362\n",
            "2 : [-3423 -3421 -3419 -3417 -3415] , -3413\n",
            "3 : [-3911 -3909 -3907 -3905 -3903] , -3901\n",
            "4 : [-2829 -2827 -2825 -2823 -2821] , -2819\n",
            "\n",
            "===== Validation data =====\n",
            "x_val-shape:(200, 5), y_val-shape:(200,)\n",
            "0 : [-3200 -3198 -3196 -3194 -3192] , -3190\n",
            "1 : [-3488 -3486 -3484 -3482 -3480] , -3478\n",
            "2 : [-2285 -2283 -2281 -2279 -2277] , -2275\n",
            "3 : [-3846 -3844 -3842 -3840 -3838] , -3836\n",
            "4 : [-2724 -2722 -2720 -2718 -2716] , -2714\n",
            "\n",
            "===== Test data =====\n",
            "x_test-shape:(200, 5), y_test-shape:(200,)\n",
            "0 : [-2126 -2124 -2122 -2120 -2118] , -2116\n",
            "1 : [-3343 -3341 -3339 -3337 -3335] , -3333\n",
            "2 : [-3710 -3708 -3706 -3704 -3702] , -3700\n",
            "3 : [-3995 -3993 -3991 -3989 -3987] , -3985\n",
            "4 : [-2885 -2883 -2881 -2879 -2877] , -2875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of one-step outputs (x[i] = [2,4,6,8,10], yi[12] but model request x[i] = [2,4,6,8,10], yi[12,14,16] "
      ],
      "metadata": {
        "id": "QTvLgp61gnqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create three array\n",
        "y_train_temp = np.zeros( (y_train.shape[0],3), dtype=np.float32)\n",
        "y_test_temp = np.zeros( (y_test.shape[0],3), dtype=np.float32)\n",
        "y_val_temp = np.zeros( (y_val.shape[0],3), dtype=np.float32)\n",
        "\n",
        "#Copy original value to vector\n",
        "y_train_temp[:,0] = y_train[:]\n",
        "y_test_temp[:,0] = y_test[:]\n",
        "y_val_temp[:,0] = y_val[:]"
      ],
      "metadata": {
        "id": "UnsB9ZPPhK7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute values for the 1stand 2nd columns of each array\n",
        "for i in range(2):\n",
        "  y_train_temp[:,i+1] = y_train_temp[:,i] +2\n",
        "  y_test_temp[:,i+1] = y_test_temp[:,i] +2\n",
        "  y_val_temp[:,i+1] = y_val_temp[:,i] +2"
      ],
      "metadata": {
        "id": "rlHaa5HKdZAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview Before-After result\n",
        "print(f\"\\n========== y_train ==========\")\n",
        "print(f\"Shape before:{y_train.shape} after:{y_train_temp.shape}\")\n",
        "print(f\"Example befor : {y_train[0]} , after ; {y_train_temp[0]}\")\n",
        "\n",
        "print(f\"\\n========== y_test ==========\")\n",
        "print(f\"Shape before:{y_test.shape} after:{y_test_temp.shape}\")\n",
        "print(f\"Example befor : {y_test[0]} , after ; {y_test_temp[0]}\")\n",
        "\n",
        "print(f\"\\n========== y_val ==========\")\n",
        "print(f\"Shape before:{y_val.shape} after:{y_val_temp.shape}\")\n",
        "print(f\"Example befor : {y_val[0]} , after ; {y_val_temp[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTYGgi4Be4d2",
        "outputId": "18bcfe90-bf3e-4c73-8190-d3265b55ce6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== y_train ==========\n",
            "Shape before:(1600,) after:(1600, 3)\n",
            "Example befor : -3023 , after ; [-3023. -3021. -3019.]\n",
            "\n",
            "========== y_test ==========\n",
            "Shape before:(200,) after:(200, 3)\n",
            "Example befor : -2116 , after ; [-2116. -2114. -2112.]\n",
            "\n",
            "========== y_val ==========\n",
            "Shape before:(200,) after:(200, 3)\n",
            "Example befor : -3190 , after ; [-3190. -3188. -3186.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reassign the new array shape to original y_train y_test y_val\n",
        "y_train = y_train_temp\n",
        "y_test = y_test_temp\n",
        "y_val = y_val_temp"
      ],
      "metadata": {
        "id": "OKq_-wrRjQHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max scaling to normalize the data to range [0, 1]\n",
        "#.fit_transfrom expects 2D input\n",
        "minmax_norm = MinMaxScaler().fit(x_train.reshape(-1,1))\n",
        "print(f\"Dataset min-max: {minmax_norm.data_min_}, {minmax_norm.data_max_}\")\n",
        "\n",
        "x_train_norm = minmax_norm.transform( x_train.reshape(-1,1)).reshape(-1,5)\n",
        "y_train_norm = minmax_norm.transform( y_train.reshape(-1,1)).reshape(-1,3)\n",
        "\n",
        "x_val_norm = minmax_norm.transform( x_val.reshape(-1,1)).reshape(-1,5)\n",
        "y_val_norm = minmax_norm.transform( y_val.reshape(-1,1)).reshape(-1,3)\n",
        "\n",
        "x_test_norm = minmax_norm.transform( x_test.reshape(-1,1)).reshape(-1,5)\n",
        "y_test_norm = minmax_norm.transform( y_test.reshape(-1,1)).reshape(-1,3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730546b4-45b2-4267-bc33-c892dcba04c7",
        "id": "w5-0FdLRfieF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset min-max: [-4000.], [-1993.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into (batch_size, time_step, input_dim) as required by the SimpleRNN layer\n",
        "print(\"\\n===== Train data after normalization =====\")\n",
        "print(f\"x_train_norm:{x_train_norm.shape}, y_train_norm:{y_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train_norm[i]} , {y_train_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data after normalization =====\")\n",
        "print(f\"x_val_norm:{x_val_norm.shape}, y_val_norm:{y_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val_norm[i]} , {y_val_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data after normalization =====\")\n",
        "print(f\"x_test_norm:{x_test_norm.shape}, y_test_norm:{y_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test_norm[i]} , {y_test_norm[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f8766a-d4a4-40d5-edf8-9e3076122277",
        "id": "btteXfSPfieG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data after normalization =====\n",
            "x_train_norm:(1600, 5), y_train_norm:(1600, 3)\n",
            "0 : [0.48181365 0.48281016 0.48380668 0.48480319 0.4857997 ] , [0.4867962  0.48779267 0.48878926]\n",
            "1 : [0.31290483 0.31390135 0.31489786 0.31589437 0.31689088] , [0.31788737 0.31888396 0.31988043]\n",
            "2 : [0.28749377 0.28849028 0.2894868  0.29048331 0.29147982] , [0.29247636 0.29347283 0.2944693 ]\n",
            "3 : [0.04434479 0.04534131 0.04633782 0.04733433 0.04833084] , [0.04932732 0.05032391 0.05132038]\n",
            "4 : [0.5834579  0.58445441 0.58545092 0.58644743 0.58744395] , [0.5884405  0.58943695 0.5904334 ]\n",
            "\n",
            "===== Validation data after normalization =====\n",
            "x_val_norm:(200, 5), y_val_norm:(200, 3)\n",
            "0 : [0.39860488 0.3996014  0.40059791 0.40159442 0.40259093] , [0.4035874  0.404584   0.40558046]\n",
            "1 : [0.25510713 0.25610364 0.25710015 0.25809666 0.25909317] , [0.2600897  0.26108617 0.26208276]\n",
            "2 : [0.85450922 0.85550573 0.85650224 0.85749875 0.85849527] , [0.85949177 0.86048824 0.8614848 ]\n",
            "3 : [0.07673144 0.07772795 0.07872446 0.07972098 0.08071749] , [0.08171398 0.08271057 0.08370704]\n",
            "4 : [0.63577479 0.6367713  0.63776781 0.63876432 0.63976084] , [0.6407574  0.64175385 0.6427503 ]\n",
            "\n",
            "===== Test data after normalization =====\n",
            "x_test_norm:(200, 5), y_test_norm:(200, 3)\n",
            "0 : [0.93373194 0.93472845 0.93572496 0.93672147 0.93771799] , [0.93871444 0.93971103 0.9407075 ]\n",
            "1 : [0.32735426 0.32835077 0.32934728 0.3303438  0.33134031] , [0.33233684 0.3333333  0.33432978]\n",
            "2 : [0.14449427 0.14549078 0.14648729 0.14748381 0.14848032] , [0.14947683 0.1504733  0.15146989]\n",
            "3 : [0.00249128 0.00348779 0.0044843  0.00548082 0.00647733] , [0.00747389 0.00847036 0.00946683]\n",
            "4 : [0.55555556 0.55655207 0.55754858 0.55854509 0.5595416 ] , [0.5605381 0.5615346 0.5625312]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the third dimension of input_dim=1\n",
        "x_train_norm  = x_train_norm[..., np.newaxis]\n",
        "x_val_norm    = x_val_norm[..., np.newaxis]\n",
        "x_test_norm   = x_test_norm[..., np.newaxis]\n",
        "\n",
        "print(\"\\nDimension after changed:\")\n",
        "print(f\"x_train_norm : {x_train_norm.shape}\")\n",
        "print(f\"x_val_norm : {x_val_norm.shape}\")\n",
        "print(f\"x_test_norm : {x_test_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b212805d-ab7d-4023-c8af-bb1dbedf3b0f",
        "id": "1GFv0NAGfieG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension after changed:\n",
            "x_train_norm : (1600, 5, 1)\n",
            "x_val_norm : (200, 5, 1)\n",
            "x_test_norm : (200, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Covert everything  to the defalt of float32\n",
        "\n",
        "x_train_norm = x_train_norm.astype(np.float32)\n",
        "y_train_norm = y_train_norm.astype(np.float32)\n",
        "x_val_norm = x_val_norm.astype(np.float32)\n",
        "y_val_norm = y_val_norm.astype(np.float32)\n",
        "x_test_norm = x_test_norm.astype(np.float32)\n",
        "y_test_norm = y_test_norm.astype(np.float32)"
      ],
      "metadata": {
        "id": "aOf1U0ddfieG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Compile and train the model"
      ],
      "metadata": {
        "id": "KMt3v9LIfieG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# For regression, the loss can be used as the evaluation metric as well\n",
        "ex4_rnn.compile(loss='mse', optimizer=adam, metrics=[])\n",
        "\n",
        "checkpoint_filepath = \"RNN_ex4_bestmodel_epoch{epoch:03d}.hdf5\"\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)"
      ],
      "metadata": {
        "id": "vt3EZs_ofieG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_ex4 = ex4_rnn.fit(x_train_norm, y_train_norm,\n",
        "                  validation_data=(x_val_norm, y_val_norm),\n",
        "                  batch_size=64, epochs=300,\n",
        "                  callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n546CkIgfieG",
        "outputId": "75bfb92d-d182-4740-ac5f-c9d0a70dd05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "25/25 [==============================] - 5s 34ms/step - loss: 0.1498 - val_loss: 0.0173\n",
            "Epoch 2/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0090\n",
            "Epoch 3/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0051\n",
            "Epoch 4/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0038\n",
            "Epoch 5/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0029\n",
            "Epoch 6/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0022\n",
            "Epoch 7/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 8/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 9/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 10/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 8.4898e-04\n",
            "Epoch 11/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 9.4492e-04 - val_loss: 7.8544e-04\n",
            "Epoch 12/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.4969e-04 - val_loss: 5.3399e-04\n",
            "Epoch 13/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.7119e-04 - val_loss: 4.2122e-04\n",
            "Epoch 14/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.4508e-04 - val_loss: 3.3140e-04\n",
            "Epoch 15/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.5424e-04 - val_loss: 3.0129e-04\n",
            "Epoch 16/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.8787e-04 - val_loss: 2.1999e-04\n",
            "Epoch 17/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.3424e-04 - val_loss: 1.8337e-04\n",
            "Epoch 18/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.9734e-04 - val_loss: 1.7502e-04\n",
            "Epoch 19/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.7566e-04 - val_loss: 1.4547e-04\n",
            "Epoch 20/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5143e-04 - val_loss: 1.3124e-04\n",
            "Epoch 21/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.3518e-04 - val_loss: 1.2746e-04\n",
            "Epoch 22/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.2598e-04 - val_loss: 1.1507e-04\n",
            "Epoch 23/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1767e-04 - val_loss: 1.0460e-04\n",
            "Epoch 24/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1350e-04 - val_loss: 1.0026e-04\n",
            "Epoch 25/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.0521e-04 - val_loss: 9.8397e-05\n",
            "Epoch 26/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.0210e-04 - val_loss: 8.5685e-05\n",
            "Epoch 27/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.8710e-05 - val_loss: 9.3501e-05\n",
            "Epoch 28/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 9.6903e-05 - val_loss: 8.3885e-05\n",
            "Epoch 29/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.9581e-05 - val_loss: 8.0544e-05\n",
            "Epoch 30/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.3988e-05 - val_loss: 7.4983e-05\n",
            "Epoch 31/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.0754e-05 - val_loss: 7.2939e-05\n",
            "Epoch 32/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.8333e-05 - val_loss: 7.0389e-05\n",
            "Epoch 33/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.4388e-05 - val_loss: 6.4068e-05\n",
            "Epoch 34/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.2817e-05 - val_loss: 6.2582e-05\n",
            "Epoch 35/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 7.0207e-05 - val_loss: 6.1101e-05\n",
            "Epoch 36/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.6365e-05 - val_loss: 6.2845e-05\n",
            "Epoch 37/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.5110e-05 - val_loss: 5.3501e-05\n",
            "Epoch 38/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.1942e-05 - val_loss: 6.6373e-05\n",
            "Epoch 39/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.2357e-05 - val_loss: 5.2024e-05\n",
            "Epoch 40/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.7105e-05 - val_loss: 5.0248e-05\n",
            "Epoch 41/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.3762e-05 - val_loss: 4.8679e-05\n",
            "Epoch 42/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.0549e-05 - val_loss: 4.4625e-05\n",
            "Epoch 43/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.8417e-05 - val_loss: 4.2924e-05\n",
            "Epoch 44/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.7380e-05 - val_loss: 4.3124e-05\n",
            "Epoch 45/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.8179e-05 - val_loss: 3.9245e-05\n",
            "Epoch 46/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.4325e-05 - val_loss: 3.8021e-05\n",
            "Epoch 47/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.1530e-05 - val_loss: 3.3136e-05\n",
            "Epoch 48/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.1848e-05 - val_loss: 3.7757e-05\n",
            "Epoch 49/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9827e-05 - val_loss: 3.8251e-05\n",
            "Epoch 50/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.7295e-05 - val_loss: 3.1918e-05\n",
            "Epoch 51/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.5602e-05 - val_loss: 3.3878e-05\n",
            "Epoch 52/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.4625e-05 - val_loss: 3.0827e-05\n",
            "Epoch 53/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.5246e-05 - val_loss: 3.8991e-05\n",
            "Epoch 54/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.2192e-05 - val_loss: 2.6198e-05\n",
            "Epoch 55/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.0226e-05 - val_loss: 2.6222e-05\n",
            "Epoch 56/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9348e-05 - val_loss: 2.6539e-05\n",
            "Epoch 57/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.5687e-05 - val_loss: 2.2224e-05\n",
            "Epoch 58/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.4965e-05 - val_loss: 2.1419e-05\n",
            "Epoch 59/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.4718e-05 - val_loss: 2.1064e-05\n",
            "Epoch 60/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.2670e-05 - val_loss: 1.8815e-05\n",
            "Epoch 61/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.2656e-05 - val_loss: 2.1773e-05\n",
            "Epoch 62/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.1901e-05 - val_loss: 2.2241e-05\n",
            "Epoch 63/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.2673e-05 - val_loss: 2.4648e-05\n",
            "Epoch 64/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1229e-05 - val_loss: 1.9049e-05\n",
            "Epoch 65/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.9468e-05 - val_loss: 1.4886e-05\n",
            "Epoch 66/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.7348e-05 - val_loss: 1.4523e-05\n",
            "Epoch 67/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7430e-05 - val_loss: 1.6203e-05\n",
            "Epoch 68/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7071e-05 - val_loss: 2.2819e-05\n",
            "Epoch 69/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5539e-05 - val_loss: 1.3597e-05\n",
            "Epoch 70/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5046e-05 - val_loss: 1.2514e-05\n",
            "Epoch 71/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5128e-05 - val_loss: 1.2315e-05\n",
            "Epoch 72/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.3938e-05 - val_loss: 1.0994e-05\n",
            "Epoch 73/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.2654e-05 - val_loss: 1.1180e-05\n",
            "Epoch 74/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.2555e-05 - val_loss: 1.0592e-05\n",
            "Epoch 75/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1991e-05 - val_loss: 1.0256e-05\n",
            "Epoch 76/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1300e-05 - val_loss: 9.4330e-06\n",
            "Epoch 77/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0635e-05 - val_loss: 9.9435e-06\n",
            "Epoch 78/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0945e-05 - val_loss: 9.8801e-06\n",
            "Epoch 79/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.0008e-05 - val_loss: 8.0552e-06\n",
            "Epoch 80/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.5176e-06 - val_loss: 1.0451e-05\n",
            "Epoch 81/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 9.8288e-06 - val_loss: 8.1618e-06\n",
            "Epoch 82/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.8473e-06 - val_loss: 7.7545e-06\n",
            "Epoch 83/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.5662e-06 - val_loss: 8.0905e-06\n",
            "Epoch 84/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.0318e-06 - val_loss: 6.7649e-06\n",
            "Epoch 85/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.8880e-06 - val_loss: 7.2743e-06\n",
            "Epoch 86/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.1868e-06 - val_loss: 7.1080e-06\n",
            "Epoch 87/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.2129e-06 - val_loss: 6.4712e-06\n",
            "Epoch 88/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.4770e-06 - val_loss: 7.7143e-06\n",
            "Epoch 89/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.9687e-06 - val_loss: 6.1294e-06\n",
            "Epoch 90/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.9801e-06 - val_loss: 5.8507e-06\n",
            "Epoch 91/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6.1356e-06 - val_loss: 8.3875e-06\n",
            "Epoch 92/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.9731e-06 - val_loss: 8.3689e-06\n",
            "Epoch 93/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.6918e-06 - val_loss: 4.7873e-06\n",
            "Epoch 94/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.6781e-06 - val_loss: 4.5006e-06\n",
            "Epoch 95/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.4241e-06 - val_loss: 6.6887e-06\n",
            "Epoch 96/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.1602e-06 - val_loss: 4.6872e-06\n",
            "Epoch 97/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.6085e-06 - val_loss: 5.8326e-06\n",
            "Epoch 98/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.3577e-06 - val_loss: 4.5136e-06\n",
            "Epoch 99/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.5416e-06 - val_loss: 4.7728e-06\n",
            "Epoch 100/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.8438e-06 - val_loss: 4.1829e-06\n",
            "Epoch 101/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.7548e-06 - val_loss: 3.9020e-06\n",
            "Epoch 102/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2949e-06 - val_loss: 5.6333e-06\n",
            "Epoch 103/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.8510e-06 - val_loss: 5.4357e-06\n",
            "Epoch 104/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.4934e-06 - val_loss: 4.0266e-06\n",
            "Epoch 105/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4451e-06 - val_loss: 4.4913e-06\n",
            "Epoch 106/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.5275e-06 - val_loss: 3.6628e-06\n",
            "Epoch 107/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.7967e-06 - val_loss: 4.9771e-06\n",
            "Epoch 108/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.4298e-06 - val_loss: 4.3463e-06\n",
            "Epoch 109/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.3476e-06 - val_loss: 3.2971e-06\n",
            "Epoch 110/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.2998e-06 - val_loss: 3.1966e-06\n",
            "Epoch 111/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.8460e-06 - val_loss: 9.3317e-06\n",
            "Epoch 112/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.8939e-06 - val_loss: 3.9200e-06\n",
            "Epoch 113/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.1528e-06 - val_loss: 3.1466e-06\n",
            "Epoch 114/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.5325e-06 - val_loss: 2.7224e-06\n",
            "Epoch 115/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.6651e-06 - val_loss: 2.8541e-06\n",
            "Epoch 116/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.6753e-06 - val_loss: 3.6105e-06\n",
            "Epoch 117/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.7314e-06 - val_loss: 3.5409e-06\n",
            "Epoch 118/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9382e-06 - val_loss: 2.8514e-06\n",
            "Epoch 119/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.5915e-06 - val_loss: 2.5982e-06\n",
            "Epoch 120/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.1325e-06 - val_loss: 2.4897e-06\n",
            "Epoch 121/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.2173e-06 - val_loss: 3.1520e-06\n",
            "Epoch 122/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.3682e-06 - val_loss: 2.7889e-06\n",
            "Epoch 123/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.3445e-06 - val_loss: 2.6296e-06\n",
            "Epoch 124/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4686e-06 - val_loss: 3.6572e-06\n",
            "Epoch 125/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.4989e-06 - val_loss: 3.2178e-06\n",
            "Epoch 126/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.0559e-06 - val_loss: 4.3774e-06\n",
            "Epoch 127/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.8141e-06 - val_loss: 4.9581e-06\n",
            "Epoch 128/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.0325e-06 - val_loss: 2.5419e-06\n",
            "Epoch 129/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.8084e-06 - val_loss: 2.1284e-06\n",
            "Epoch 130/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.3025e-06 - val_loss: 2.0794e-06\n",
            "Epoch 131/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.0875e-06 - val_loss: 2.5043e-06\n",
            "Epoch 132/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.1356e-06 - val_loss: 2.7135e-06\n",
            "Epoch 133/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2075e-06 - val_loss: 2.5831e-06\n",
            "Epoch 134/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9769e-06 - val_loss: 5.0543e-06\n",
            "Epoch 135/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6978e-06 - val_loss: 2.9466e-06\n",
            "Epoch 136/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9559e-06 - val_loss: 2.5269e-06\n",
            "Epoch 137/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.0530e-06 - val_loss: 2.1989e-06\n",
            "Epoch 138/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2034e-06 - val_loss: 3.0728e-06\n",
            "Epoch 139/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9334e-06 - val_loss: 2.9634e-06\n",
            "Epoch 140/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.7549e-06 - val_loss: 5.3877e-06\n",
            "Epoch 141/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.4160e-06 - val_loss: 3.0664e-06\n",
            "Epoch 142/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.8127e-06 - val_loss: 3.2340e-06\n",
            "Epoch 143/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7525e-06 - val_loss: 3.0047e-06\n",
            "Epoch 144/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.1815e-06 - val_loss: 2.8638e-06\n",
            "Epoch 145/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6262e-06 - val_loss: 3.6022e-06\n",
            "Epoch 146/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6854e-06 - val_loss: 2.2297e-06\n",
            "Epoch 147/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.3448e-06 - val_loss: 4.4382e-06\n",
            "Epoch 148/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.3588e-06 - val_loss: 3.9499e-06\n",
            "Epoch 149/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.0217e-06 - val_loss: 2.0995e-06\n",
            "Epoch 150/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8901e-06 - val_loss: 2.2403e-06\n",
            "Epoch 151/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.1323e-06 - val_loss: 1.6546e-06\n",
            "Epoch 152/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6513e-05 - val_loss: 4.0317e-05\n",
            "Epoch 153/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1756e-05 - val_loss: 3.4984e-06\n",
            "Epoch 154/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.5730e-06 - val_loss: 3.0637e-06\n",
            "Epoch 155/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.4597e-06 - val_loss: 5.5521e-06\n",
            "Epoch 156/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.8682e-06 - val_loss: 5.9766e-06\n",
            "Epoch 157/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4237e-06 - val_loss: 1.8746e-06\n",
            "Epoch 158/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.6398e-06 - val_loss: 9.8823e-06\n",
            "Epoch 159/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.1501e-06 - val_loss: 3.0733e-06\n",
            "Epoch 160/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.4157e-05 - val_loss: 4.8062e-05\n",
            "Epoch 161/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9708e-05 - val_loss: 4.1417e-06\n",
            "Epoch 162/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6397e-05 - val_loss: 1.5031e-05\n",
            "Epoch 163/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.4077e-06 - val_loss: 9.0405e-06\n",
            "Epoch 164/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.4885e-05 - val_loss: 1.7353e-05\n",
            "Epoch 165/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2914e-05 - val_loss: 8.0457e-06\n",
            "Epoch 166/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.4375e-06 - val_loss: 2.9131e-06\n",
            "Epoch 167/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1163e-05 - val_loss: 6.4762e-06\n",
            "Epoch 168/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1943e-05 - val_loss: 2.8082e-06\n",
            "Epoch 169/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9638e-06 - val_loss: 2.5364e-06\n",
            "Epoch 170/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.4703e-05 - val_loss: 2.3105e-05\n",
            "Epoch 171/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2618e-05 - val_loss: 1.7008e-05\n",
            "Epoch 172/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5540e-05 - val_loss: 5.2399e-06\n",
            "Epoch 173/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9929e-06 - val_loss: 4.8494e-06\n",
            "Epoch 174/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.1182e-05 - val_loss: 1.6414e-05\n",
            "Epoch 175/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.1051e-06 - val_loss: 1.4610e-05\n",
            "Epoch 176/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7472e-05 - val_loss: 3.3467e-06\n",
            "Epoch 177/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.0762e-06 - val_loss: 6.4027e-06\n",
            "Epoch 178/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.5824e-06 - val_loss: 7.6151e-06\n",
            "Epoch 179/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.5715e-06 - val_loss: 2.5199e-05\n",
            "Epoch 180/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1487e-05 - val_loss: 1.4271e-06\n",
            "Epoch 181/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.2930e-06 - val_loss: 6.7253e-06\n",
            "Epoch 182/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6072e-05 - val_loss: 3.3925e-06\n",
            "Epoch 183/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2184e-06 - val_loss: 5.0848e-06\n",
            "Epoch 184/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.4119e-06 - val_loss: 4.7449e-06\n",
            "Epoch 185/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4049e-05 - val_loss: 6.5682e-05\n",
            "Epoch 186/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.1715e-05 - val_loss: 2.4280e-05\n",
            "Epoch 187/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.1205e-05 - val_loss: 1.3425e-05\n",
            "Epoch 188/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7.5667e-06 - val_loss: 1.7935e-06\n",
            "Epoch 189/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.2560e-06 - val_loss: 4.0849e-06\n",
            "Epoch 190/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4401e-06 - val_loss: 2.7800e-06\n",
            "Epoch 191/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6.3847e-06 - val_loss: 1.7201e-06\n",
            "Epoch 192/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.2617e-05 - val_loss: 2.0222e-05\n",
            "Epoch 193/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.9920e-05 - val_loss: 5.4315e-05\n",
            "Epoch 194/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.1252e-05 - val_loss: 6.1367e-06\n",
            "Epoch 195/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8544e-05 - val_loss: 3.2174e-06\n",
            "Epoch 196/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.3115e-06 - val_loss: 5.1473e-06\n",
            "Epoch 197/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.8628e-06 - val_loss: 2.0668e-06\n",
            "Epoch 198/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.4732e-06 - val_loss: 3.4553e-06\n",
            "Epoch 199/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.9432e-06 - val_loss: 1.7506e-05\n",
            "Epoch 200/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.4932e-06 - val_loss: 2.6830e-06\n",
            "Epoch 201/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8.9029e-06 - val_loss: 2.4250e-05\n",
            "Epoch 202/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.1910e-05 - val_loss: 1.0530e-05\n",
            "Epoch 203/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.5299e-05 - val_loss: 5.2624e-06\n",
            "Epoch 204/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9229e-05 - val_loss: 2.6333e-05\n",
            "Epoch 205/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.6638e-05 - val_loss: 5.3541e-05\n",
            "Epoch 206/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.1264e-05 - val_loss: 1.2138e-05\n",
            "Epoch 207/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.2937e-06 - val_loss: 4.6606e-06\n",
            "Epoch 208/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9210e-06 - val_loss: 4.3270e-06\n",
            "Epoch 209/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4516e-05 - val_loss: 3.9953e-05\n",
            "Epoch 210/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5704e-05 - val_loss: 1.6814e-05\n",
            "Epoch 211/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6054e-05 - val_loss: 1.0793e-05\n",
            "Epoch 212/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.1759e-06 - val_loss: 3.7484e-06\n",
            "Epoch 213/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.0371e-06 - val_loss: 1.2023e-05\n",
            "Epoch 214/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1881e-05 - val_loss: 1.1470e-04\n",
            "Epoch 215/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.5923e-05 - val_loss: 1.1325e-05\n",
            "Epoch 216/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0157e-05 - val_loss: 1.4585e-05\n",
            "Epoch 217/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.3825e-05 - val_loss: 2.4648e-05\n",
            "Epoch 218/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1829e-05 - val_loss: 6.0560e-06\n",
            "Epoch 219/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.9287e-06 - val_loss: 1.1593e-05\n",
            "Epoch 220/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.7678e-05 - val_loss: 1.3016e-06\n",
            "Epoch 221/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4478e-06 - val_loss: 4.6617e-06\n",
            "Epoch 222/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2915e-06 - val_loss: 1.7234e-06\n",
            "Epoch 223/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.0850e-06 - val_loss: 1.1465e-06\n",
            "Epoch 224/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.4417e-06 - val_loss: 2.9094e-06\n",
            "Epoch 225/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.3910e-06 - val_loss: 4.1775e-06\n",
            "Epoch 226/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2753e-06 - val_loss: 1.3007e-06\n",
            "Epoch 227/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.2589e-06 - val_loss: 4.5730e-06\n",
            "Epoch 228/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.5125e-06 - val_loss: 6.2320e-06\n",
            "Epoch 229/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0852e-05 - val_loss: 1.2637e-06\n",
            "Epoch 230/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.4252e-06 - val_loss: 6.5649e-06\n",
            "Epoch 231/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.2928e-06 - val_loss: 4.5205e-06\n",
            "Epoch 232/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1295e-05 - val_loss: 1.1156e-05\n",
            "Epoch 233/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.5940e-05 - val_loss: 3.9433e-05\n",
            "Epoch 234/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8141e-05 - val_loss: 3.6691e-06\n",
            "Epoch 235/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.3745e-06 - val_loss: 2.0496e-05\n",
            "Epoch 236/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.7213e-05 - val_loss: 1.7668e-05\n",
            "Epoch 237/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4152e-05 - val_loss: 4.5691e-06\n",
            "Epoch 238/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.0885e-06 - val_loss: 1.9465e-06\n",
            "Epoch 239/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.5202e-06 - val_loss: 5.4327e-06\n",
            "Epoch 240/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.0036e-05 - val_loss: 2.2547e-04\n",
            "Epoch 241/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.5980e-05 - val_loss: 9.0830e-06\n",
            "Epoch 242/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.1763e-05 - val_loss: 2.7151e-06\n",
            "Epoch 243/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.8168e-06 - val_loss: 8.0721e-06\n",
            "Epoch 244/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 9.4640e-06 - val_loss: 4.1242e-06\n",
            "Epoch 245/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.3897e-06 - val_loss: 5.0195e-06\n",
            "Epoch 246/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.2223e-06 - val_loss: 3.9051e-06\n",
            "Epoch 247/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.7527e-06 - val_loss: 4.3456e-06\n",
            "Epoch 248/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6577e-05 - val_loss: 7.3085e-05\n",
            "Epoch 249/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6508e-05 - val_loss: 5.9258e-06\n",
            "Epoch 250/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9037e-06 - val_loss: 1.1196e-06\n",
            "Epoch 251/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.6887e-06 - val_loss: 1.2068e-06\n",
            "Epoch 252/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.3006e-06 - val_loss: 2.6953e-06\n",
            "Epoch 253/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9195e-06 - val_loss: 1.3150e-06\n",
            "Epoch 254/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.0163e-06 - val_loss: 5.1719e-06\n",
            "Epoch 255/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.1191e-06 - val_loss: 2.0393e-06\n",
            "Epoch 256/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.5210e-06 - val_loss: 1.1125e-06\n",
            "Epoch 257/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0503e-05 - val_loss: 3.2489e-05\n",
            "Epoch 258/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.2684e-05 - val_loss: 4.9853e-05\n",
            "Epoch 259/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7861e-05 - val_loss: 2.8200e-06\n",
            "Epoch 260/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.3075e-06 - val_loss: 6.7369e-06\n",
            "Epoch 261/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7062e-05 - val_loss: 2.3985e-05\n",
            "Epoch 262/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1490e-05 - val_loss: 6.8044e-06\n",
            "Epoch 263/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1536e-05 - val_loss: 5.6000e-06\n",
            "Epoch 264/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.0239e-06 - val_loss: 2.1506e-06\n",
            "Epoch 265/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.5903e-06 - val_loss: 9.1274e-06\n",
            "Epoch 266/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.6045e-06 - val_loss: 7.9169e-07\n",
            "Epoch 267/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9529e-06 - val_loss: 2.4135e-06\n",
            "Epoch 268/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4.7636e-06 - val_loss: 2.1866e-06\n",
            "Epoch 269/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.1280e-06 - val_loss: 5.2779e-06\n",
            "Epoch 270/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.7261e-06 - val_loss: 1.0051e-05\n",
            "Epoch 271/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.4345e-06 - val_loss: 9.9801e-06\n",
            "Epoch 272/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.0588e-05 - val_loss: 1.2191e-05\n",
            "Epoch 273/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.5887e-05 - val_loss: 9.2316e-06\n",
            "Epoch 274/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7112e-05 - val_loss: 1.0386e-05\n",
            "Epoch 275/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.4497e-05 - val_loss: 1.5047e-05\n",
            "Epoch 276/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9632e-05 - val_loss: 2.3854e-05\n",
            "Epoch 277/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9349e-05 - val_loss: 8.8011e-06\n",
            "Epoch 278/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4548e-05 - val_loss: 1.0025e-05\n",
            "Epoch 279/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4516e-05 - val_loss: 1.8534e-05\n",
            "Epoch 280/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.0202e-05 - val_loss: 2.0100e-05\n",
            "Epoch 281/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2042e-05 - val_loss: 2.6404e-06\n",
            "Epoch 282/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1814e-05 - val_loss: 1.1090e-05\n",
            "Epoch 283/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9555e-05 - val_loss: 3.0870e-05\n",
            "Epoch 284/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.3039e-05 - val_loss: 7.3283e-06\n",
            "Epoch 285/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.9900e-06 - val_loss: 2.3051e-06\n",
            "Epoch 286/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.9151e-06 - val_loss: 1.1635e-05\n",
            "Epoch 287/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.3372e-06 - val_loss: 5.4039e-06\n",
            "Epoch 288/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.3187e-06 - val_loss: 3.8735e-06\n",
            "Epoch 289/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.2832e-06 - val_loss: 1.0416e-05\n",
            "Epoch 290/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0665e-05 - val_loss: 8.4429e-06\n",
            "Epoch 291/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.2906e-06 - val_loss: 2.8510e-06\n",
            "Epoch 292/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.5426e-06 - val_loss: 1.3160e-05\n",
            "Epoch 293/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.8459e-06 - val_loss: 6.2292e-06\n",
            "Epoch 294/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7.7802e-06 - val_loss: 8.6904e-07\n",
            "Epoch 295/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.8847e-06 - val_loss: 1.3946e-06\n",
            "Epoch 296/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1165e-06 - val_loss: 1.8778e-06\n",
            "Epoch 297/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.4219e-06 - val_loss: 1.4963e-05\n",
            "Epoch 298/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.0417e-05 - val_loss: 6.4189e-06\n",
            "Epoch 299/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.9980e-06 - val_loss: 3.8626e-05\n",
            "Epoch 300/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1566e-05 - val_loss: 4.5719e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training and validation loss values\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot( hist_ex4.history['loss'])\n",
        "plt.plot( hist_ex4.history['val_loss'])\n",
        "plt.title('Model loss mean squared error')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train','val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "482029bc-2f0f-402b-936e-bc598755f604",
        "id": "qnVYqj0UfieH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Evaluate the model"
      ],
      "metadata": {
        "id": "ZvmnRWI2fieH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the best epoch (minimum val_loss)\n",
        "bestmodel_file = max([ f for f in os.listdir(\".\") if f.startswith('RNN_ex4_bestmodel_') and f.endswith(\".hdf5\")])\n",
        "print( f\"The best model : {bestmodel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29731ec-1e6f-4c3c-c329-7e112a35910e",
        "id": "MaGJQz0tfieH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model : RNN_ex4_bestmodel_epoch266.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex4_rnn_best = tf.keras.models.load_model(bestmodel_file, compile=True)"
      ],
      "metadata": {
        "id": "7PhAmlt-fieH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from last epoch\n",
        "score = ex4_rnn.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the last epoch) :{[(ex4_rnn.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the last epoch) :{[(ex4_rnn.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01db4898-fc11-4861-c0a1-b505f919952f",
        "id": "r2iCbpmwfieH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 4.817316494154511e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from best epoch\n",
        "score = ex4_rnn_best.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the best epoch) :{[(ex4_rnn_best.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the best epoch) :{[(ex4_rnn_best.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647bdcc7-02f5-43cc-8e46-cc95fcc63379",
        "id": "A8_nn9XSfieH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the best epoch) :[('loss', 9.596348036211566e-07)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 Inference"
      ],
      "metadata": {
        "id": "UkOsFO7PfieH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_predict = ex4_rnn.predict(x_test_norm)\n",
        "y2_test_predict = ex4_rnn_best.predict(x_test_norm)\n",
        "\n",
        "# Denormalize to raw value\n",
        "y1_inv = minmax_norm.inverse_transform(y1_test_predict)\n",
        "y2_inv = minmax_norm.inverse_transform(y2_test_predict)"
      ],
      "metadata": {
        "id": "ImN8fZb_fieH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(f\"x_test[{i}] = {x_test[i].reshape(1,-1)}, y_test[{i}] = {y_test[i]}, predict--> last_epoch({np.around(y1_inv[i])}) best_epoch({np.around(y2_inv[i])})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad7359c-e534-4ac2-c055-68dba77a1012",
        "id": "PxSHVe6vfieH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test[0] = [[-2126 -2124 -2122 -2120 -2118]], y_test[0] = [-2116. -2114. -2112.], predict--> last_epoch([-2111. -2117. -2110.]) best_epoch([-2117. -2116. -2112.])\n",
            "x_test[1] = [[-3343 -3341 -3339 -3337 -3335]], y_test[1] = [-3333. -3331. -3329.], predict--> last_epoch([-3326. -3333. -3326.]) best_epoch([-3332. -3332. -3326.])\n",
            "x_test[2] = [[-3710 -3708 -3706 -3704 -3702]], y_test[2] = [-3700. -3698. -3696.], predict--> last_epoch([-3695. -3699. -3697.]) best_epoch([-3701. -3697. -3698.])\n",
            "x_test[3] = [[-3995 -3993 -3991 -3989 -3987]], y_test[3] = [-3985. -3983. -3981.], predict--> last_epoch([-3977. -3985. -3973.]) best_epoch([-3983. -3987. -3975.])\n",
            "x_test[4] = [[-2885 -2883 -2881 -2879 -2877]], y_test[4] = [-2875. -2873. -2871.], predict--> last_epoch([-2870. -2877. -2871.]) best_epoch([-2875. -2876. -2871.])\n",
            "x_test[5] = [[-2148 -2146 -2144 -2142 -2140]], y_test[5] = [-2138. -2136. -2134.], predict--> last_epoch([-2132. -2139. -2132.]) best_epoch([-2138. -2137. -2134.])\n",
            "x_test[6] = [[-3022 -3020 -3018 -3016 -3014]], y_test[6] = [-3012. -3010. -3008.], predict--> last_epoch([-3005. -3015. -3005.]) best_epoch([-3011. -3012. -3007.])\n",
            "x_test[7] = [[-2034 -2032 -2030 -2028 -2026]], y_test[7] = [-2024. -2022. -2020.], predict--> last_epoch([-2023. -2030. -2020.]) best_epoch([-2027. -2029. -2020.])\n",
            "x_test[8] = [[-3707 -3705 -3703 -3701 -3699]], y_test[8] = [-3697. -3695. -3693.], predict--> last_epoch([-3691. -3696. -3695.]) best_epoch([-3699. -3694. -3695.])\n",
            "x_test[9] = [[-3232 -3230 -3228 -3226 -3224]], y_test[9] = [-3222. -3220. -3218.], predict--> last_epoch([-3216. -3223. -3215.]) best_epoch([-3221. -3221. -3215.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex5 Guess the next three number (containing output in each step)"
      ],
      "metadata": {
        "id": "QVOjbXHYh4Zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Create the deep RNN model"
      ],
      "metadata": {
        "id": "j9miBmUflvCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex5_rnn = tf.keras.models.Sequential()\n",
        "\n",
        "# batch_size=None, time_steps=None, input_dim=1\n",
        "# >> output of RNN is (batch_size, units)=(batch_size,10)\n",
        "ex5_rnn.add( tf.keras.layers.SimpleRNN(units=20, input_shape=(None,1), return_sequences=True) ) # RNN Layer 1st\n",
        "ex5_rnn.add( tf.keras.layers.SimpleRNN(units=20, return_sequences=True) ) #RNN Layer 2nd\n",
        "ex5_rnn.add( tf.keras.layers.SimpleRNN(units=10, return_sequences=True) ) #RNN layer 3 /output prediction of all time step\n",
        "#Use the defult 'linear activation'\n",
        "ex5_rnn.add( tf.keras.layers.TimeDistributed( tf.keras.layers.Dense(3) ) )\n",
        "\n",
        "ex5_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sN4kEJznbbH",
        "outputId": "0b20ff28-3631-4714-ecb8-35a1bd41adb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_3 (SimpleRNN)    (None, None, 20)          440       \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, None, 20)          820       \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, None, 10)          310       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 3)          33        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,603\n",
            "Trainable params: 1,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Prepare data with three-step outputs for all time step"
      ],
      "metadata": {
        "id": "O7rP2DS5lvWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_data = 2000 #Number of genarate data\n",
        "\n",
        "#TimeseriesGenerator\n",
        "sampling_rate = 2     #for 2 consecutive numbers, sample only one\n",
        "n_input_timesteps = 5 #How many timestep for the input sequence\n",
        "\n",
        "dataset = np.array([ i for i in range(n_data*-sampling_rate, n_data*sampling_rate)])\n",
        "\n",
        "gen_dataset = tf.keras.preprocessing.sequence.TimeseriesGenerator( dataset, dataset, length=sampling_rate*n_input_timesteps, batch_size=n_data, sampling_rate=sampling_rate)\n",
        "\n",
        "x, y = gen_dataset[0]"
      ],
      "metadata": {
        "id": "R3Xi1Po_p63s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview the first five rows and the last five rows\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe74002-1e35-4ee5-d414-44534eafcd2a",
        "id": "xwX62tcrp63s"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(2000, 5), y-shape:(2000,)\n",
            "0 : [-4000 -3998 -3996 -3994 -3992] , -3990\n",
            "1 : [-3999 -3997 -3995 -3993 -3991] , -3989\n",
            "2 : [-3998 -3996 -3994 -3992 -3990] , -3988\n",
            "3 : [-3997 -3995 -3993 -3991 -3989] , -3987\n",
            "4 : [-3996 -3994 -3992 -3990 -3988] , -3986\n",
            "-1 : [-2001 -1999 -1997 -1995 -1993] , -1991\n",
            "-2 : [-2002 -2000 -1998 -1996 -1994] , -1992\n",
            "-3 : [-2003 -2001 -1999 -1997 -1995] , -1993\n",
            "-4 : [-2004 -2002 -2000 -1998 -1996] , -1994\n",
            "-5 : [-2005 -2003 -2001 -1999 -1997] , -1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data (before splitting it in to train/val/test sets later inthe next cell)\n",
        "\n",
        "#Shuffle the data\n",
        "seed=1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(x)\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(y)\n",
        "\n",
        "# Preview the first five rows of data\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d1007a-71fb-47ce-f6a7-7ff7c21c9035",
        "id": "IAxr_Qhqp63t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(2000, 5), y-shape:(2000,)\n",
            "0 : [-3033 -3031 -3029 -3027 -3025] , -3023\n",
            "1 : [-3372 -3370 -3368 -3366 -3364] , -3362\n",
            "2 : [-3423 -3421 -3419 -3417 -3415] , -3413\n",
            "3 : [-3911 -3909 -3907 -3905 -3903] , -3901\n",
            "4 : [-2829 -2827 -2825 -2823 -2821] , -2819\n",
            "-1 : [-2825 -2823 -2821 -2819 -2817] , -2815\n",
            "-2 : [-3811 -3809 -3807 -3805 -3803] , -3801\n",
            "-3 : [-3140 -3138 -3136 -3134 -3132] , -3130\n",
            "-4 : [-2744 -2742 -2740 -2738 -2736] , -2734\n",
            "-5 : [-2809 -2807 -2805 -2803 -2801] , -2799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = int(n_data * 0.8)       # Split 80% to train set\n",
        "n_test = int(n_data * 0.1)        # Split 10% to test set\n",
        "n_val = n_data -n_train -n_test   # 10% to validate set\n",
        "\n",
        "x_train, y_train = x[:n_train] , y[:n_train] \n",
        "x_val, y_val = x[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "x_test, y_test = x[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"x_train-shape:{x_train.shape}, y_train-shape:{y_train.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train[i]} , {y_train[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"x_val-shape:{x_val.shape}, y_val-shape:{y_val.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val[i]} , {y_val[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"x_test-shape:{x_test.shape}, y_test-shape:{y_test.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test[i]} , {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8354908-fa5e-43eb-95bf-c425b7dd81bd",
        "id": "_NzZ3irSp63t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "x_train-shape:(1600, 5), y_train-shape:(1600,)\n",
            "0 : [-3033 -3031 -3029 -3027 -3025] , -3023\n",
            "1 : [-3372 -3370 -3368 -3366 -3364] , -3362\n",
            "2 : [-3423 -3421 -3419 -3417 -3415] , -3413\n",
            "3 : [-3911 -3909 -3907 -3905 -3903] , -3901\n",
            "4 : [-2829 -2827 -2825 -2823 -2821] , -2819\n",
            "\n",
            "===== Validation data =====\n",
            "x_val-shape:(200, 5), y_val-shape:(200,)\n",
            "0 : [-3200 -3198 -3196 -3194 -3192] , -3190\n",
            "1 : [-3488 -3486 -3484 -3482 -3480] , -3478\n",
            "2 : [-2285 -2283 -2281 -2279 -2277] , -2275\n",
            "3 : [-3846 -3844 -3842 -3840 -3838] , -3836\n",
            "4 : [-2724 -2722 -2720 -2718 -2716] , -2714\n",
            "\n",
            "===== Test data =====\n",
            "x_test-shape:(200, 5), y_test-shape:(200,)\n",
            "0 : [-2126 -2124 -2122 -2120 -2118] , -2116\n",
            "1 : [-3343 -3341 -3339 -3337 -3335] , -3333\n",
            "2 : [-3710 -3708 -3706 -3704 -3702] , -3700\n",
            "3 : [-3995 -3993 -3991 -3989 -3987] , -3985\n",
            "4 : [-2885 -2883 -2881 -2879 -2877] , -2875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of one-step outputs (x[i] = [2,4,6,8,10], yi[12] \n",
        "</br> but model request \n",
        "</br> x[i] = [2,4,6,8,10] \n",
        "</br> y[i] = [[4,6,8],[6,8,10],[8,10,12],[10,12,14],[12,14,16]]"
      ],
      "metadata": {
        "id": "ZLEXDKqKp63t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create three array each input's time_steps=5, output_dim=3\n",
        "n_output_timesteps = 3\n",
        "y_train_temp = np.zeros( (y_train.shape[0], n_input_timesteps, n_output_timesteps), dtype=np.float32)\n",
        "y_test_temp = np.zeros( (y_test.shape[0], n_input_timesteps, n_output_timesteps), dtype=np.float32)\n",
        "y_val_temp = np.zeros( (y_val.shape[0], n_input_timesteps, n_output_timesteps), dtype=np.float32)\n",
        "\n",
        "#Fill the three new arrays with the first predicted numbers (for the last time step only)\n",
        "y_train_temp[:,-1,0] = y_train[:]\n",
        "y_test_temp[:,-1,0]  = y_test[:]\n",
        "y_val_temp[:,-1,0]   = y_val[:]\n",
        "\n",
        "print(f\"Example data : \\n{y_train_temp[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRL_2qMNp63t",
        "outputId": "71fcac03-5ce9-4cec-b9b1-ed0c4391e0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example data : \n",
            "[[    0.     0.     0.]\n",
            " [    0.     0.     0.]\n",
            " [    0.     0.     0.]\n",
            " [    0.     0.     0.]\n",
            " [-3023.     0.     0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the last time step only,fill in tje second, third\n",
        "for i in range(1,n_output_timesteps):\n",
        "  y_train_temp[:,-1,i] = y_train_temp[:,-1,i-1] +2\n",
        "  y_test_temp[:,-1,i]  = y_test_temp[:,-1,i-1] +2\n",
        "  y_val_temp[:,-1,i]   = y_val_temp[:,-1,i-1] +2\n",
        "\n",
        "print(f\"Example data :\\n {y_train_temp[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etWb4jx6p63t",
        "outputId": "fbe40e24-2933-4d1f-c33b-e7cd7e8e3635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example data :\n",
            " [[    0.     0.     0.]\n",
            " [    0.     0.     0.]\n",
            " [    0.     0.     0.]\n",
            " [    0.     0.     0.]\n",
            " [-3023. -3021. -3019.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the remaining non-last time step, fill in values by referring to thire next timestep\n",
        "for tm in range(n_input_timesteps-2,-1,-1):\n",
        "  y_train_temp[:, tm, :] = y_train_temp[:, tm+1, :]-2\n",
        "  y_test_temp[:, tm, :]  = y_test_temp[:, tm+1, :]-2\n",
        "  y_val_temp[:, tm, :]   = y_val_temp[:, tm+1, :]-2\n",
        "\n",
        "print(f\"Example data :\\n {y_train_temp[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsNf4QOAvR4V",
        "outputId": "246c7e98-8dd5-4327-bd35-b53acc1d0948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example data :\n",
            " [[-3031. -3029. -3027.]\n",
            " [-3029. -3027. -3025.]\n",
            " [-3027. -3025. -3023.]\n",
            " [-3025. -3023. -3021.]\n",
            " [-3023. -3021. -3019.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview Before-After result\n",
        "print(f\"\\n========== y_train ==========\")\n",
        "print(f\"Shape before:{y_train.shape} after:{y_train_temp.shape}\")\n",
        "print(f\"Example \\nbefor : {y_train[0]} , \\nafter ; \\n{y_train_temp[0]}\")\n",
        "\n",
        "print(f\"\\n========== y_test ==========\")\n",
        "print(f\"Shape before:{y_test.shape} after:{y_test_temp.shape}\")\n",
        "print(f\"Example \\nbefor : {y_test[0]} , \\nafter : \\n{y_test_temp[0]}\")\n",
        "\n",
        "print(f\"\\n========== y_val ==========\")\n",
        "print(f\"Shape before:{y_val.shape} after:{y_val_temp.shape}\")\n",
        "print(f\"Example \\nbefor : {y_val[0]} , \\nafter ; \\n{y_val_temp[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038a50a3-e2a3-4f5a-b692-f400402257fa",
        "id": "EVVWpJuGp63t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== y_train ==========\n",
            "Shape before:(1600,) after:(1600, 5, 3)\n",
            "Example \n",
            "befor : -3023 , \n",
            "after ; \n",
            "[[-3031. -3029. -3027.]\n",
            " [-3029. -3027. -3025.]\n",
            " [-3027. -3025. -3023.]\n",
            " [-3025. -3023. -3021.]\n",
            " [-3023. -3021. -3019.]]\n",
            "\n",
            "========== y_test ==========\n",
            "Shape before:(200,) after:(200, 5, 3)\n",
            "Example \n",
            "befor : -2116 , \n",
            "after : \n",
            "[[-2124. -2122. -2120.]\n",
            " [-2122. -2120. -2118.]\n",
            " [-2120. -2118. -2116.]\n",
            " [-2118. -2116. -2114.]\n",
            " [-2116. -2114. -2112.]]\n",
            "\n",
            "========== y_val ==========\n",
            "Shape before:(200,) after:(200, 5, 3)\n",
            "Example \n",
            "befor : -3190 , \n",
            "after ; \n",
            "[[-3198. -3196. -3194.]\n",
            " [-3196. -3194. -3192.]\n",
            " [-3194. -3192. -3190.]\n",
            " [-3192. -3190. -3188.]\n",
            " [-3190. -3188. -3186.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reassign the new array shape to original y_train y_test y_val\n",
        "y_train = y_train_temp\n",
        "y_test = y_test_temp\n",
        "y_val = y_val_temp"
      ],
      "metadata": {
        "id": "i_D5-cUvp63t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max scaling to normalize the data to range [0, 1]\n",
        "#.fit_transfrom expects 2D input\n",
        "minmax_norm = MinMaxScaler().fit(x_train.reshape(-1,1))\n",
        "print(f\"Dataset min-max: {minmax_norm.data_min_}, {minmax_norm.data_max_}\")\n",
        "\n",
        "x_train_norm = minmax_norm.transform( x_train.reshape(-1,1)).reshape(-1,5)\n",
        "y_train_norm = minmax_norm.transform( y_train.reshape(-1,1)).reshape(y_train.shape)\n",
        "\n",
        "x_val_norm = minmax_norm.transform( x_val.reshape(-1,1)).reshape(-1,5)\n",
        "y_val_norm = minmax_norm.transform( y_val.reshape(-1,1)).reshape(y_val.shape)\n",
        "\n",
        "x_test_norm = minmax_norm.transform( x_test.reshape(-1,1)).reshape(-1,5)\n",
        "y_test_norm = minmax_norm.transform( y_test.reshape(-1,1)).reshape(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8227a56b-769c-4b02-b6ff-83834d9427b6",
        "id": "IG80vnBqp63t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset min-max: [-4000.], [-1993.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into (batch_size, time_step, input_dim) as required by the SimpleRNN layer\n",
        "print(\"\\n===== Train data after normalization =====\")\n",
        "print(f\"x_train_norm:{x_train_norm.shape}, y_train_norm:{y_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_train_norm[i]} , {y_train_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data after normalization =====\")\n",
        "print(f\"x_val_norm:{x_val_norm.shape}, y_val_norm:{y_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_val_norm[i]} , {y_val_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data after normalization =====\")\n",
        "print(f\"x_test_norm:{x_test_norm.shape}, y_test_norm:{y_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x_test_norm[i]} , {y_test_norm[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024a1301-1eee-4f38-b1e8-698d5061a783",
        "id": "c_n5J9kzp63t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data after normalization =====\n",
            "x_train_norm:(1600, 5), y_train_norm:(1600, 5, 3)\n",
            "0 : [0.48181365 0.48281016 0.48380668 0.48480319 0.4857997 ] , [[0.4828102  0.48380667 0.48480314]\n",
            " [0.48380667 0.48480314 0.48579973]\n",
            " [0.48480314 0.48579973 0.4867962 ]\n",
            " [0.48579973 0.4867962  0.48779267]\n",
            " [0.4867962  0.48779267 0.48878926]]\n",
            "1 : [0.31290483 0.31390135 0.31489786 0.31589437 0.31689088] , [[0.31390136 0.31489784 0.3158943 ]\n",
            " [0.31489784 0.3158943  0.3168909 ]\n",
            " [0.3158943  0.3168909  0.31788737]\n",
            " [0.3168909  0.31788737 0.31888396]\n",
            " [0.31788737 0.31888396 0.31988043]]\n",
            "2 : [0.28749377 0.28849028 0.2894868  0.29048331 0.29147982] , [[0.28849024 0.28948683 0.2904833 ]\n",
            " [0.28948683 0.2904833  0.29147977]\n",
            " [0.2904833  0.29147977 0.29247636]\n",
            " [0.29147977 0.29247636 0.29347283]\n",
            " [0.29247636 0.29347283 0.2944693 ]]\n",
            "3 : [0.04434479 0.04534131 0.04633782 0.04733433 0.04833084] , [[0.04534132 0.04633779 0.04733438]\n",
            " [0.04633779 0.04733438 0.04833085]\n",
            " [0.04733438 0.04833085 0.04932732]\n",
            " [0.04833085 0.04932732 0.05032391]\n",
            " [0.04932732 0.05032391 0.05132038]]\n",
            "4 : [0.5834579  0.58445441 0.58545092 0.58644743 0.58744395] , [[0.58445436 0.58545095 0.5864474 ]\n",
            " [0.58545095 0.5864474  0.5874439 ]\n",
            " [0.5864474  0.5874439  0.5884405 ]\n",
            " [0.5874439  0.5884405  0.58943695]\n",
            " [0.5884405  0.58943695 0.5904334 ]]\n",
            "\n",
            "===== Validation data after normalization =====\n",
            "x_val_norm:(200, 5), y_val_norm:(200, 5, 3)\n",
            "0 : [0.39860488 0.3996014  0.40059791 0.40159442 0.40259093] , [[0.3996014  0.40059787 0.40159446]\n",
            " [0.40059787 0.40159446 0.40259093]\n",
            " [0.40159446 0.40259093 0.4035874 ]\n",
            " [0.40259093 0.4035874  0.404584  ]\n",
            " [0.4035874  0.404584   0.40558046]]\n",
            "1 : [0.25510713 0.25610364 0.25710015 0.25809666 0.25909317] , [[0.25610358 0.25710016 0.25809664]\n",
            " [0.25710016 0.25809664 0.25909323]\n",
            " [0.25809664 0.25909323 0.2600897 ]\n",
            " [0.25909323 0.2600897  0.26108617]\n",
            " [0.2600897  0.26108617 0.26208276]]\n",
            "2 : [0.85450922 0.85550573 0.85650224 0.85749875 0.85849527] , [[0.85550576 0.85650223 0.8574987 ]\n",
            " [0.85650223 0.8574987  0.8584953 ]\n",
            " [0.8574987  0.8584953  0.85949177]\n",
            " [0.8584953  0.85949177 0.86048824]\n",
            " [0.85949177 0.86048824 0.8614848 ]]\n",
            "3 : [0.07673144 0.07772795 0.07872446 0.07972098 0.08071749] , [[0.07772798 0.07872445 0.07972092]\n",
            " [0.07872445 0.07972092 0.08071751]\n",
            " [0.07972092 0.08071751 0.08171398]\n",
            " [0.08071751 0.08171398 0.08271057]\n",
            " [0.08171398 0.08271057 0.08370704]]\n",
            "4 : [0.63577479 0.6367713  0.63776781 0.63876432 0.63976084] , [[0.63677126 0.63776785 0.6387643 ]\n",
            " [0.63776785 0.6387643  0.6397608 ]\n",
            " [0.6387643  0.6397608  0.6407574 ]\n",
            " [0.6397608  0.6407574  0.64175385]\n",
            " [0.6407574  0.64175385 0.6427503 ]]\n",
            "\n",
            "===== Test data after normalization =====\n",
            "x_test_norm:(200, 5), y_test_norm:(200, 5, 3)\n",
            "0 : [0.93373194 0.93472845 0.93572496 0.93672147 0.93771799] , [[0.93472844 0.9357249  0.9367215 ]\n",
            " [0.9357249  0.9367215  0.937718  ]\n",
            " [0.9367215  0.937718   0.93871444]\n",
            " [0.937718   0.93871444 0.93971103]\n",
            " [0.93871444 0.93971103 0.9407075 ]]\n",
            "1 : [0.32735426 0.32835077 0.32934728 0.3303438  0.33134031] , [[0.32835072 0.3293473  0.33034378]\n",
            " [0.3293473  0.33034378 0.33134025]\n",
            " [0.33034378 0.33134025 0.33233684]\n",
            " [0.33134025 0.33233684 0.3333333 ]\n",
            " [0.33233684 0.3333333  0.33432978]]\n",
            "2 : [0.14449427 0.14549078 0.14648729 0.14748381 0.14848032] , [[0.14549083 0.1464873  0.14748377]\n",
            " [0.1464873  0.14748377 0.14848036]\n",
            " [0.14748377 0.14848036 0.14947683]\n",
            " [0.14848036 0.14947683 0.1504733 ]\n",
            " [0.14947683 0.1504733  0.15146989]]\n",
            "3 : [0.00249128 0.00348779 0.0044843  0.00548082 0.00647733] , [[0.00348777 0.00448436 0.00548083]\n",
            " [0.00448436 0.00548083 0.0064773 ]\n",
            " [0.00548083 0.0064773  0.00747389]\n",
            " [0.0064773  0.00747389 0.00847036]\n",
            " [0.00747389 0.00847036 0.00946683]]\n",
            "4 : [0.55555556 0.55655207 0.55754858 0.55854509 0.5595416 ] , [[0.5565521  0.5575486  0.55854505]\n",
            " [0.5575486  0.55854505 0.55954164]\n",
            " [0.55854505 0.55954164 0.5605381 ]\n",
            " [0.55954164 0.5605381  0.5615346 ]\n",
            " [0.5605381  0.5615346  0.5625312 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the third dimension of input_dim=1\n",
        "x_train_norm  = x_train_norm[..., np.newaxis]\n",
        "x_val_norm    = x_val_norm[..., np.newaxis]\n",
        "x_test_norm   = x_test_norm[..., np.newaxis]\n",
        "\n",
        "print(\"\\nDimension after changed:\")\n",
        "print(f\"x_train_norm : {x_train_norm.shape}\")\n",
        "print(f\"x_val_norm : {x_val_norm.shape}\")\n",
        "print(f\"x_test_norm : {x_test_norm.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee2bf1f-4390-469c-f084-2b820e7532cf",
        "id": "r4L4cc_Pp63t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension after changed:\n",
            "x_train_norm : (1600, 5, 1)\n",
            "x_val_norm : (200, 5, 1)\n",
            "x_test_norm : (200, 5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Covert everything  to the defalt of float32\n",
        "\n",
        "x_train_norm = x_train_norm.astype(np.float32)\n",
        "y_train_norm = y_train_norm.astype(np.float32)\n",
        "x_val_norm = x_val_norm.astype(np.float32)\n",
        "y_val_norm = y_val_norm.astype(np.float32)\n",
        "x_test_norm = x_test_norm.astype(np.float32)\n",
        "y_test_norm = y_test_norm.astype(np.float32)"
      ],
      "metadata": {
        "id": "DxEDVd8ip63u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Compile and train the model"
      ],
      "metadata": {
        "id": "6eNzLTKslvpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When trainin we use losses computed from all time step, but when evaluating we only use loss computed from the last step"
      ],
      "metadata": {
        "id": "tvdNO7jO1I4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create custom metric to judge the performance of out model\n",
        "def last_time_step_mse(y_true, y_pred):\n",
        "  return tf.keras.metrics.mean_squared_error( y_true[:, -1], y_pred[:, -1])"
      ],
      "metadata": {
        "id": "fG9ze3Uy1aKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# For regression, the loss can be used as the evaluation metric as well\n",
        "ex5_rnn.compile(loss='mse', optimizer=adam, metrics=[last_time_step_mse])\n",
        "\n",
        "checkpoint_filepath = \"RNN_ex5_bestmodel_epoch{epoch:03d}.hdf5\"\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)"
      ],
      "metadata": {
        "id": "RsnpZcns09PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_ex5 = ex5_rnn.fit(x_train_norm, y_train_norm,\n",
        "                  validation_data=(x_val_norm, y_val_norm),\n",
        "                  batch_size=64, epochs=300,\n",
        "                  callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f070c0d-9e04-41c3-e57e-568a251c0987",
        "id": "tFGGyhx709PH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "25/25 [==============================] - 2s 26ms/step - loss: 0.2111 - last_time_step_mse: 0.1106 - val_loss: 0.0811 - val_last_time_step_mse: 0.0271\n",
            "Epoch 2/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0567 - last_time_step_mse: 0.0250 - val_loss: 0.0307 - val_last_time_step_mse: 0.0106\n",
            "Epoch 3/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0239 - last_time_step_mse: 0.0098 - val_loss: 0.0148 - val_last_time_step_mse: 0.0061\n",
            "Epoch 4/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.0127 - last_time_step_mse: 0.0063 - val_loss: 0.0085 - val_last_time_step_mse: 0.0041\n",
            "Epoch 5/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0080 - last_time_step_mse: 0.0042 - val_loss: 0.0058 - val_last_time_step_mse: 0.0026\n",
            "Epoch 6/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0058 - last_time_step_mse: 0.0030 - val_loss: 0.0043 - val_last_time_step_mse: 0.0020\n",
            "Epoch 7/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0044 - last_time_step_mse: 0.0024 - val_loss: 0.0033 - val_last_time_step_mse: 0.0016\n",
            "Epoch 8/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0034 - last_time_step_mse: 0.0020 - val_loss: 0.0025 - val_last_time_step_mse: 0.0013\n",
            "Epoch 9/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0027 - last_time_step_mse: 0.0015 - val_loss: 0.0020 - val_last_time_step_mse: 0.0011\n",
            "Epoch 10/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0022 - last_time_step_mse: 0.0013 - val_loss: 0.0016 - val_last_time_step_mse: 8.6869e-04\n",
            "Epoch 11/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0018 - last_time_step_mse: 0.0010 - val_loss: 0.0014 - val_last_time_step_mse: 9.0051e-04\n",
            "Epoch 12/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0015 - last_time_step_mse: 8.8044e-04 - val_loss: 0.0012 - val_last_time_step_mse: 6.3556e-04\n",
            "Epoch 13/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0013 - last_time_step_mse: 7.1213e-04 - val_loss: 0.0010 - val_last_time_step_mse: 5.1190e-04\n",
            "Epoch 14/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0011 - last_time_step_mse: 5.9814e-04 - val_loss: 8.9616e-04 - val_last_time_step_mse: 4.5653e-04\n",
            "Epoch 15/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.0010 - last_time_step_mse: 5.2533e-04 - val_loss: 7.8701e-04 - val_last_time_step_mse: 3.9112e-04\n",
            "Epoch 16/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.9526e-04 - last_time_step_mse: 4.3499e-04 - val_loss: 7.0418e-04 - val_last_time_step_mse: 3.1432e-04\n",
            "Epoch 17/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.0491e-04 - last_time_step_mse: 3.6766e-04 - val_loss: 6.3271e-04 - val_last_time_step_mse: 2.7522e-04\n",
            "Epoch 18/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 7.3486e-04 - last_time_step_mse: 3.3655e-04 - val_loss: 6.1466e-04 - val_last_time_step_mse: 3.5718e-04\n",
            "Epoch 19/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.6813e-04 - last_time_step_mse: 2.8534e-04 - val_loss: 5.3896e-04 - val_last_time_step_mse: 2.1946e-04\n",
            "Epoch 20/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.1578e-04 - last_time_step_mse: 2.5535e-04 - val_loss: 4.9875e-04 - val_last_time_step_mse: 2.0006e-04\n",
            "Epoch 21/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.6968e-04 - last_time_step_mse: 2.2230e-04 - val_loss: 4.7063e-04 - val_last_time_step_mse: 2.2467e-04\n",
            "Epoch 22/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.2763e-04 - last_time_step_mse: 1.9268e-04 - val_loss: 4.3896e-04 - val_last_time_step_mse: 1.5640e-04\n",
            "Epoch 23/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.9517e-04 - last_time_step_mse: 1.7100e-04 - val_loss: 4.0316e-04 - val_last_time_step_mse: 1.7401e-04\n",
            "Epoch 24/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4.6466e-04 - last_time_step_mse: 1.5692e-04 - val_loss: 3.7692e-04 - val_last_time_step_mse: 1.2237e-04\n",
            "Epoch 25/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4103e-04 - last_time_step_mse: 1.5008e-04 - val_loss: 3.7730e-04 - val_last_time_step_mse: 1.2680e-04\n",
            "Epoch 26/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.1551e-04 - last_time_step_mse: 1.2707e-04 - val_loss: 3.3979e-04 - val_last_time_step_mse: 9.9188e-05\n",
            "Epoch 27/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.9358e-04 - last_time_step_mse: 1.2056e-04 - val_loss: 3.1503e-04 - val_last_time_step_mse: 9.6491e-05\n",
            "Epoch 28/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 3.7285e-04 - last_time_step_mse: 1.0177e-04 - val_loss: 3.0016e-04 - val_last_time_step_mse: 8.3882e-05\n",
            "Epoch 29/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.6060e-04 - last_time_step_mse: 1.1005e-04 - val_loss: 2.9500e-04 - val_last_time_step_mse: 6.4134e-05\n",
            "Epoch 30/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.3702e-04 - last_time_step_mse: 7.8675e-05 - val_loss: 2.7352e-04 - val_last_time_step_mse: 6.0773e-05\n",
            "Epoch 31/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 3.2283e-04 - last_time_step_mse: 7.2794e-05 - val_loss: 2.6559e-04 - val_last_time_step_mse: 5.5816e-05\n",
            "Epoch 32/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.1188e-04 - last_time_step_mse: 7.9362e-05 - val_loss: 2.5398e-04 - val_last_time_step_mse: 4.9015e-05\n",
            "Epoch 33/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9852e-04 - last_time_step_mse: 6.1058e-05 - val_loss: 2.5904e-04 - val_last_time_step_mse: 8.3033e-05\n",
            "Epoch 34/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.9503e-04 - last_time_step_mse: 7.6797e-05 - val_loss: 2.3443e-04 - val_last_time_step_mse: 4.6574e-05\n",
            "Epoch 35/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.7906e-04 - last_time_step_mse: 6.2589e-05 - val_loss: 2.3398e-04 - val_last_time_step_mse: 8.1664e-05\n",
            "Epoch 36/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7581e-04 - last_time_step_mse: 7.5344e-05 - val_loss: 2.4581e-04 - val_last_time_step_mse: 1.0324e-04\n",
            "Epoch 37/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.6020e-04 - last_time_step_mse: 5.9767e-05 - val_loss: 2.0688e-04 - val_last_time_step_mse: 3.1023e-05\n",
            "Epoch 38/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 2.4433e-04 - last_time_step_mse: 4.0665e-05 - val_loss: 2.0558e-04 - val_last_time_step_mse: 3.4705e-05\n",
            "Epoch 39/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 2.3631e-04 - last_time_step_mse: 3.7909e-05 - val_loss: 1.9325e-04 - val_last_time_step_mse: 3.1751e-05\n",
            "Epoch 40/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 2.2731e-04 - last_time_step_mse: 3.2621e-05 - val_loss: 1.8840e-04 - val_last_time_step_mse: 3.3872e-05\n",
            "Epoch 41/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 2.2265e-04 - last_time_step_mse: 3.6212e-05 - val_loss: 1.8800e-04 - val_last_time_step_mse: 3.6121e-05\n",
            "Epoch 42/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 2.1646e-04 - last_time_step_mse: 3.8804e-05 - val_loss: 1.7972e-04 - val_last_time_step_mse: 3.8936e-05\n",
            "Epoch 43/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 2.0858e-04 - last_time_step_mse: 3.4097e-05 - val_loss: 1.7582e-04 - val_last_time_step_mse: 4.1922e-05\n",
            "Epoch 44/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 2.0067e-04 - last_time_step_mse: 2.9921e-05 - val_loss: 1.6776e-04 - val_last_time_step_mse: 2.0449e-05\n",
            "Epoch 45/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.9569e-04 - last_time_step_mse: 2.9054e-05 - val_loss: 1.7098e-04 - val_last_time_step_mse: 3.8664e-05\n",
            "Epoch 46/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.9154e-04 - last_time_step_mse: 2.7985e-05 - val_loss: 1.6136e-04 - val_last_time_step_mse: 3.4506e-05\n",
            "Epoch 47/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 1.8437e-04 - last_time_step_mse: 2.4575e-05 - val_loss: 1.4922e-04 - val_last_time_step_mse: 1.6397e-05\n",
            "Epoch 48/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.8178e-04 - last_time_step_mse: 3.4398e-05 - val_loss: 1.4536e-04 - val_last_time_step_mse: 1.6569e-05\n",
            "Epoch 49/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.7424e-04 - last_time_step_mse: 2.4636e-05 - val_loss: 1.4729e-04 - val_last_time_step_mse: 2.6333e-05\n",
            "Epoch 50/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 1.7024e-04 - last_time_step_mse: 2.6196e-05 - val_loss: 1.4126e-04 - val_last_time_step_mse: 1.5960e-05\n",
            "Epoch 51/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.6517e-04 - last_time_step_mse: 2.4153e-05 - val_loss: 1.3336e-04 - val_last_time_step_mse: 1.3347e-05\n",
            "Epoch 52/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6029e-04 - last_time_step_mse: 2.1863e-05 - val_loss: 1.3743e-04 - val_last_time_step_mse: 1.5654e-05\n",
            "Epoch 53/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6029e-04 - last_time_step_mse: 2.7643e-05 - val_loss: 1.4828e-04 - val_last_time_step_mse: 2.6518e-05\n",
            "Epoch 54/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5344e-04 - last_time_step_mse: 2.0088e-05 - val_loss: 1.2635e-04 - val_last_time_step_mse: 1.0008e-05\n",
            "Epoch 55/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.4740e-04 - last_time_step_mse: 1.6596e-05 - val_loss: 1.2739e-04 - val_last_time_step_mse: 2.6422e-05\n",
            "Epoch 56/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.4456e-04 - last_time_step_mse: 1.7799e-05 - val_loss: 1.2020e-04 - val_last_time_step_mse: 1.0079e-05\n",
            "Epoch 57/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 1.4118e-04 - last_time_step_mse: 1.7416e-05 - val_loss: 1.1766e-04 - val_last_time_step_mse: 1.5278e-05\n",
            "Epoch 58/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.3523e-04 - last_time_step_mse: 1.1767e-05 - val_loss: 1.1257e-04 - val_last_time_step_mse: 9.7092e-06\n",
            "Epoch 59/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 1.3265e-04 - last_time_step_mse: 1.3478e-05 - val_loss: 1.1137e-04 - val_last_time_step_mse: 1.1393e-05\n",
            "Epoch 60/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.2930e-04 - last_time_step_mse: 1.2217e-05 - val_loss: 1.1081e-04 - val_last_time_step_mse: 2.0159e-05\n",
            "Epoch 61/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.2749e-04 - last_time_step_mse: 1.3682e-05 - val_loss: 1.1119e-04 - val_last_time_step_mse: 3.2582e-05\n",
            "Epoch 62/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.2425e-04 - last_time_step_mse: 1.2534e-05 - val_loss: 1.0765e-04 - val_last_time_step_mse: 6.2577e-06\n",
            "Epoch 63/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 1.2530e-04 - last_time_step_mse: 2.1331e-05 - val_loss: 1.0651e-04 - val_last_time_step_mse: 8.7080e-06\n",
            "Epoch 64/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.1852e-04 - last_time_step_mse: 9.9720e-06 - val_loss: 1.0274e-04 - val_last_time_step_mse: 6.8556e-06\n",
            "Epoch 65/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.1617e-04 - last_time_step_mse: 1.1191e-05 - val_loss: 9.5008e-05 - val_last_time_step_mse: 5.3734e-06\n",
            "Epoch 66/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.1206e-04 - last_time_step_mse: 8.4819e-06 - val_loss: 9.3830e-05 - val_last_time_step_mse: 1.1344e-05\n",
            "Epoch 67/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.1005e-04 - last_time_step_mse: 8.1198e-06 - val_loss: 9.2690e-05 - val_last_time_step_mse: 6.6582e-06\n",
            "Epoch 68/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0842e-04 - last_time_step_mse: 9.3137e-06 - val_loss: 9.4072e-05 - val_last_time_step_mse: 1.8327e-05\n",
            "Epoch 69/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.0915e-04 - last_time_step_mse: 1.3929e-05 - val_loss: 9.3425e-05 - val_last_time_step_mse: 4.5235e-06\n",
            "Epoch 70/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.0577e-04 - last_time_step_mse: 1.4372e-05 - val_loss: 1.0488e-04 - val_last_time_step_mse: 2.2915e-05\n",
            "Epoch 71/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.0494e-04 - last_time_step_mse: 1.5111e-05 - val_loss: 8.6030e-05 - val_last_time_step_mse: 9.6463e-06\n",
            "Epoch 72/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.0107e-04 - last_time_step_mse: 1.2453e-05 - val_loss: 8.4604e-05 - val_last_time_step_mse: 4.0591e-06\n",
            "Epoch 73/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 9.7683e-05 - last_time_step_mse: 7.9093e-06 - val_loss: 8.5937e-05 - val_last_time_step_mse: 6.5479e-06\n",
            "Epoch 74/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 9.6180e-05 - last_time_step_mse: 7.7984e-06 - val_loss: 8.1868e-05 - val_last_time_step_mse: 1.1038e-05\n",
            "Epoch 75/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 9.4956e-05 - last_time_step_mse: 9.3750e-06 - val_loss: 7.8232e-05 - val_last_time_step_mse: 5.1603e-06\n",
            "Epoch 76/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.3271e-05 - last_time_step_mse: 1.0745e-05 - val_loss: 8.1798e-05 - val_last_time_step_mse: 1.5413e-05\n",
            "Epoch 77/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 9.1397e-05 - last_time_step_mse: 1.0826e-05 - val_loss: 7.6559e-05 - val_last_time_step_mse: 4.5916e-06\n",
            "Epoch 78/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.9552e-05 - last_time_step_mse: 8.5956e-06 - val_loss: 7.5864e-05 - val_last_time_step_mse: 5.2908e-06\n",
            "Epoch 79/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.8050e-05 - last_time_step_mse: 1.0060e-05 - val_loss: 7.3371e-05 - val_last_time_step_mse: 1.0124e-05\n",
            "Epoch 80/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.6614e-05 - last_time_step_mse: 1.0394e-05 - val_loss: 7.1486e-05 - val_last_time_step_mse: 4.6194e-06\n",
            "Epoch 81/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.4040e-05 - last_time_step_mse: 6.9627e-06 - val_loss: 7.2943e-05 - val_last_time_step_mse: 4.0854e-06\n",
            "Epoch 82/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.2880e-05 - last_time_step_mse: 7.0000e-06 - val_loss: 6.9373e-05 - val_last_time_step_mse: 7.5395e-06\n",
            "Epoch 83/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8.1329e-05 - last_time_step_mse: 6.8929e-06 - val_loss: 7.0230e-05 - val_last_time_step_mse: 1.4143e-05\n",
            "Epoch 84/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8.1110e-05 - last_time_step_mse: 1.1048e-05 - val_loss: 7.0633e-05 - val_last_time_step_mse: 7.8006e-06\n",
            "Epoch 85/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.9673e-05 - last_time_step_mse: 8.6920e-06 - val_loss: 6.9337e-05 - val_last_time_step_mse: 1.3692e-05\n",
            "Epoch 86/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.9799e-05 - last_time_step_mse: 1.3281e-05 - val_loss: 7.4838e-05 - val_last_time_step_mse: 3.0728e-05\n",
            "Epoch 87/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.8825e-05 - last_time_step_mse: 1.3321e-05 - val_loss: 6.6305e-05 - val_last_time_step_mse: 1.3792e-05\n",
            "Epoch 88/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.5758e-05 - last_time_step_mse: 9.2831e-06 - val_loss: 6.2605e-05 - val_last_time_step_mse: 3.4798e-06\n",
            "Epoch 89/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.4537e-05 - last_time_step_mse: 7.9973e-06 - val_loss: 6.3196e-05 - val_last_time_step_mse: 8.7466e-06\n",
            "Epoch 90/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.2874e-05 - last_time_step_mse: 7.2085e-06 - val_loss: 6.3567e-05 - val_last_time_step_mse: 3.9846e-06\n",
            "Epoch 91/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7.3745e-05 - last_time_step_mse: 1.2512e-05 - val_loss: 6.0470e-05 - val_last_time_step_mse: 1.1180e-05\n",
            "Epoch 92/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.0147e-05 - last_time_step_mse: 5.9840e-06 - val_loss: 6.5104e-05 - val_last_time_step_mse: 1.0631e-05\n",
            "Epoch 93/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.9840e-05 - last_time_step_mse: 8.9071e-06 - val_loss: 5.7012e-05 - val_last_time_step_mse: 4.3497e-06\n",
            "Epoch 94/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7.0055e-05 - last_time_step_mse: 1.2110e-05 - val_loss: 6.6508e-05 - val_last_time_step_mse: 3.5363e-05\n",
            "Epoch 95/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.8685e-05 - last_time_step_mse: 1.1276e-05 - val_loss: 5.7927e-05 - val_last_time_step_mse: 6.2860e-06\n",
            "Epoch 96/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.6185e-05 - last_time_step_mse: 5.5507e-06 - val_loss: 5.9666e-05 - val_last_time_step_mse: 1.7882e-05\n",
            "Epoch 97/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.9119e-05 - last_time_step_mse: 1.6548e-05 - val_loss: 5.9745e-05 - val_last_time_step_mse: 3.0359e-05\n",
            "Epoch 98/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.4337e-05 - last_time_step_mse: 7.5858e-06 - val_loss: 5.3233e-05 - val_last_time_step_mse: 4.5828e-06\n",
            "Epoch 99/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.4465e-05 - last_time_step_mse: 1.0632e-05 - val_loss: 5.1767e-05 - val_last_time_step_mse: 2.8281e-06\n",
            "Epoch 100/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.3497e-05 - last_time_step_mse: 9.1188e-06 - val_loss: 5.2750e-05 - val_last_time_step_mse: 9.1682e-06\n",
            "Epoch 101/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.0975e-05 - last_time_step_mse: 6.4075e-06 - val_loss: 5.0439e-05 - val_last_time_step_mse: 2.7846e-06\n",
            "Epoch 102/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.1232e-05 - last_time_step_mse: 8.6587e-06 - val_loss: 5.3151e-05 - val_last_time_step_mse: 1.2099e-05\n",
            "Epoch 103/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6.1557e-05 - last_time_step_mse: 1.1640e-05 - val_loss: 4.9913e-05 - val_last_time_step_mse: 4.5059e-06\n",
            "Epoch 104/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.0112e-05 - last_time_step_mse: 1.1713e-05 - val_loss: 5.0592e-05 - val_last_time_step_mse: 8.3028e-06\n",
            "Epoch 105/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.3243e-05 - last_time_step_mse: 2.1648e-05 - val_loss: 6.1607e-05 - val_last_time_step_mse: 3.7815e-05\n",
            "Epoch 106/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.3721e-05 - last_time_step_mse: 2.5348e-05 - val_loss: 5.7650e-05 - val_last_time_step_mse: 3.7250e-05\n",
            "Epoch 107/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.7440e-05 - last_time_step_mse: 8.9433e-06 - val_loss: 5.1147e-05 - val_last_time_step_mse: 1.2060e-05\n",
            "Epoch 108/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5.6139e-05 - last_time_step_mse: 7.0256e-06 - val_loss: 4.7228e-05 - val_last_time_step_mse: 3.9801e-06\n",
            "Epoch 109/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.5048e-05 - last_time_step_mse: 7.2195e-06 - val_loss: 5.2832e-05 - val_last_time_step_mse: 2.3806e-05\n",
            "Epoch 110/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.9807e-05 - last_time_step_mse: 2.2116e-05 - val_loss: 5.5316e-05 - val_last_time_step_mse: 4.0410e-05\n",
            "Epoch 111/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6.0858e-05 - last_time_step_mse: 2.9053e-05 - val_loss: 4.4134e-05 - val_last_time_step_mse: 3.0251e-06\n",
            "Epoch 112/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.4029e-05 - last_time_step_mse: 1.0293e-05 - val_loss: 4.8931e-05 - val_last_time_step_mse: 1.8385e-05\n",
            "Epoch 113/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.6637e-05 - last_time_step_mse: 1.9404e-05 - val_loss: 4.6195e-05 - val_last_time_step_mse: 7.8117e-06\n",
            "Epoch 114/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.0986e-05 - last_time_step_mse: 6.7225e-06 - val_loss: 4.3335e-05 - val_last_time_step_mse: 4.9552e-06\n",
            "Epoch 115/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.3717e-05 - last_time_step_mse: 1.6093e-05 - val_loss: 4.9971e-05 - val_last_time_step_mse: 2.3881e-05\n",
            "Epoch 116/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.1926e-05 - last_time_step_mse: 1.0222e-05 - val_loss: 4.1713e-05 - val_last_time_step_mse: 6.6028e-06\n",
            "Epoch 117/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.9545e-05 - last_time_step_mse: 7.9642e-06 - val_loss: 4.3409e-05 - val_last_time_step_mse: 9.0842e-06\n",
            "Epoch 118/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5.2571e-05 - last_time_step_mse: 1.9045e-05 - val_loss: 6.2681e-05 - val_last_time_step_mse: 7.4463e-05\n",
            "Epoch 119/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.5784e-05 - last_time_step_mse: 2.8576e-05 - val_loss: 4.3429e-05 - val_last_time_step_mse: 1.9175e-06\n",
            "Epoch 120/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.8989e-05 - last_time_step_mse: 1.1104e-05 - val_loss: 4.1615e-05 - val_last_time_step_mse: 1.2735e-05\n",
            "Epoch 121/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.7241e-05 - last_time_step_mse: 8.2002e-06 - val_loss: 3.8986e-05 - val_last_time_step_mse: 4.7863e-06\n",
            "Epoch 122/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.8614e-05 - last_time_step_mse: 1.2390e-05 - val_loss: 4.2102e-05 - val_last_time_step_mse: 1.1740e-05\n",
            "Epoch 123/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.8024e-05 - last_time_step_mse: 1.2202e-05 - val_loss: 4.1035e-05 - val_last_time_step_mse: 6.3443e-06\n",
            "Epoch 124/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.6930e-05 - last_time_step_mse: 9.0543e-06 - val_loss: 3.7970e-05 - val_last_time_step_mse: 2.1796e-06\n",
            "Epoch 125/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4.5550e-05 - last_time_step_mse: 1.0270e-05 - val_loss: 3.7282e-05 - val_last_time_step_mse: 5.8668e-06\n",
            "Epoch 126/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.4930e-05 - last_time_step_mse: 1.0638e-05 - val_loss: 3.5822e-05 - val_last_time_step_mse: 4.2126e-06\n",
            "Epoch 127/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.3721e-05 - last_time_step_mse: 7.3446e-06 - val_loss: 3.9647e-05 - val_last_time_step_mse: 1.6279e-05\n",
            "Epoch 128/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.2979e-05 - last_time_step_mse: 8.8743e-06 - val_loss: 3.6424e-05 - val_last_time_step_mse: 3.0599e-06\n",
            "Epoch 129/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.0857e-05 - last_time_step_mse: 5.8742e-05 - val_loss: 6.0106e-05 - val_last_time_step_mse: 9.7111e-05\n",
            "Epoch 130/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6.5666e-05 - last_time_step_mse: 7.7367e-05 - val_loss: 3.6002e-05 - val_last_time_step_mse: 1.5649e-06\n",
            "Epoch 131/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.3673e-05 - last_time_step_mse: 1.3349e-05 - val_loss: 3.4294e-05 - val_last_time_step_mse: 4.3763e-06\n",
            "Epoch 132/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.0882e-05 - last_time_step_mse: 6.3706e-06 - val_loss: 3.5241e-05 - val_last_time_step_mse: 6.4954e-06\n",
            "Epoch 133/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.2044e-05 - last_time_step_mse: 1.2514e-05 - val_loss: 4.7094e-05 - val_last_time_step_mse: 3.9744e-05\n",
            "Epoch 134/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.8527e-05 - last_time_step_mse: 2.9083e-05 - val_loss: 4.8276e-05 - val_last_time_step_mse: 5.8524e-05\n",
            "Epoch 135/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.6193e-05 - last_time_step_mse: 2.6560e-05 - val_loss: 3.5027e-05 - val_last_time_step_mse: 7.4948e-06\n",
            "Epoch 136/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.1213e-05 - last_time_step_mse: 1.4189e-05 - val_loss: 3.9061e-05 - val_last_time_step_mse: 1.2559e-05\n",
            "Epoch 137/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.0145e-05 - last_time_step_mse: 1.1123e-05 - val_loss: 3.2833e-05 - val_last_time_step_mse: 7.5821e-06\n",
            "Epoch 138/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.7211e-05 - last_time_step_mse: 4.2664e-06 - val_loss: 3.3586e-05 - val_last_time_step_mse: 9.5398e-06\n",
            "Epoch 139/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.7392e-05 - last_time_step_mse: 6.8846e-06 - val_loss: 3.0313e-05 - val_last_time_step_mse: 1.4978e-06\n",
            "Epoch 140/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6328e-05 - last_time_step_mse: 5.3285e-06 - val_loss: 3.4139e-05 - val_last_time_step_mse: 1.0293e-05\n",
            "Epoch 141/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.3817e-05 - last_time_step_mse: 2.6139e-05 - val_loss: 3.9441e-05 - val_last_time_step_mse: 3.1946e-05\n",
            "Epoch 142/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.0313e-05 - last_time_step_mse: 1.5282e-05 - val_loss: 3.2139e-05 - val_last_time_step_mse: 7.4808e-06\n",
            "Epoch 143/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.0243e-05 - last_time_step_mse: 1.8100e-05 - val_loss: 2.8891e-05 - val_last_time_step_mse: 3.4852e-06\n",
            "Epoch 144/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.7282e-05 - last_time_step_mse: 1.1776e-05 - val_loss: 2.8843e-05 - val_last_time_step_mse: 1.7918e-06\n",
            "Epoch 145/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.8362e-05 - last_time_step_mse: 1.6407e-05 - val_loss: 4.4136e-05 - val_last_time_step_mse: 4.6168e-05\n",
            "Epoch 146/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9698e-05 - last_time_step_mse: 2.0162e-05 - val_loss: 3.1113e-05 - val_last_time_step_mse: 8.9783e-06\n",
            "Epoch 147/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9730e-05 - last_time_step_mse: 1.9631e-05 - val_loss: 3.6850e-05 - val_last_time_step_mse: 3.2996e-05\n",
            "Epoch 148/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.8606e-05 - last_time_step_mse: 4.7012e-05 - val_loss: 5.7589e-05 - val_last_time_step_mse: 8.4487e-05\n",
            "Epoch 149/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.3067e-05 - last_time_step_mse: 3.1261e-05 - val_loss: 3.1814e-05 - val_last_time_step_mse: 1.5242e-05\n",
            "Epoch 150/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6342e-05 - last_time_step_mse: 1.4765e-05 - val_loss: 4.5939e-05 - val_last_time_step_mse: 6.4510e-05\n",
            "Epoch 151/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.8656e-05 - last_time_step_mse: 2.2227e-05 - val_loss: 3.2457e-05 - val_last_time_step_mse: 1.3869e-05\n",
            "Epoch 152/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.7503e-05 - last_time_step_mse: 1.9147e-05 - val_loss: 2.8902e-05 - val_last_time_step_mse: 7.0179e-06\n",
            "Epoch 153/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.2021e-05 - last_time_step_mse: 3.4825e-05 - val_loss: 3.2323e-05 - val_last_time_step_mse: 2.0472e-05\n",
            "Epoch 154/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4.3721e-05 - last_time_step_mse: 3.7969e-05 - val_loss: 4.5211e-05 - val_last_time_step_mse: 4.5833e-05\n",
            "Epoch 155/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.2336e-05 - last_time_step_mse: 9.6818e-06 - val_loss: 2.7332e-05 - val_last_time_step_mse: 2.1656e-06\n",
            "Epoch 156/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.1035e-05 - last_time_step_mse: 7.3530e-06 - val_loss: 2.7970e-05 - val_last_time_step_mse: 8.2241e-06\n",
            "Epoch 157/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.5226e-05 - last_time_step_mse: 1.8553e-05 - val_loss: 2.5149e-05 - val_last_time_step_mse: 2.4354e-06\n",
            "Epoch 158/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6188e-05 - last_time_step_mse: 2.0586e-05 - val_loss: 3.9076e-05 - val_last_time_step_mse: 3.0518e-05\n",
            "Epoch 159/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 3.6837e-05 - last_time_step_mse: 2.4468e-05 - val_loss: 2.4342e-05 - val_last_time_step_mse: 2.2292e-06\n",
            "Epoch 160/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.9253e-05 - last_time_step_mse: 4.9031e-06 - val_loss: 2.3680e-05 - val_last_time_step_mse: 5.7435e-07\n",
            "Epoch 161/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.2194e-05 - last_time_step_mse: 1.4520e-05 - val_loss: 2.6413e-05 - val_last_time_step_mse: 1.0876e-05\n",
            "Epoch 162/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.2467e-05 - last_time_step_mse: 1.4629e-05 - val_loss: 2.4183e-05 - val_last_time_step_mse: 5.4450e-06\n",
            "Epoch 163/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.1160e-05 - last_time_step_mse: 1.3759e-05 - val_loss: 2.7488e-05 - val_last_time_step_mse: 1.2621e-05\n",
            "Epoch 164/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 3.5717e-05 - last_time_step_mse: 2.6156e-05 - val_loss: 2.3386e-05 - val_last_time_step_mse: 4.5944e-06\n",
            "Epoch 165/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 3.6858e-05 - last_time_step_mse: 3.0878e-05 - val_loss: 2.3327e-05 - val_last_time_step_mse: 4.9296e-06\n",
            "Epoch 166/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8815e-05 - last_time_step_mse: 9.4947e-06 - val_loss: 3.1251e-05 - val_last_time_step_mse: 2.4776e-05\n",
            "Epoch 167/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.0189e-05 - last_time_step_mse: 3.8251e-05 - val_loss: 2.6951e-05 - val_last_time_step_mse: 1.3070e-05\n",
            "Epoch 168/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 3.0230e-05 - last_time_step_mse: 1.2861e-05 - val_loss: 2.1730e-05 - val_last_time_step_mse: 2.3542e-06\n",
            "Epoch 169/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7769e-05 - last_time_step_mse: 7.7909e-06 - val_loss: 2.2674e-05 - val_last_time_step_mse: 2.7343e-06\n",
            "Epoch 170/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7008e-05 - last_time_step_mse: 6.5451e-06 - val_loss: 2.7484e-05 - val_last_time_step_mse: 2.3079e-05\n",
            "Epoch 171/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.0873e-05 - last_time_step_mse: 4.2638e-05 - val_loss: 3.5631e-05 - val_last_time_step_mse: 4.5725e-05\n",
            "Epoch 172/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9062e-05 - last_time_step_mse: 1.3436e-05 - val_loss: 2.3221e-05 - val_last_time_step_mse: 6.4315e-06\n",
            "Epoch 173/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.5969e-05 - last_time_step_mse: 6.5144e-06 - val_loss: 2.1297e-05 - val_last_time_step_mse: 1.5999e-06\n",
            "Epoch 174/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.2971e-05 - last_time_step_mse: 2.5124e-05 - val_loss: 6.5304e-05 - val_last_time_step_mse: 1.3066e-04\n",
            "Epoch 175/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.9417e-05 - last_time_step_mse: 7.0433e-05 - val_loss: 2.6299e-05 - val_last_time_step_mse: 2.0815e-05\n",
            "Epoch 176/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8781e-05 - last_time_step_mse: 1.5151e-05 - val_loss: 2.3285e-05 - val_last_time_step_mse: 1.1381e-05\n",
            "Epoch 177/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.6286e-05 - last_time_step_mse: 1.0856e-05 - val_loss: 2.4787e-05 - val_last_time_step_mse: 8.1570e-06\n",
            "Epoch 178/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.5963e-05 - last_time_step_mse: 9.2068e-06 - val_loss: 2.2438e-05 - val_last_time_step_mse: 7.5865e-06\n",
            "Epoch 179/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.6753e-05 - last_time_step_mse: 1.2800e-05 - val_loss: 2.1005e-05 - val_last_time_step_mse: 5.6004e-06\n",
            "Epoch 180/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.4131e-05 - last_time_step_mse: 6.5850e-06 - val_loss: 1.9881e-05 - val_last_time_step_mse: 3.8444e-06\n",
            "Epoch 181/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.7231e-05 - last_time_step_mse: 1.4664e-05 - val_loss: 2.8724e-05 - val_last_time_step_mse: 2.8655e-05\n",
            "Epoch 182/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.3043e-05 - last_time_step_mse: 2.9683e-05 - val_loss: 2.1073e-05 - val_last_time_step_mse: 1.7301e-06\n",
            "Epoch 183/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.2391e-05 - last_time_step_mse: 2.7245e-05 - val_loss: 3.2992e-05 - val_last_time_step_mse: 2.2602e-05\n",
            "Epoch 184/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8933e-05 - last_time_step_mse: 2.0349e-05 - val_loss: 2.2871e-05 - val_last_time_step_mse: 1.2002e-05\n",
            "Epoch 185/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.9709e-05 - last_time_step_mse: 2.1641e-05 - val_loss: 3.8607e-05 - val_last_time_step_mse: 6.3659e-05\n",
            "Epoch 186/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.9355e-05 - last_time_step_mse: 2.3836e-05 - val_loss: 1.8295e-05 - val_last_time_step_mse: 5.8321e-07\n",
            "Epoch 187/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.5616e-05 - last_time_step_mse: 1.3011e-05 - val_loss: 2.3123e-05 - val_last_time_step_mse: 1.6163e-05\n",
            "Epoch 188/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.5549e-05 - last_time_step_mse: 1.3739e-05 - val_loss: 2.7648e-05 - val_last_time_step_mse: 3.0923e-05\n",
            "Epoch 189/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.6644e-05 - last_time_step_mse: 1.4791e-05 - val_loss: 2.0101e-05 - val_last_time_step_mse: 5.2126e-06\n",
            "Epoch 190/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.2388e-05 - last_time_step_mse: 6.5828e-06 - val_loss: 2.0021e-05 - val_last_time_step_mse: 8.2447e-06\n",
            "Epoch 191/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.5054e-05 - last_time_step_mse: 1.4740e-05 - val_loss: 1.8105e-05 - val_last_time_step_mse: 2.4298e-06\n",
            "Epoch 192/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.3599e-05 - last_time_step_mse: 3.8920e-05 - val_loss: 2.6327e-05 - val_last_time_step_mse: 2.0948e-05\n",
            "Epoch 193/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8030e-05 - last_time_step_mse: 2.2033e-05 - val_loss: 2.3571e-05 - val_last_time_step_mse: 1.1605e-05\n",
            "Epoch 194/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.2965e-05 - last_time_step_mse: 1.0604e-05 - val_loss: 1.7349e-05 - val_last_time_step_mse: 5.0869e-07\n",
            "Epoch 195/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.2851e-05 - last_time_step_mse: 1.0118e-05 - val_loss: 1.6467e-05 - val_last_time_step_mse: 1.9875e-06\n",
            "Epoch 196/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.0921e-05 - last_time_step_mse: 5.3156e-06 - val_loss: 1.7293e-05 - val_last_time_step_mse: 4.3558e-06\n",
            "Epoch 197/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.4231e-05 - last_time_step_mse: 1.5998e-05 - val_loss: 8.0574e-05 - val_last_time_step_mse: 1.7478e-04\n",
            "Epoch 198/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.1091e-05 - last_time_step_mse: 8.7780e-05 - val_loss: 4.2556e-05 - val_last_time_step_mse: 6.1081e-05\n",
            "Epoch 199/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.5156e-05 - last_time_step_mse: 1.8729e-05 - val_loss: 1.7962e-05 - val_last_time_step_mse: 2.9897e-06\n",
            "Epoch 200/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9299e-05 - last_time_step_mse: 3.6305e-06 - val_loss: 2.0844e-05 - val_last_time_step_mse: 1.7569e-05\n",
            "Epoch 201/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.0249e-05 - last_time_step_mse: 5.8443e-06 - val_loss: 2.0323e-05 - val_last_time_step_mse: 1.3522e-05\n",
            "Epoch 202/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1354e-05 - last_time_step_mse: 9.7232e-06 - val_loss: 1.9254e-05 - val_last_time_step_mse: 1.2451e-05\n",
            "Epoch 203/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.3800e-05 - last_time_step_mse: 1.5246e-05 - val_loss: 1.6869e-05 - val_last_time_step_mse: 6.1034e-06\n",
            "Epoch 204/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.6877e-05 - last_time_step_mse: 2.5075e-05 - val_loss: 1.8475e-05 - val_last_time_step_mse: 9.7985e-06\n",
            "Epoch 205/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1764e-05 - last_time_step_mse: 1.1424e-05 - val_loss: 1.9493e-05 - val_last_time_step_mse: 1.1142e-05\n",
            "Epoch 206/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.0177e-05 - last_time_step_mse: 9.1931e-06 - val_loss: 2.0166e-05 - val_last_time_step_mse: 9.1248e-06\n",
            "Epoch 207/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.5829e-05 - last_time_step_mse: 4.9531e-05 - val_loss: 2.4877e-05 - val_last_time_step_mse: 3.2637e-05\n",
            "Epoch 208/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5.4877e-05 - last_time_step_mse: 1.0438e-04 - val_loss: 1.7011e-05 - val_last_time_step_mse: 9.8590e-06\n",
            "Epoch 209/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1517e-05 - last_time_step_mse: 1.4132e-05 - val_loss: 1.6690e-05 - val_last_time_step_mse: 2.4938e-06\n",
            "Epoch 210/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.8448e-05 - last_time_step_mse: 4.6653e-06 - val_loss: 1.5542e-05 - val_last_time_step_mse: 3.5509e-06\n",
            "Epoch 211/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.8004e-05 - last_time_step_mse: 4.3647e-06 - val_loss: 1.4110e-05 - val_last_time_step_mse: 4.6687e-07\n",
            "Epoch 212/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1142e-05 - last_time_step_mse: 1.4603e-05 - val_loss: 1.5982e-05 - val_last_time_step_mse: 4.5660e-06\n",
            "Epoch 213/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9310e-05 - last_time_step_mse: 8.4951e-06 - val_loss: 2.5244e-05 - val_last_time_step_mse: 1.8337e-05\n",
            "Epoch 214/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.0312e-05 - last_time_step_mse: 1.1136e-05 - val_loss: 1.5168e-05 - val_last_time_step_mse: 3.6796e-06\n",
            "Epoch 215/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7362e-05 - last_time_step_mse: 4.3706e-06 - val_loss: 1.4322e-05 - val_last_time_step_mse: 1.4244e-06\n",
            "Epoch 216/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.0507e-05 - last_time_step_mse: 1.4230e-05 - val_loss: 2.0019e-05 - val_last_time_step_mse: 1.9115e-05\n",
            "Epoch 217/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.4527e-05 - last_time_step_mse: 2.5190e-05 - val_loss: 3.4859e-05 - val_last_time_step_mse: 5.0475e-05\n",
            "Epoch 218/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8254e-05 - last_time_step_mse: 3.4035e-05 - val_loss: 1.5903e-05 - val_last_time_step_mse: 4.6602e-06\n",
            "Epoch 219/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.3070e-05 - last_time_step_mse: 1.8512e-05 - val_loss: 2.4583e-05 - val_last_time_step_mse: 2.4824e-05\n",
            "Epoch 220/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9958e-05 - last_time_step_mse: 1.2991e-05 - val_loss: 3.6361e-05 - val_last_time_step_mse: 5.6257e-05\n",
            "Epoch 221/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9936e-05 - last_time_step_mse: 1.3155e-05 - val_loss: 1.7117e-05 - val_last_time_step_mse: 2.8878e-06\n",
            "Epoch 222/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.3296e-05 - last_time_step_mse: 2.1496e-05 - val_loss: 1.8113e-05 - val_last_time_step_mse: 1.1987e-05\n",
            "Epoch 223/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1095e-05 - last_time_step_mse: 1.6363e-05 - val_loss: 1.4532e-05 - val_last_time_step_mse: 3.8676e-06\n",
            "Epoch 224/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5705e-05 - last_time_step_mse: 3.6215e-06 - val_loss: 1.6589e-05 - val_last_time_step_mse: 1.0151e-05\n",
            "Epoch 225/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5940e-05 - last_time_step_mse: 4.5683e-06 - val_loss: 1.5706e-05 - val_last_time_step_mse: 7.5161e-06\n",
            "Epoch 226/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7275e-05 - last_time_step_mse: 9.1980e-06 - val_loss: 1.4557e-05 - val_last_time_step_mse: 5.8957e-06\n",
            "Epoch 227/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.6431e-05 - last_time_step_mse: 6.0099e-05 - val_loss: 6.3940e-05 - val_last_time_step_mse: 1.2534e-04\n",
            "Epoch 228/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 3.9677e-05 - last_time_step_mse: 6.9575e-05 - val_loss: 3.3483e-05 - val_last_time_step_mse: 6.0556e-05\n",
            "Epoch 229/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.3267e-05 - last_time_step_mse: 2.4615e-05 - val_loss: 1.5075e-05 - val_last_time_step_mse: 6.8171e-06\n",
            "Epoch 230/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5575e-05 - last_time_step_mse: 4.7726e-06 - val_loss: 1.3398e-05 - val_last_time_step_mse: 3.7571e-06\n",
            "Epoch 231/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5110e-05 - last_time_step_mse: 3.9319e-06 - val_loss: 1.4508e-05 - val_last_time_step_mse: 4.1211e-06\n",
            "Epoch 232/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6585e-05 - last_time_step_mse: 8.9798e-06 - val_loss: 2.4930e-05 - val_last_time_step_mse: 3.6821e-05\n",
            "Epoch 233/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.7214e-05 - last_time_step_mse: 9.9656e-06 - val_loss: 1.3050e-05 - val_last_time_step_mse: 3.5840e-06\n",
            "Epoch 234/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7954e-05 - last_time_step_mse: 1.2593e-05 - val_loss: 1.9917e-05 - val_last_time_step_mse: 2.2381e-05\n",
            "Epoch 235/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.0786e-05 - last_time_step_mse: 2.0674e-05 - val_loss: 2.5304e-05 - val_last_time_step_mse: 2.5657e-05\n",
            "Epoch 236/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.6306e-05 - last_time_step_mse: 3.1156e-05 - val_loss: 1.4197e-05 - val_last_time_step_mse: 1.0376e-05\n",
            "Epoch 237/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.5273e-05 - last_time_step_mse: 3.1770e-05 - val_loss: 5.7906e-05 - val_last_time_step_mse: 1.2588e-04\n",
            "Epoch 238/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.6167e-05 - last_time_step_mse: 3.6104e-05 - val_loss: 1.8757e-05 - val_last_time_step_mse: 1.8948e-05\n",
            "Epoch 239/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.8464e-05 - last_time_step_mse: 1.4928e-05 - val_loss: 1.3001e-05 - val_last_time_step_mse: 4.3863e-06\n",
            "Epoch 240/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8491e-05 - last_time_step_mse: 1.5567e-05 - val_loss: 1.6287e-05 - val_last_time_step_mse: 1.2452e-05\n",
            "Epoch 241/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8409e-05 - last_time_step_mse: 1.5642e-05 - val_loss: 1.4204e-05 - val_last_time_step_mse: 8.1389e-06\n",
            "Epoch 242/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9055e-05 - last_time_step_mse: 1.9024e-05 - val_loss: 1.8870e-05 - val_last_time_step_mse: 1.5788e-05\n",
            "Epoch 243/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8436e-05 - last_time_step_mse: 1.3830e-05 - val_loss: 1.4314e-05 - val_last_time_step_mse: 8.4473e-06\n",
            "Epoch 244/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8650e-05 - last_time_step_mse: 1.6527e-05 - val_loss: 1.5102e-05 - val_last_time_step_mse: 1.3900e-05\n",
            "Epoch 245/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5038e-05 - last_time_step_mse: 7.4416e-06 - val_loss: 1.3293e-05 - val_last_time_step_mse: 8.3332e-06\n",
            "Epoch 246/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.4645e-05 - last_time_step_mse: 7.9935e-06 - val_loss: 1.2834e-05 - val_last_time_step_mse: 5.8797e-06\n",
            "Epoch 247/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5970e-05 - last_time_step_mse: 9.7973e-06 - val_loss: 2.1282e-05 - val_last_time_step_mse: 3.1233e-05\n",
            "Epoch 248/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.4427e-05 - last_time_step_mse: 6.2796e-06 - val_loss: 1.0161e-05 - val_last_time_step_mse: 4.7770e-07\n",
            "Epoch 249/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9201e-05 - last_time_step_mse: 1.9071e-05 - val_loss: 1.5243e-05 - val_last_time_step_mse: 1.7686e-05\n",
            "Epoch 250/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8998e-05 - last_time_step_mse: 4.6524e-05 - val_loss: 3.1798e-05 - val_last_time_step_mse: 5.9987e-05\n",
            "Epoch 251/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.0722e-05 - last_time_step_mse: 2.4855e-05 - val_loss: 1.2534e-05 - val_last_time_step_mse: 1.0156e-05\n",
            "Epoch 252/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.3700e-05 - last_time_step_mse: 6.7945e-06 - val_loss: 1.8109e-05 - val_last_time_step_mse: 1.5182e-05\n",
            "Epoch 253/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4845e-05 - last_time_step_mse: 8.1875e-06 - val_loss: 1.4806e-05 - val_last_time_step_mse: 1.7214e-05\n",
            "Epoch 254/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.2613e-05 - last_time_step_mse: 2.8661e-05 - val_loss: 3.8933e-05 - val_last_time_step_mse: 7.1650e-05\n",
            "Epoch 255/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8643e-05 - last_time_step_mse: 4.6393e-05 - val_loss: 2.5367e-05 - val_last_time_step_mse: 4.7839e-05\n",
            "Epoch 256/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.7810e-05 - last_time_step_mse: 1.8810e-05 - val_loss: 1.5518e-05 - val_last_time_step_mse: 1.6463e-05\n",
            "Epoch 257/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8257e-05 - last_time_step_mse: 1.9993e-05 - val_loss: 1.6580e-05 - val_last_time_step_mse: 1.6305e-05\n",
            "Epoch 258/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8593e-05 - last_time_step_mse: 2.0644e-05 - val_loss: 2.2507e-05 - val_last_time_step_mse: 3.3287e-05\n",
            "Epoch 259/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.5839e-05 - last_time_step_mse: 1.1972e-05 - val_loss: 1.2827e-05 - val_last_time_step_mse: 8.7581e-06\n",
            "Epoch 260/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.3004e-05 - last_time_step_mse: 6.1989e-06 - val_loss: 1.0396e-05 - val_last_time_step_mse: 3.7744e-06\n",
            "Epoch 261/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5208e-05 - last_time_step_mse: 1.2663e-05 - val_loss: 1.9892e-05 - val_last_time_step_mse: 2.5115e-05\n",
            "Epoch 262/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5317e-05 - last_time_step_mse: 1.1418e-05 - val_loss: 1.4849e-05 - val_last_time_step_mse: 1.5077e-05\n",
            "Epoch 263/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1694e-05 - last_time_step_mse: 4.4068e-06 - val_loss: 1.3205e-05 - val_last_time_step_mse: 1.4047e-05\n",
            "Epoch 264/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.5717e-05 - last_time_step_mse: 1.4183e-05 - val_loss: 4.2742e-05 - val_last_time_step_mse: 7.7899e-05\n",
            "Epoch 265/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.1525e-05 - last_time_step_mse: 2.8073e-05 - val_loss: 1.7668e-05 - val_last_time_step_mse: 1.8155e-05\n",
            "Epoch 266/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.6151e-05 - last_time_step_mse: 1.4810e-05 - val_loss: 1.0153e-05 - val_last_time_step_mse: 4.7571e-06\n",
            "Epoch 267/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.5382e-05 - last_time_step_mse: 1.2623e-05 - val_loss: 9.9564e-06 - val_last_time_step_mse: 6.5693e-06\n",
            "Epoch 268/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1752e-05 - last_time_step_mse: 4.7671e-06 - val_loss: 8.9847e-06 - val_last_time_step_mse: 1.3353e-06\n",
            "Epoch 269/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1286e-05 - last_time_step_mse: 3.2786e-06 - val_loss: 1.5979e-05 - val_last_time_step_mse: 1.5515e-05\n",
            "Epoch 270/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6717e-05 - last_time_step_mse: 1.8506e-05 - val_loss: 1.3450e-05 - val_last_time_step_mse: 1.0803e-05\n",
            "Epoch 271/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.3942e-05 - last_time_step_mse: 1.1193e-05 - val_loss: 1.6691e-05 - val_last_time_step_mse: 3.2423e-05\n",
            "Epoch 272/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.8162e-05 - last_time_step_mse: 4.6286e-05 - val_loss: 1.4426e-05 - val_last_time_step_mse: 2.0444e-05\n",
            "Epoch 273/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.0007e-05 - last_time_step_mse: 2.5881e-05 - val_loss: 1.1670e-05 - val_last_time_step_mse: 1.4253e-06\n",
            "Epoch 274/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.3354e-05 - last_time_step_mse: 8.7759e-06 - val_loss: 1.3359e-05 - val_last_time_step_mse: 5.7170e-06\n",
            "Epoch 275/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.5748e-05 - last_time_step_mse: 1.5970e-05 - val_loss: 1.3103e-05 - val_last_time_step_mse: 1.8372e-05\n",
            "Epoch 276/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.8509e-05 - last_time_step_mse: 2.5102e-05 - val_loss: 1.6473e-05 - val_last_time_step_mse: 2.3248e-05\n",
            "Epoch 277/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4676e-05 - last_time_step_mse: 1.6367e-05 - val_loss: 1.2253e-05 - val_last_time_step_mse: 1.0421e-05\n",
            "Epoch 278/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.4693e-05 - last_time_step_mse: 1.3345e-05 - val_loss: 8.9033e-06 - val_last_time_step_mse: 1.9145e-06\n",
            "Epoch 279/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.0143e-05 - last_time_step_mse: 2.9316e-06 - val_loss: 9.5468e-06 - val_last_time_step_mse: 4.6764e-06\n",
            "Epoch 280/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2217e-05 - last_time_step_mse: 8.2155e-06 - val_loss: 9.2402e-06 - val_last_time_step_mse: 4.5561e-06\n",
            "Epoch 281/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1287e-05 - last_time_step_mse: 5.9839e-06 - val_loss: 9.1072e-06 - val_last_time_step_mse: 1.5069e-06\n",
            "Epoch 282/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1184e-05 - last_time_step_mse: 6.3143e-06 - val_loss: 1.0149e-05 - val_last_time_step_mse: 8.9016e-06\n",
            "Epoch 283/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.6177e-05 - last_time_step_mse: 2.0140e-05 - val_loss: 2.1569e-05 - val_last_time_step_mse: 3.7184e-05\n",
            "Epoch 284/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.3007e-05 - last_time_step_mse: 3.7189e-05 - val_loss: 1.8590e-05 - val_last_time_step_mse: 3.4926e-05\n",
            "Epoch 285/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 2.2178e-05 - last_time_step_mse: 3.3336e-05 - val_loss: 8.7378e-06 - val_last_time_step_mse: 2.3914e-06\n",
            "Epoch 286/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2666e-05 - last_time_step_mse: 1.0225e-05 - val_loss: 9.7136e-06 - val_last_time_step_mse: 7.2763e-06\n",
            "Epoch 287/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2318e-05 - last_time_step_mse: 1.0214e-05 - val_loss: 1.2224e-05 - val_last_time_step_mse: 1.0967e-05\n",
            "Epoch 288/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4795e-05 - last_time_step_mse: 1.4964e-05 - val_loss: 3.2247e-05 - val_last_time_step_mse: 7.3972e-05\n",
            "Epoch 289/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9521e-05 - last_time_step_mse: 2.9747e-05 - val_loss: 1.8613e-05 - val_last_time_step_mse: 2.8210e-05\n",
            "Epoch 290/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4385e-05 - last_time_step_mse: 1.5859e-05 - val_loss: 2.0831e-05 - val_last_time_step_mse: 3.2537e-05\n",
            "Epoch 291/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.3066e-05 - last_time_step_mse: 1.2300e-05 - val_loss: 1.7518e-05 - val_last_time_step_mse: 1.9847e-05\n",
            "Epoch 292/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.4669e-05 - last_time_step_mse: 4.2425e-05 - val_loss: 5.6300e-05 - val_last_time_step_mse: 1.5207e-04\n",
            "Epoch 293/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.9564e-05 - last_time_step_mse: 3.1769e-05 - val_loss: 1.4689e-05 - val_last_time_step_mse: 1.7202e-05\n",
            "Epoch 294/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1525e-05 - last_time_step_mse: 9.5195e-06 - val_loss: 8.4892e-06 - val_last_time_step_mse: 4.0708e-06\n",
            "Epoch 295/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.4595e-05 - last_time_step_mse: 1.7577e-05 - val_loss: 9.2187e-06 - val_last_time_step_mse: 3.1510e-06\n",
            "Epoch 296/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1891e-05 - last_time_step_mse: 9.6222e-06 - val_loss: 1.2994e-05 - val_last_time_step_mse: 1.5377e-05\n",
            "Epoch 297/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.2380e-05 - last_time_step_mse: 1.1509e-05 - val_loss: 9.7390e-06 - val_last_time_step_mse: 5.1736e-06\n",
            "Epoch 298/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 1.0040e-05 - last_time_step_mse: 6.0135e-06 - val_loss: 7.7577e-06 - val_last_time_step_mse: 1.9668e-06\n",
            "Epoch 299/300\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 1.1024e-05 - last_time_step_mse: 9.1928e-06 - val_loss: 7.6619e-06 - val_last_time_step_mse: 1.1740e-06\n",
            "Epoch 300/300\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.0243e-06 - last_time_step_mse: 3.2393e-06 - val_loss: 1.0077e-05 - val_last_time_step_mse: 1.1095e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training and validation loss values\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot( hist_ex5.history['loss'])\n",
        "plt.plot( hist_ex5.history['val_loss'])\n",
        "plt.title('Model loss mean squared error')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train','val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "4b02fbb7-888e-487b-84c6-c08011467c50",
        "id": "3y9UTY7609PI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training and validation loss values\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot( hist_ex5.history['last_time_step_mse'])\n",
        "plt.plot( hist_ex5.history['val_last_time_step_mse'])\n",
        "plt.title('Model evaluate : last_time_step_mse')\n",
        "plt.ylabel('last_time_step_mse')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train','val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "fBEHHuEf69_E",
        "outputId": "50c76a59-a305-411f-91ac-dda1f333f184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Evaluate the model"
      ],
      "metadata": {
        "id": "gKbZjYwN7g2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the best epoch (minimum val_loss)\n",
        "bestmodel_file = max([ f for f in os.listdir(\".\") if f.startswith('RNN_ex5_bestmodel_') and f.endswith(\".hdf5\")])\n",
        "print( f\"The best model : {bestmodel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756d2d18-0b19-4dbb-de30-b7936a20234d",
        "id": "RmdwDxSp7yGP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model : RNN_ex5_bestmodel_epoch299.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex5_rnn_best = tf.keras.models.load_model(bestmodel_file, compile=True \n",
        "                                          ,custom_objects={\"last_time_step_mse\":last_time_step_mse})"
      ],
      "metadata": {
        "id": "WJu6Ak577yGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from last epoch\n",
        "score = ex5_rnn.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the last epoch) :{[(ex5_rnn.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the last epoch) :{[(ex5_rnn.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba478d-df32-4341-a316-4fd0fe137ff7",
        "id": "WtXra_PH7yGP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 1.0543169992160983e-05), ('last_time_step_mse', 1.128229996538721e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from best epoch\n",
        "score = ex5_rnn_best.evaluate(x_test_norm, y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the best epoch) :{[(ex5_rnn_best.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the best epoch) :{[(ex5_rnn_best.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d39843-76eb-4daa-bfd2-b9644f4af022",
        "id": "Zw-zlFn07yGQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the best epoch) :[('loss', 8.073094249994028e-06), ('last_time_step_mse', 1.4510791288557812e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Inference"
      ],
      "metadata": {
        "id": "QZ2Qy0oelwqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_predict = ex5_rnn.predict(x_test_norm)[:,-1,:]\n",
        "y2_test_predict = ex5_rnn_best.predict(x_test_norm)[:,-1,:]\n",
        "\n",
        "# Denormalize to raw value\n",
        "y1_inv = minmax_norm.inverse_transform(y1_test_predict)\n",
        "y2_inv = minmax_norm.inverse_transform(y2_test_predict)"
      ],
      "metadata": {
        "id": "JB8bXDNX8iWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(f\"x_test[{i}] = {x_test[i].reshape(-1)}, y_test[{i}] = {y_test[i][-1]}, predict--> last_epoch({np.around(y1_inv[i])}) best_epoch({np.around(y2_inv[i])})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef67e4d-a86d-404b-838a-f938e51bae07",
        "id": "KfZ4y4sf8iWK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test[0] = [-2126 -2124 -2122 -2120 -2118], y_test[0] = [-2116. -2114. -2112.], predict--> last_epoch([-2112. -2109. -2100.]) best_epoch([-2112. -2112. -2114.])\n",
            "x_test[1] = [-3343 -3341 -3339 -3337 -3335], y_test[1] = [-3333. -3331. -3329.], predict--> last_epoch([-3331. -3328. -3320.]) best_epoch([-3333. -3331. -3332.])\n",
            "x_test[2] = [-3710 -3708 -3706 -3704 -3702], y_test[2] = [-3700. -3698. -3696.], predict--> last_epoch([-3698. -3696. -3688.]) best_epoch([-3703. -3701. -3699.])\n",
            "x_test[3] = [-3995 -3993 -3991 -3989 -3987], y_test[3] = [-3985. -3983. -3981.], predict--> last_epoch([-3985. -3983. -3974.]) best_epoch([-3990. -3987. -3986.])\n",
            "x_test[4] = [-2885 -2883 -2881 -2879 -2877], y_test[4] = [-2875. -2873. -2871.], predict--> last_epoch([-2872. -2869. -2861.]) best_epoch([-2874. -2872. -2872.])\n",
            "x_test[5] = [-2148 -2146 -2144 -2142 -2140], y_test[5] = [-2138. -2136. -2134.], predict--> last_epoch([-2132. -2129. -2122.]) best_epoch([-2133. -2134. -2135.])\n",
            "x_test[6] = [-3022 -3020 -3018 -3016 -3014], y_test[6] = [-3012. -3010. -3008.], predict--> last_epoch([-3008. -3006. -2998.]) best_epoch([-3011. -3010. -3011.])\n",
            "x_test[7] = [-2034 -2032 -2030 -2028 -2026], y_test[7] = [-2024. -2022. -2020.], predict--> last_epoch([-2019. -2015. -2006.]) best_epoch([-2021. -2021. -2020.])\n",
            "x_test[8] = [-3707 -3705 -3703 -3701 -3699], y_test[8] = [-3697. -3695. -3693.], predict--> last_epoch([-3695. -3692. -3685.]) best_epoch([-3700. -3698. -3696.])\n",
            "x_test[9] = [-3232 -3230 -3228 -3226 -3224], y_test[9] = [-3222. -3220. -3218.], predict--> last_epoch([-3219. -3217. -3209.]) best_epoch([-3222. -3220. -3220.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex6 Guess the next number with Encoder-Decoder"
      ],
      "metadata": {
        "id": "iA1_tqDsh4rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Create the Encoder-Decoder RNN Model"
      ],
      "metadata": {
        "id": "UOj9savt91Y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Create the unified model for training"
      ],
      "metadata": {
        "id": "-i-H1Zqp92BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   n_input : the cardinality of the input sequence, e.g. number of features, word, or characters foreach time step.\n",
        "*   n_output : the cardinality of output sequence, e.g. number of features, word, or characters foreach time step.\n",
        "*   n_units : Then number of cells to create in encoder-decode model e.g. 128, 256\n",
        "\n"
      ],
      "metadata": {
        "id": "RaWxSCDj_dKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_input, n_output ,n_units = 1, 1, 20"
      ],
      "metadata": {
        "id": "9lRLdVCI_acQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder\n",
        "# Create layer\n",
        "encoder_inputs = tf.keras.layers.Input( shape=(None,n_input), name=\"encoder_input_x\" )\n",
        "encoder_rnn = tf.keras.layers.SimpleRNN( units=n_units, return_state=True, name='encode_rnn')\n",
        "# link layer\n",
        "encoder_outputs, encoder_states = encoder_rnn(encoder_inputs)"
      ],
      "metadata": {
        "id": "cWo0sLtH_amq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the decoder\n",
        "# Create layer\n",
        "decoder_inputs = tf.keras.layers.Input( shape=(None,n_output), name='decoder_input_x')\n",
        "decoder_rnn = tf.keras.layers.SimpleRNN( units=n_units, return_sequences=True, return_state=True, name='decode_rnn')\n",
        "decoder_dense = tf.keras.layers.Dense( n_output, name='decoder_dense')\n",
        "# link layer\n",
        "decoder_outputs,_ = decoder_rnn(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "qbExNFpL_axZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Encoder-Decoder model use for trainig call seq2seq_model\n",
        "seq2seq_model = tf.keras.Model( inputs=[encoder_inputs, decoder_inputs] ,outputs=decoder_outputs, name='seq2seq_model')\n",
        "seq2seq_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiLM5MabD8nO",
        "outputId": "ce650f23-cb11-471a-bfdd-20c23737301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"seq2seq_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input_x (InputLayer)   [(None, None, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " decoder_input_x (InputLayer)   [(None, None, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " encode_rnn (SimpleRNN)         [(None, 20),         440         ['encoder_input_x[0][0]']        \n",
            "                                 (None, 20)]                                                      \n",
            "                                                                                                  \n",
            " decode_rnn (SimpleRNN)         [(None, None, 20),   440         ['decoder_input_x[0][0]',        \n",
            "                                 (None, 20)]                      'encode_rnn[0][1]']             \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)          (None, None, 1)      21          ['decode_rnn[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 901\n",
            "Trainable params: 901\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cisualize the model\n",
        "tf.keras.utils.plot_model( seq2seq_model, \"RNN_ex6_trainmodel.png\", show_shapes=True, show_dtype=False ,show_layer_names=True ,dpi=96)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "JcxOffMXFjJC",
        "outputId": "75218829-bd79-4e03-a306-9821e00ad9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) create decoder-encoder for inferencing for using when imprement"
      ],
      "metadata": {
        "id": "GS5npHHw92gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder model for inferencing\n",
        "encoder_model = tf.keras.Model( inputs=encoder_inputs, outputs=encoder_states ,name='encoder_model' )\n",
        "\n",
        "encoder_model.summary()\n",
        "tf.keras.utils.plot_model( encoder_model, \"RNN_ex6_encodermodel.png\", show_shapes=True, show_dtype=False ,show_layer_names=True ,dpi=96)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "UTQY8Ga0HyjK",
        "outputId": "3d4829f8-e6ec-445a-ec58-e3a4c47a8687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input_x (InputLayer  [(None, None, 1)]        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " encode_rnn (SimpleRNN)      [(None, 20),              440       \n",
            "                              (None, 20)]                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 440\n",
            "Trainable params: 440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the decoder model for inferencing\n",
        "## Create a new input layer to be use during inferencing\n",
        "decoder_states_inputs = tf.keras.layers.Input( shape=(n_units), name='decoder_states_inputs' )\n",
        "\n",
        "## link all layer\n",
        "decoder_outputs,decoder_states = decoder_rnn( decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = tf.keras.Model( inputs=[decoder_inputs]+[decoder_states_inputs],\n",
        "                               outputs=[decoder_outputs]+[decoder_states],\n",
        "                               name=\"decoder_model\")\n",
        "\n",
        "decoder_model.summary()\n",
        "tf.keras.utils.plot_model( decoder_model, \"RNN_ex6_decodermodel.png\", show_shapes=True, show_dtype=False ,show_layer_names=True ,dpi=96)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "VDvkw9ajHymG",
        "outputId": "4c2e9ce2-8919-4304-ae51-e8fd56925cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " decoder_input_x (InputLayer)   [(None, None, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " decoder_states_inputs (InputLa  [(None, 20)]        0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " decode_rnn (SimpleRNN)         [(None, None, 20),   440         ['decoder_input_x[0][0]',        \n",
            "                                 (None, 20)]                      'decoder_states_inputs[0][0]']  \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)          (None, None, 1)      21          ['decode_rnn[1][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAAEnCAYAAACpNjYKAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeXhN1/4/8PeJnOSck0ESQtIQIqGlhra4X1J+bqfbwZeKILlo0ZaEakSVGFNFe0t8IxcJN6W00UtiaLRU9dFeXLeap4pKqSA1xRRCZJbp8/vDN+frSEKGc7LP8H49T56n3XvtvT9r75W9lk/W3lslIgIiIiIiIiIiIitmp3QARERERERERESmxgQIEREREREREVk9JkCIiIiIiIiIyOoxAUJEREREREREVs/+/gUHDx5EbGysErEQERERVfPuu++ib9++Jtn38OHDTbJfIiIiUlZN44dqM0AuXryILVu2NFlQZFuysrLYvhpgy5YtyMrKUjoMslFsf6SkLVu24OLFiybdP9s32ZKffvoJP/30k9JhWBSOX60Xfx+sV23jh2ozQKps3rzZpAGRbUpJSUFISAjbVz2pVCpMnToVI0aMUDoUskFsf6QklUpl8mOwfZMtqZr1xLFY3XH8ar34+2C9ahs/8B0gRERERERERGT1mAAhIiIiIiIiIqvHBAgRERERERERWT0mQIiIiIiIiIjI6jEBQkRERERERERWzyQJkLfeegsuLi5QqVQ4evSoKQ5hEfF88803aN68Ob7++usmO6at4LklIiJzwDGPdeH4ou54rojIEpkkAbJmzRp88sknpth1gygVj4g0+TFtBc8tERGZA455rAvHF3XHc0VEloiPwJjQwIEDcfv2bQwaNEjpUFBcXIzAwEClwzAanlsiIiLL0JB+Uqm+leOLuuO5IiJLZLIEiEqlMtWuG8Tc4mlqa9euRXZ2ttJhWCWeWyIi22ZuYwxzi6ch/ST7Vp6D+uC5IqK6MkoCREQQExODRx99FI6OjmjevDmmT59erVxFRQWio6Ph6+sLrVaL7t27Izk52aBMUlISevXqBY1GAycnJ7Rv3x4LFy7UHyc2NhadO3eGo6Mj3N3dMWTIEJw8edLo8SxZsgQ6nQ4uLi7Izs7GtGnT4OPjg4yMjDqdkwMHDsDX1xcqlQorV64EACQkJMDJyQk6nQ7bt2/Hyy+/DFdXV7Rp0wYbN27Ub7t8+XJoNBq0atUK4eHh8Pb2hkajQWBgINLS0vTlIiIi4ODgAC8vL/2yt99+G05OTlCpVLhx4wYAIDIyEtOmTUNmZiZUKhUCAgLqVAcAWL9+PZydnaFSqeDu7o7U1FQcOnQI7dq1Q7NmzTBy5Mg678tYLOHcfvvtt3B1dcWHH37YFKeEiIiaCMc8Ndu3bx/+9Kc/QafTwdXVFd26dUNeXl6t/eS///1vdOnSBc2bN4dGo0G3bt2we/duALX3rQ87p7XFUFeWML5obB2NxRLOFcdiRFQjuU9ycrLUsPiB5syZIyqVSv7nf/5Hbt26JUVFRRIfHy8A5MiRI/py7733njg6OsqWLVvk1q1bMnv2bLGzs5Off/5ZRESWLVsmAORvf/ub5OTkyM2bN+Uf//iHjBo1SkREoqOjxcHBQZKSkiQ3N1eOHTsmTz31lLRs2VKuXr1q9HjmzJkjAGTKlCmyYsUKGTp0qPz+++91Pi8XL14UALJixQqD2ADI999/L7dv35bs7Gzp37+/ODk5SWlpqb5cWFiYODk5yYkTJ6SkpESOHz8uvXv3FhcXF7lw4YK+3KhRo6R169YGx42JiREAcv36df2y4OBg8ff3r3Ps9zpx4oTodDoZM2aMftmsWbNkzZo19d5XQ9pXTcz93O7YsUNcXFxkwYIFja6riAgASU5ONsq+iOqL7Y+UZOr2V9/9c8xTXUFBgbi6usrixYuluLhYrl69KkOHDtX3lTX1k5s3b5b58+fLzZs3JScnR/r06SMtWrTQr69pmwfV4WEx1JU5jy+MVcdhw4bJsGHD6rVNTcz5XIkYdyxmrPErmR9j/T6Q+amtf2/0DJDi4mIsW7YMzz//PN599124ublBq9XCw8PDoFxJSQkSEhIQFBSE4OBguLm5Ye7cuVCr1Vi3bh3KysrwwQcf4JlnnsHMmTPh4eEBd3d3vPnmm+jduzeKi4sRGxuLoUOHYvTo0WjevDm6deuG1atX48aNG0hMTDRqPPf6+OOPMXnyZGzduhWPPfZYY08ZACAwMBCurq7w9PREaGgoCgsLceHCBYMy9vb2+r/8dOnSBQkJCcjPz68Wn6l17twZy5Ytw2effYYvvvgCGzduxJ07d/Dmm282aRx1ZQ7nduDAgcjLy8O8efOMsj8iIlIexzw1O3fuHPLy8vD4449Do9GgdevW2Lp1K1q2bFnrNsOGDcP7778Pd3d3eHh4YPDgwcjJycH169drLP+wOjQkhvpSenzRFHU0FqXPFcCxGBHVrNEJkDNnzqCoqAjPPffcA8tlZGSgqKgIXbt21S/TarXw8vLCyZMncezYMeTm5uLFF1802K5Zs2aYMmUKjh8/joKCAvTq1ctgfe/eveHg4KCfMmeseJqSg4MDAKCsrOyB5Xr16gWdTtfk8QHAhAkTMGzYMISHhyMlJQVLlixp8hgawhLOLRERWQaOeWrWoUMHtGrVCqNHj8b8+fNx7ty5eu9DrVYDuPuYS00eVgdjxFAfSowvmrqOxsKxGBGZk0YnQLKysgAAnp6eDyxXWFgIAJg7dy5UKpX+5/z58ygqKtI/v+jm5lbj9rm5uQAAZ2fnauvc3NyQn59v1HjMlaOjY61/HTG1Dz/8EAUFBVb7kiklzy0REZk/jnlqptVq8cMPP6Bfv3748MMP0aFDB4SGhqK4uLjWbXbu3Ik///nP8PT0hKOjI2bMmNGoOjQkhqZirPGFOdfRWDgWIyJTa3QCRKPRAADu3LnzwHJVnfOyZcsgIgY/Bw8exCOPPAIA+hca3a9qkFDV6d8rNzcXbdq0MWo85qisrMygrk197ClTpiA2NhYHDx7EokWLmjwGU1Ly3BIRkWXgmKd2jz/+OL7++mtcvnwZUVFRSE5OxtKlS2sse+HCBQQFBcHLywtpaWm4ffs2Fi9e3Og61CeGpmLs8YU51tFYOBYjoqbQ6ARI165dYWdnh3379j2wXNu2baHRaHD06NEa17dv3x4eHh747rvvaj2Os7MzDh06ZLA8LS0NpaWl6Nmzp1HjMUd79+6FiKBPnz76Zfb29g+dUmgM77zzDsaPH4+pU6fi3XffxcKFC802UdQQSp5bIiKyDBzz1Ozy5cs4ceIEgLuJir/97W946qmn9Mvul56ejrKyMkyaNAkdOnSARqN56Kd7H1aH+sbQVIw5vjDXOhoLx2JE1BQanQDx9PREcHAwtmzZgrVr1yIvLw/Hjh3Tv6Crikajwbhx47Bx40YkJCQgLy8PFRUVyMrKwpUrV+Do6IjZs2dj//79iIiIwKVLl1BZWYn8/HycOHECGo0G06ZNw7Zt27Bhwwbk5eUhPT0dEydOhLe3N8LCwowajzmorKzErVu3UF5ejmPHjiEyMhK+vr4YO3asvkxAQABu3ryJ1NRUlJWV4fr16zh//ny1fXl4eODy5cs4d+4c8vPz69WZxMfHw8fHB0OHDgUAfPTRR+jSpQtGjRqlyKfXjMHU53bXrl389BoRkZXhmKdmly9fRnh4OE6ePInS0lIcOXIE58+f1/9D9v5+0tvbGwCwZ88elJSU4PTp0wafP61pm2bNmj2wDg+LoamYcnxx/vx5s6ijsXAsRkSKuP+zMA35zFN+fr689dZb0qJFC3F2dpZ+/fpJdHS0AJA2bdrIr7/+KiIid+7ckaioKPH19RV7e3vx9PSU4OBgOX78uH5fK1eulG7duolGoxGNRiNPPvmkxMfHi4hIZWWlxMTESMeOHUWtVou7u7sEBQVJRkaG0eNZvHixaLVaASBt27aVpKSkep2TFStWiJeXlwAQnU4ngwcPlvj4eNHpdAJAOnbsKJmZmZKYmCiurq4CQNq1ayenTp0SkbufB1Or1eLj4yP29vbi6uoqQ4YMkczMTIPj5OTkyDPPPCMajUb8/PzknXfekenTpwsACQgI0H9K7PDhw9KuXTvRarXSr18/g0/oPcigQYNEpVKJh4eH/PjjjyIiMnXqVLGzsxMA0rx5czl06FCdz4sxPiNmCef2m2++ERcXF1m0aFGj6loF/AwpKYjtj5Rk6vZX3/1zzFPduXPnJDAwUNzd3aVZs2byyCOPyJw5c6S8vFxEau4no6KixMPDQ9zc3GT48OGycuVKASD+/v5y4cKFGrd5UB0eFkNdmPv4Ii0trdF1FDHOZz/N/VwZeyzGz+BaL34G13rV1r+r/nelXkpKCkJCQnDfYmpi4eHh2Lx5M3JycpQOxajMoX1Z4rlVqVRITk7GiBEjlA6FbBDbHynJ1O2P7ZuMxVLGF8OHDwcAbN68WbEYLOVcVTGH8SuZhjn8PpBp1Na/N/oRGDKd2j4FR43Hc0tERETGxvFF3fFcEZESmACph5MnTxp8eq22n9DQUKVDfSBrqQcRERGZhrWMFaylHkREZBxMgNTDY489Vu3TazX9bNq0qVHHmT17NtatW4fbt2/Dz88PW7ZsMVIN7mqqepgjU59bcxEeHm4wsBs9enS1Mnv27MGsWbOwdetWdOjQQV/2tddeq1b2L3/5C1xcXNCsWTM8/vjjOHz4cFNUo0GsrT73qqysxLJlyxAYGFht3VdffYXFixdX+4taamqqQVto2bKlyeNk+7Oe+tzLUtofGYe1jBWsZexmTWzlXNlyXwgACxYsQJcuXeDq6gpHR0cEBARgxowZKCgoqFb2wIEDePrpp6HT6eDt7Y2oqCiDz3ubWx/Da2vh1/b+l4LwJT9kSmxfDYN6vqQvLCxMPDw8ZNeuXZKRkSElJSUG66Ojo2XQoEGSl5enX+bv7y8tWrQQALJjx45q+9y1a5e8+uqrDa9EE7O2+pw6dUqefvppASA9evSosUxcXJwMGDBAbt26pV9WWVkpWVlZsn//fnnllVekRYsW9T4221/9WVt9LKn9mdv+icwNX/pYfw0Zv9p6XzhgwACJj4+XnJwcycvLk+TkZFGr1fLSSy8ZlPvtt99Eq9XKvHnzpKCgQH788Udp2bKljBs3zqCcqfqYhvw+8NpaxrWtrX/nDBAiK6XVavHSSy+hU6dOcHR01C//+OOPsWnTJqSkpMDFxcVgm+XLl8POzg5hYWG4fft2U4dsdNZSn19//RUzZ87ExIkT8cQTT9RabsqUKejRowdeeeUVlJeXA7j7AigfHx/0798fHTt2bKqQ2f5gPfWxxPZHRGQObLkvdHZ2RlhYGDw8PODi4oIRI0YgKCgI3377LS5evKgvt3DhQnh5eeGDDz6Ak5MT+vbti6ioKKxfvx4nT57UlzO3PobX1nKvLRMgRDbkzJkzmDdvHj744ANoNJpq6wMDAxEZGYlLly7hvffeUyBC47KW+vTo0QNbt27FqFGjDDrZmsyfPx9Hjx5FXFxcE0VXd2x/lsla2h8RkTmwlb5wx44daNasmcGyqscYioqKAADl5eXYuXMnBgwYAJVKpS/38ssvQ0Swfft2g+3NvY/htbWMa8sECJENWb58OUQEgwcPrrXMokWL0KlTJ6xZswZ79ux54P5EBLGxsejcuTMcHR3h7u6OIUOGGGR1ExIS4OTkBJ1Oh+3bt+Pll1+Gq6sr2rRpg40bNxrsr6KiAtHR0fD19YVWq0X37t2RnJzcqDpbW30ext3dHQMGDEBcXJzZfa6P7c/y6/Mw5tz+iIjMgS32hVUuXboErVYLPz8/AMAff/yBgoIC+Pr6GpTz9/cHABw7dsxgubn3Mby2lnFtmQAhsiE7d+7Eo48+Cp1OV2sZrVaL9evXw87ODuPHj0dhYWGtZefPn49Zs2Zhzpw5yM7Oxv79+3Hx4kX0798f165dAwBMmjQJU6dORXFxMVxcXJCcnIzMzEx06NAB48ePR1lZmX5/M2fOxJIlS7Bs2TJcuXIFgwYNwsiRI3Ho0KEG19na6lMXTz75JC5duoRff/3VpMepL7Y/y69PXZhr+yMiMge22BcCd2cG/PDDDxg/fjwcHBwAAFevXgWAao+KaDQaaLVaffz3Muc+htfWMq4tEyBENqKwsBBnz57VZ14fpG/fvpg6dSrOnTuHmTNn1limuLgYsbGxGDp0KEaPHo3mzZujW7duWL16NW7cuIHExMRq2wQGBsLV1RWenp4IDQ1FYWEhLly4AAAoKSlBQkICgoKCEBwcDDc3N8ydOxdqtRrr1q1rVN2trT4PU/WsZHp6ukmPUx9sf9ZTn4cxx/ZHRGQObLkv/Oijj+Dt7Y1Fixbpl1V9DeT+xykAQK1Wo7i4uNpyc+1jeG0t59ra17bi3md1iIyN7avpZWdnQ0QemJW+16JFi7Bjxw7Ex8cjJCSk2vrjx4+joKAAvXr1Mljeu3dvODg4IC0t7YH7r8oQV2WmMzIyUFRUhK5du+rLaLVaeHl5GUz1ayhrq8+DVF3jmrLrSmH7s676PIg5tr+HCQkJqfG6EFkzjsWanq32hdu2bUNKSgq+++47gxkBVe/JqHrx5b1KS0uh1WqrLTfXPobX1nKuba0JEFM/J0y26eDBg4iLi2P7qidjDMxLSkoA4KEvMayi0Wiwbt069OvXD2+88QYWL15ssD43NxfA3TdB38/NzQ35+fn1iq9qCuDcuXMxd+5cg3Xe3t712ldNrK0+D1LVqVRdc3PA9mdd9XkQc2x/DxMZGYm+ffsqHQZRk1i2bBkAYOrUqQpHYjmqxq+NZYt94aZNmxAbG4u9e/fikUceMVjn5eUFAMjLyzNYXlRUhJKSkhqPaa59DK+t5VzbWhMgI0aMMOmByXbFxcWxfdWTMRIgVTeVioqKOm/Tt29fvPvuu1i6dCkWLlxo8CIjNzc3AKjxBpybm4s2bdrUKz5PT08AdwdmkZGR9dq2rqytPrUpLS0FgBqz60ph+7O++tTGHNvfw/Tt25f9EtmMzZs3A+BYv76MkQCxtb5wxYoV2L17N3744Yca/yHv5+cHFxcXnD9/3mD5mTNnAADdu3evto259jG8tobM+dryHSBENqJVq1ZQqVT1/u74woUL8dhjj+HIkSMGy7t27QpnZ+dqL05KS0tDaWkpevbsWa/jtG3bFhqNBkePHq3XdvVlbfWpSdU1bt26dZMfuzZsf3dZW31qYo7tj4jIHNhKXygiiIqKQnp6OlJTU2v8BzIA2Nvb45VXXsH+/ftRWVmpX75r1y6oVKoav6Zirn0Mr60hc762TIAQ2QidTocOHTogKyurXttVTdG7/yVGGo0G06ZNw7Zt27Bhwwbk5eUhPT0dEydOhLe3N8LCwup9nHHjxmHjxo1ISEhAXl4eKioqkJWVhStXrgAAQkND0bp1axw+fLhe+7bm+tSk6hp369bNqPttDLY/66xPTcyx/RERmQNb6QtPnDiBJUuW4JNPPoFarYZKpTL4Wbp0qb7svHnzcO3aNbz//vsoLCzEwYMHERMTg7Fjx+LRRx+ttm9z7WN4bS3o2sp9kpOTpYbFREbB9tUwACQ5ObnO5cPCwsTHx6fa8oiICFGr1VJUVKRftm3bNvH39xcA0rJlS5k8eXKN+5w+fbq8+uqrBssqKyslJiZGOnbsKGq1Wtzd3SUoKEgyMjL0ZeLj40Wn0wkA6dixo2RmZkpiYqK4uroKAGnXrp2cOnVKRETu3LkjUVFR4uvrK/b29uLp6SnBwcFy/PhxEREJCgoSABIdHV1r3a2tPiIiBw8elKefflq8vb0FgAAQLy8vCQwMlH379lUrP3DgQPHx8ZHKykqD5VOmTJEWLVo88Fg1Yftj+7Ok9mdu+ycyN8OGDZNhw4YpHYZFacj41Zb7wvT0dH1/UdNPTEyMQfl9+/bJn/70J3F0dBRvb2+ZPn26lJSU1LhvY/cxDfl94LW1jGtbW//OBAg1KbavhjHWP0BPnz4t9vb2kpSUZMzwmkxFRYX0799f1q5dq3QoRmGK+ty4cUM0Go0sXbq02jqlEyBsf+bFWtufue2fyNwwAVJ/xkyAsC9sOFP0McZMgPDaNlxTjh/4CAyRlSouLsbu3btx+vRp/UuFAgICsGDBAixYsAAFBQUKR1g/FRUVSE1NRX5+PkJDQ5UOp9FMVZ/58+fjiSeeQEREBIC7z2pevnwZBw4c0L94qimw/Zk3a29/RETmgH2hcZlTH8Nra1xNeW3NOgHy008/oXPnzrCzs4NKpULr1q2xaNEipcMysHXrVnTo0EH/3JOXlxdGjx6tdFhEuHnzJl566SV06tQJb7zxhn75rFmzMHz4cISGhtb7RU1K2rt3L7Zu3Ypdu3bV+Rvr5swU9YmNjcXRo0fxzTffQK1WAwC2b98OHx8f9O/fHzt37jTKceqC7c+8WXv7s3UcPxGZB/aFxmNufQyvrfE09bVV/e/0EL2UlBSEhITgvsWKeumll7B7927cunVL/0kgcxMQEIAbN27ov9lMNTPH9mUJVCoVkpOTjfrJuu+++w4//PADPv74Y6Ptk5Szfft2nDhxAjNmzKj2Iq3GYvujh7G09teU+1cSx09Uk+HDhwP4v8/h0sOZavzKvrBuTNnHmOr3gde2bpQYP5j1DBBzVFxcjMDAQKXDoEZoimtoCe3kL3/5C2/KVuTVV1/FrFmzjN55mArbn3WxtPZHTc8S+kVqOhyL3cW+sG4ssY/hta0bJa4tEyD1tHbtWmRnZysdBjVCU1xDthMiIqL/w36R7sWxGBEpxSITIAkJCXBycoJOp8P27dvx8ssvw9XVFW3atMHGjRv15ZYvXw6NRoNWrVohPDwc3t7e0Gg0CAwMRFpamr5cREQEHBwc4OXlpV/29ttvw8nJCSqVCjdu3AAAREZGYtq0acjMzIRKpUJAQECD4v/3v/+NLl26oHnz5tBoNOjWrRt2794NAHjrrbf0z8P6+/vjyJEjAIBx48ZBp9OhefPm+OqrrwDcfVlNdHQ0fH19odVq0b17dyQnJwMAlixZAp1OBxcXF2RnZ2PatGnw8fFBRkZGg2JWkoggNjYWnTt3hqOjI9zd3TFkyBCcPHlSX6Yx17Cp2sm3334LV1dXfPjhhyY9X0RERDXh+Mm2xk/GxLEYEVmN+z8LY46fKX3xxRcFgNy6dUu/bM6cOQJAvv/+e7l9+7ZkZ2dL//79xcnJSUpLS/XlwsLCxMnJSU6cOCElJSVy/Phx6d27t7i4uMiFCxf05UaNGiWtW7c2OG5MTIwAkOvXr+uXBQcHi7+/f7UY/f39pXnz5nWqz+bNm2X+/Ply8+ZNycnJkT59+hh82ic4OFiaNWsmly5dMthu5MiR8tVXX+n//7333hNHR0fZsmWL3Lp1S2bPni12dnby888/G5yjKVOmyIoVK2To0KHy+++/1ylGU2lI+4qOjhYHBwdJSkqS3NxcOXbsmDz11FPSsmVLuXr1qr5cY65hU7STHTt2iIuLiyxYsKBe9RfhZxpJWWx/pCRTtz9rbt8cP91lDeMnY2rIZz9tfSxmjv8+IuPgZ6GtV239u0XOALlXYGAgXF1d4enpidDQUBQWFuLChQsGZezt7fUZ6y5duiAhIQH5+flYt26dIjEPGzYM77//Ptzd3eHh4YHBgwcjJycH169fBwBMnDgRFRUVBvHl5eXh559/xiuvvAIAKCkpQUJCAoKCghAcHAw3NzfMnTsXarW6Wr0+/vhjTJ48GVu3bsVjjz3WdBU1guLiYsTGxmLo0KEYPXo0mjdvjm7dumH16tW4ceMGEhMTjXYsU7eTgQMHIi8vD/PmzTPK/oiIiBqK4yfrHj8ZE8diRGRNLD4Bci8HBwcAQFlZ2QPL9erVCzqdzmDanpKqPvdTUVEBAHj22WfRqVMnfPrpp/q3TW/atAmhoaH6F8RkZGSgqKgIXbt21e9Hq9XCy8vLbOplDMePH0dBQQF69eplsLx3795wcHAwmBZpbObWToiIiEyB4yfrGz8ZE8diRGRNrCoBUh+Ojo76vxg0tZ07d+LPf/4zPD094ejoiBkzZhisV6lUCA8Pxx9//IHvv/8eAPD555/jzTff1JcpLCwEAMydO1f/zKtKpcL58+dRVFTUdJUxsarP4jk7O1db5+bmhvz8fJMeX8l2QkREZG44frI9HIsRkTWxyQRIWVkZcnNz0aZNmyY53v79+7Fs2TIAwIULFxAUFAQvLy+kpaXh9u3bWLx4cbVtxo4dC41GgzVr1iAjIwOurq5o166dfr2npycAYNmyZRARg5+DBw82Sb2agpubGwDU2Lma+ho2dTshIiIyZxw/2SaOxYjImtgrHYAS9u7dCxFBnz599Mvs7e0fOvWzoX755Rc4OTkBANLT01FWVoZJkyahQ4cOAO7+xeJ+7u7uCAkJwaZNm+Di4oLx48cbrG/bti00Gg2OHj1qkpjNRdeuXeHs7IxDhw4ZLE9LS0NpaSl69uypX2bsa9jU7YSIiMiccfxkmzgWIyJrYhMzQCorK3Hr1i2Ul5fj2LFjiIyMhK+vL8aOHasvExAQgJs3byI1NRVlZWW4fv06zp8/X21fHh4euHz5Ms6dO4f8/PwH3oDLyspw7do17N27V9+B+/r6AgD27NmDkpISnD59utZnJydOnIg7d+5gx44dGDRokME6jUaDcePGYePGjUhISEBeXh4qKiqQlZWFK1eu1PcUmS2NRoNp06Zh27Zt2LBhA/Ly8pCeno6JEyfC29sbYWFh+rKNvYambie7du3ip9eIiMhicPxEAMdiRGRl7v8sjDl95umnn36Sxx9/XOzs7ASAeHl5yYcffijx8fGi0+kEgHTs2FEyMzMlMTFRXF1dBYC0a9dOTp06JSJ3P6mlVqvFx8dH7O3txdXVVYYMGSKZmZkGx8rJyZFnnnlGNBqN+Pn5yTvvvCPTp08XABIQEKD//Nbhw4elXbt2otVqpV+/frJq1Srx9/cXAA/82bZtm/5YUVFR4uHhIW5ubjJ8+HBZuXKlABB/f3+Dz3yJiDz55JMya9asGs/PnTt3JCoqSnx9fcXe3oAgZ6oAACAASURBVF48PT0lODhYjh8/LosXLxatVisApG3btpKUlGTMS9NgDWlflZWVEhMTIx07dhS1Wi3u7u4SFBQkGRkZBuUaeg2vXr1q8nZy9epV+eabb8TFxUUWLVpU7/MGK/5MI5k/tj9SkqnbnzW2b46frG/8ZEwN+eynrY/FzOnfR2Rc/Ayu9aqtf1f970q9lJQUhISE4L7FFis8PBybN29GTk6O0qE0yMCBA7Fy5Ur4+fkpHYpRmGv7Mvd2olKpkJycjBEjRigdCtkgtj9SkqnbH9t3zcy9X3wYaxs/GdPw4cMBAJs3b1Y4EkPm3ObMdfxKjWeuvw/UeLX17zbxCEzV59Eswb1TQo8dOwaNRsPOu4lYUjshIiIyNUvqFzl+sg6W1OaIyDLZ5EtQzVlUVBQmTpwIEcG4ceOQlJSkdEhEREREZo3jJyIiqgurngEye/ZsrFu3Drdv34afnx+2bNmidEgPpdPp8Nhjj+H555/H/Pnz0aVLF6VDsnqW2E6IiIhMxRL7RY6fLJsltjkiskxWnQD56KOPcOfOHYgIzp49i2HDhikd0kMtWrQIFRUVuHDhQrU3l5NpWGI7ISIiMhVL7Bc5frJsltjmiMgyWXUChIiIiIiIiIgIYAKEiIiIiIiIiGwAEyBEREREREREZPWYACEiIiIiIiIiq1frZ3BTUlKaMg6yEQcPHgTA9tUQVeeOrNfNmzfh4eGhdBg1Yvsja8b2TZaooX1GVlYWAI7F6oPjV+vF3wfboxIRuXdBSkoKQkJClIqHiIiIyEBycjJGjBhhkn2rVCqT7JeIiIiUVdP4oVoChIiIlPHLL78gMTER//znP1FeXo5BgwZhwoQJeP7555UOjYiIFHT58mUkJSVh1apVuHjxIp599llMmDABQ4YMgVqtVjo8IiKLwQQIEZGZycvLw6ZNm7Bq1SocPXoUnTt3xpgxYzBhwgS4u7srHR4RETWByspK/PDDD0hMTMSXX36JFi1aYOzYsRg/fjz8/f2VDo+IyCIxAUJEZMaqZoV88cUXqKiowPDhwxEZGYmnnnpK6dCIiMgErly5gs8//xyrV6/G+fPn8dxzz2HChAl49dVX4eDgoHR4REQWjQkQIiILcPv2bSQnJyM+Ph7Hjh1Dz549MWHCBIwcORLOzs5Kh0dERI1w/2wPFxcXDB8+HFOmTEGXLl2UDo+IyGowAUJEZGGqZoVs2LABzZo1w1//+leEh4fjySefVDo0IiKqh3tne5w7d06f3H7ttdeg1WqVDo+IyOowAUJEZKFyc3ORkpKCFStW4LffftMPnEeNGgUnJyelwyMiohrcO9sjNTUVzs7OGD58OCIiIvD4448rHR4RkVVjAoSIyApUzQpJSkqCWq1GaGgoJk2ahB49eigdGhER4f9me/zjH//A2bNnOduDiEgBTIAQEVmRW7duYfPmzVi+fDmOHz+uH2CPHj0aOp1O6fCIiGzK/bM9nJycMGLECLzzzjvo2rWr0uEREdkcJkCIiKzUgQMHsHz5cqSmpkKn0yEkJASTJ09Gt27dlA6NiMiqXb16FZ999hlnexARmRkmQIiIrNy1a9ewfv16JCYm4o8//uBAnIjIBDjbg4jI/DEBQkRkI2obnPPFe0REDVc124NJZiIi88cECBGRDaoasN/76cWIiAiEhobCwcFB6fCIiMxabQllPmZIRGTemAAhIrJh9w7iv/zyS7Ro0QJjx47FhAkT0KFDB6XDIyIyK7U9UsgXTRMRWQYmQIiICABw+fJlJCUlYdWqVbh48SKeffZZTJgwAUOGDIFarVY6PCIiRdw/24MvlSYislxMgBARkYH7Z4W0bNkSY8aMQVhYGPz8/JQOj4ioSVTN9vjkk0+QmZnJ2R5ERFaACRAiIqrVpUuXsGHDBsTHx+PSpUv6WSFBQUGwt7dXOjwiIqMSEXz//fdITEzE9u3bodVqERISgrfffhvdu3dXOjwiImokJkCIiOihKioq8K9//QuJiYnYtm0bWrVqhddffx0TJ05Eu3btlA6PiKhRbt26hc2bN+Pvf/87Tpw4wdkeRERWigkQIiKql6ysLKxZswarVq3CjRs3OCuEiCzWL7/8gsTERCQlJcHBwQEhISGYNGkSevTooXRoRERkAkyAEBFRg5SWlmL79u1ITEzE999/j0ceeQSjR4/GpEmT4Ovrq3R4REQ1qprtsXz5chw/flw/22PUqFFwcnJSOjwiIjIhJkCIiKjRTp8+jbVr1+LTTz/FzZs38cwzz2DChAkYOnQomjVrpnR4REQGsz3UajVCQ0M524OIyMYwAUJEREZz584dfPXVV/pZIT4+Phg1ahQmT56MNm3aKB0eEdmY3NxcpKSkYMWKFfjtt98424OIyMYxAUJERCZx6tQpfPrpp1i7di3y8vLw6quvYsKECXjuueegUqmUDo+IrFhNsz0mTpyIJ554QunQiIhIQUyAEBGRSd0/K8Tf3x9vvfUW3njjDXh6eiodHhFZCc72ICKih2EChIiImszJkyexfv16rFmzBvn5+ZwVQkSNVtNsj/DwcDz55JNKh0ZERGaGCRAiImpyJSUl+Prrr5GYmIg9e/agU6dOeOONN/Dmm2+iZcuWSodHRGauarbHypUrkZ6erp/tMXLkSDg7OysdHhERmSkmQIiISFG///47PvvsMyQmJqKoqAiDBw/mrBAiqlHVbI8NGzbA3t6esz2IiKhemAAhIiKzUDUr5O9//zv+85//4NFHH8W4cePw1ltvoUWLFkqHR0QKuX37NpKTkznbg4iIGo0JECIiMjtVf+X95z//ifLycgwaNAgTJkzA888/r3RoRNRE7p3t0axZM/z1r39FWFgYnnrqKaVDIyIiC8UECBERma38/Hxs3LgRq1evxpEjR9C5c2eMGTMG48ePh4eHh9LhEZGRVc32iI+Px7Fjxzjbg4iIjIoJECIisghVfw3+4osvUFFRwVkhRFaEsz2IiKgpMAFCREQWJS8vD5s2bUJCQgJ+/fVX/oWYyEJVzfa4/3f5r3/9K1xcXJQOj4iIrBATIEREZLFq+qsxvwhBZN44m4uIiJTCBAgREVm82r4SMWrUKDg5OSkdHpHNu3/mVpcuXfD6669jwoQJcHd3Vzo8IiKyEUyAEBGRVan663JSUhLUajVCQ0MxadIk9OjRQ+nQiGwOZ3sQEZE5YQKEiIisUm5uLlJSUrB8+XIcP35cPytk9OjR0Ol0SodHZLWqZnusWrUKR48e1c/24NebiIhIaUyAEBGR1av6K/Tnn38OR0dHhISE4O2330b37t2VDo3IanC2BxERmTsmQIiIyGZcu3YN69evxyeffILMzEzOCiFqpPtne3Tu3BljxozhbA8iIjJLTIAQEZHNqaysxA8//IDExESkpqbCyckJI0aMwDvvvIOuXbsqHR6R2aua7fHPf/4T5eXlnO1BREQWgQkQIiKyaVevXsVnn32Gf/zjHzh79qx+Vshrr70GrVZbp30sXboUY8aMgaenp4mjJTKetLQ0ZGdnY9CgQXUqXzXbY/Xq1Thy5AhnexARkcVhAoSIiAiGs0K+/PJLuLi44LXXXkNERAT8/f1r3e769evw8fGBt7c39uzZg44dOzZh1EQNk5qaitDQUDzxxBP46aefHliWsz2IiMha2CkdABERkTmws7PD888/j5SUFFy4cAFRUVHYvn07OnXqhBdeeAGbN29GWVlZte3Wr18PEcHly5fRu3dv/PjjjwpET1R3y5cvR3BwMEpLS5GWloYTJ05UK5Ofn4/ExET07NkTvXr1wv79+zF37lxkZWUhJSWFyQ8iIrJInAFCRERUi/tnhbRs2RJjxoxBWFgY/Pz8ICLw9/fH2bNnAdxNojRr1gyff/45QkNDFY6eyJCIYP78+ViwYIF+mYODAyZOnIi4uDgAhrM9ysrKMHjwYM72ICIiq8EECBERUR2cP38ea9aswdq1a3Ht2jW8+OKL6N+/P2bPnl2trEqlQnR0NObPn9/0gRLV4M6dO3j99dexZcsWVFZWGqxzdnbGRx99hPXr1+Pw4cPo2rWr/j04bm5uCkVMRERkfEyAEBER1UNFRQX+9a9/ITExEUeOHMH58+drfDRGpVJh8uTJiIuLg50dnzgl5dy8eRP//d//jZ9//hnl5eXV1tvZ2aFDhw548sknMWHCBDz33HNQqVQKREpERGRaTIAQERE1wLVr1+Dj44OKiopayzRr1gyvvPIKNm3aBJ1O14TREd31xx9/4IUXXsDFixdrTNQBdxMgvXv3fujLUImIiCwd/yRFRETUAJ9++ulD/0peUVGBb7/9Fv3790d2dnYTRUZ0V1paGnr16vXA5Adw9103aWlp+O2335owOiIioqbHBAgREVE9iQhWr15d4+ME9ysrK0N6ejp69eqFU6dONUF0RMCXX36JAQMGIC8v74HJjypqtRqffPJJE0RGRESkHCZAiIiI6um7777DhQsX6ly+rKwMly5dQp8+fZCWlmbCyIiAuLg4/WduH/SI1r3Kysqwbt06FBcXmzg6IiIi5fAdIET3GT58OLZs2aJ0GEREREREZof/fCRLZq90AETmqE+fPpg6darSYZCRHDx4EHFxcUhOTlY6FIsSEhKCyMhI9O3bV+lQLFZpaSlKS0tRWFiIO3fuoLS0FMXFxbhz5w6eeOIJ2NuzGybjycnJwfnz5+Hg4ACdTgdHR0f9fzs4OECtVj90H7xfElFtqu4PRJaMIy+iGrRp0wYjRoxQOgwyori4OF7TegoJCUHfvn153ohsDO+XRFQbJkDI0vEdIERERERERERk9ZgAISIiIiIiIiKrxwQIEREREREREVk9JkCIiIiIiIiIyOoxAUJEREREREREVo8JECITeuutt+Di4gKVSoWjR48qHY7ZxWNpvvnmGzRv3hxff/210qEQEREREVE9MQFCZEJr1qzBJ598onQYeuYWj6UREaVDICIiIiKiBrJXOgAiIksxcOBA3L59W+kwAADFxcV47rnn8OOPPyodChERERGRReAMECITU6lUSodgwNzioYZZu3YtsrOzlQ6DiIiIiMhiMAFCZEQigpiYGDz66KNwdHRE8+bNMX369GrlKioqEB0dDV9fX2i1WnTv3h3JyckGZZKSktCrVy9oNBo4OTmhffv2WLhwof44sbGx6Ny5MxwdHeHu7o4hQ4bg5MmTJovnYZYsWQKdTgcXFxdkZ2dj2rRp8PHxwZQpU+Dk5ASdToft27fj5ZdfhqurK9q0aYONGzfqt09ISKhTOaUcOHAAvr6+UKlUWLlyJYC6x7x8+XJoNBq0atUK4eHh8Pb2hkajQWBgINLS0vTlIiIi4ODgAC8vL/2yt99+G05OTlCpVLhx4wYAIDIyEtOmTUNmZiZUKhUCAgIAAN9++y1cXV3x4YcfNsUpISIiIiKyKEyAEBnRvHnzEBUVhbCwMFy7dg1Xr17FzJkzq5WbOXMmlixZgmXLluHKlSsYNGgQRo4ciUOHDgEA4uLi8Prrr2PYsGG4fPkysrKyMHv2bGRkZAAA5s+fj1mzZmHOnDnIzs7G/v37cfHiRfTv3x/Xrl0zejx1MWPGDLz77rsoKCjARx99BD8/P/Tp0wcTJ07E1KlTUVxcDBcXFyQnJyMzMxMdOnTA+PHjUVZWBgCYNGlSncoppV+/ftUeN6lrzBERERg7diyKioowZcoUnDt3DocPH0Z5eTleeOEFXLx4EcDdRMmIESMMjhEfH48PPvjAYFlcXBwGDRoEf39/iAjOnDkD4G4iCwAqKytNcg6IiIiIiCwZEyBERlJcXIxly5bh+eefx7vvvgs3NzdotVp4eHgYlCspKUFCQgKCgoIQHBwMNzc3zJ07F2q1GuvWrUNZWRk++OADPPPMM5g5cyY8PDzg7u6ON998E71790ZxcTFiY2MxdOhQjB49Gs2bN0e3bt2wevVq3LhxA4mJiUaNpyE+/vhjTJ48GVu3bsVjjz2mXx4YGAhXV1d4enoiNDQUhYWFuHDhQrXt61rOnNQlZnt7e/2snS5duiAhIQH5+fkNPs/3GzhwIPLy8jBv3jyj7I+IiIiIyJowAUJkJGfOnEFRURGee+65B5bLyMhAUVERunbtql+m1Wrh5eWFkydP4tixY8jNzcWLL75osF2zZs0wZcoUHD9+HAUFBejVq5fB+t69e8PBwUH/SIWx4jEVBwcHAHjozI66ljMndY25V69e0Ol0Jj3PRERERER0FxMgREaSlZUFAPD09HxgucLCQgDA3LlzoVKp9D/nz59HUVER8vLyAABubm41bp+bmwsAcHZ2rrbOzc0N+fn5Ro2HTMvR0RHXr19XOgwiIiIiIqvHBAiRkWg0GgDAnTt3HliuKiGxbNkyiIjBz8GDB/HII48AgP6Fl/erSoxUJTrulZubizZt2hg1HjKdsrIyg2tGRERERESmwwQIkZF07doVdnZ22Ldv3wPLtW3bFhqNBkePHq1xffv27eHh4YHvvvuu1uM4OztXe0FpWloaSktL0bNnT6PGQ6azd+9eiAj69OmjX2Zvb29Rj/sQEREREVkKJkCIjMTT0xPBwcHYsmUL1q5di7y8PBw7dkz/UtIqGo0G48aNw8aNG5GQkIC8vDxUVFQgKysLV65cgaOjI2bPno39+/cjIiICly5dQmVlJfLz83HixAloNBpMmzYN27Ztw4YNG5CXl4f09HRMnDgR3t7eCAsLM2o8ZDyVlZW4desWysvLcezYMURGRsLX1xdjx47VlwkICMDNmzeRmpqKsrIyXL9+HefPn6+2Lw8PD1y+fBnnzp1Dfn4+ysrKsGvXLn4Gl4iIiIioNkJEBoYNGybDhg1r0Lb5+fny1ltvSYsWLcTZ2Vn69esn0dHRAkDatGkjv/76q4iI3LlzR6KiosTX11fs7e3F09NTgoOD5fjx4/p9rVy5Urp16yYajUY0Go08+eSTEh8fLyIilZWVEhMTIx07dhS1Wi3u7u4SFBQkGRkZJovnYRYvXixarVYASNu2bSUpKUlEROLj40Wn0wkA6dixo2RmZkpiYqK4uroKAGnXrp2cOnWqzuUaIjk5WRp7u1uxYoV4eXkJANHpdDJ48OB6xRwWFiZqtVp8fHzE3t5eXF1dZciQIZKZmWlwnJycHHnmmWdEo9GIn5+fvPPOOzJ9+nQBIAEBAXLhwgURETl8+LC0a9dOtFqt9OvXT65evSrffPONuLi4yKJFixpV1yoAJDk52Sj7IiLLYIz7JRFZJ94fyBqoREQUyLsQma3hw4cDADZv3qxwJGQsKSkpCAkJgZK3u/DwcGzevBk5OTmKxVBfKpUKycnJGDFihNKhEFETMYf7JRGZJ94fyBrwERgioiZSUVGhdAhERERERDaLCRAiqtXJkycNPo1b209oaKjSoZIZCA8PN2gXo0ePrlZmz549mDVrFrZu3YoOHTroy7722mvVyv7lL3+Bi4sLmjVrhscffxyHDx9uimo0iLXV516VlZVYtmwZAgMDq6376quvsHjxYqMl96y1fQDAggUL0KVLF7i6usLR0REBAQGYMWMGCgoKqpU9cOAAnn76aeh0Onh7eyMqKsrgi161nffU1FSD38GWLVuavF4Af/etqT5A07TVhrLWdgRY9z2CyKwo+gAOkRlqzDtAyDwp/czqrFmzxMHBQQBI+/btZfPmzYrFUh+o5ztAwsLCxMPDQ3bt2iUZGRlSUlJisD46OloGDRokeXl5+mX+/v7SokULASA7duyots9du3bJq6++2vBKNDFrq8+pU6fk6aefFgDSo0ePGsvExcXJgAED5NatW406lrW3jwEDBkh8fLzk5ORIXl6eJCcni1qtlpdeesmg3G+//SZarVbmzZsnBQUF8uOPP0rLli1l3LhxBuVqOu+VlZWSlZUl+/fvl1deeUVatGhR7zgbcr/k77511acp2mpDWHs7soR7hNLjKSJjYAsmug8TINaHHXbDNCQB4uPjU+O6v/3tb9KpUycpLi42WO7v7y9ffPGF2NnZiY+Pj+Tm5hqst6TBq4h11efo0aMydOhQ2bBhgzzxxBO1JkBERCIiIqRv375SVlbWoGPZQvsYOHCglJeXGywbMWKEANC/3FhEJCQkRPz8/KSyslK/LCYmRlQqlfz+++8G2z/ovE+ZMqVJEyD83bee+jR1W60LW2hHlnCP4HiKrAEfgSEiIpM6c+YM5s2bhw8++AAajaba+sDAQERGRuLSpUt47733FIjQuKylPj169MDWrVsxatQoODo6PrDs/PnzcfToUcTFxdX7OLbSPnbs2IFmzZoZLKuafl5UVAQAKC8vx86dOzFgwACoVCp9uZdffhkigu3btxts35jz3hRs5dpWsZb6mFtbtZV2ZG7nnchaMQFCREQmtXz5cogIBg8eXGuZRYsWoVOnTlizZg327NnzwP2JCGJjY9G5c2c4OjrC3d0dQ4YMwcmTJ/VlEhIS4OTkBJ1Oh+3bt+Pll1+Gq6sr2rRpg40bNxrsr6KiAtHR0fD19YVWq0X37t2RnJzcqDpbW30ext3dHQMGDEBcXFy9vw5gi+2jyqVLl6DVauHn5wcA+OOPP1BQUABfX1+Dcv7+/gCAY8eOGSxvzHlvCrZ4ba2tPlWUbKu22I6qWPs9gkgRTT7nhMjM8REY68Mpmw0DIz0C06FDB+nSpUuN2/j7+8vZs2dFROTHH38UOzs7ad++vRQUFIhIzdOXo6OjxcHBQZKSkiQ3N1eOHTsmTz31lLRs2VKuXr2qLzdnzhwBIN9//73cvn1bsrOzpX///uLk5CSlpaX6cu+99544OjrKli1b5NatWzJ79myxs7OTn3/+uc51t9b6VPmv//qvBz4CI3L3XTcA5MiRI/Xaty21j3sVFhaKi4uLRERE6Jft27dPAEhMTEy18lqtVp577rlqy2s77+bwCIwtXVtrq8+9TN1WH8aW2tG9zPEewfEUWQPOACEiIpMpLCzE2bNn9X+depC+ffti6tSpOHfuHGbOnFljmeLiYsTGxmLo0KEYPXo0mjdvjm7dumH16tW4ceMGEhMTq20TGBgIV1dXeHp6IjQ0FIWFhbhw4QIAoKSkBAkJCQgKCkJwcDDc3Nwwd+5cqNVqrFu3rlF1t7b6PEzHjh0BAOnp6XXexpbbx0cffQRvb28sWrRIv6zqKw73T4MHALVajeLi4mrLG3Lem4ItX1trq4+SbdWW25G13yOIlGKvdABE5igrKwspKSlKh0FGcvDgQQDgNVVAdnY2RAQ6na5O5RctWoQdO3YgPj4eISEh1dYfP34cBQUF6NWrl8Hy3r17w8HBAWlpaQ/cv4ODAwCgrKwMAJCRkYGioiJ07dpVX0ar1cLLy8tgOnRDWVt9HqTqGl+7dq3O29hq+9i2bRtSUlLw3XffwcXFRb+86v0G5eXl1bYpLS2FVquttrwh570p2Oq1rWIt9VG6rdpqO1L6vBNZMyZAiGrw008/1dhxkmXjNW16JSUlAPDQl2hW0Wg0WLduHfr164c33ngDixcvNlifm5sLAHB2dq62rZubG/Lz8+sVX2FhIQBg7ty5mDt3rsE6b2/veu2rJtZWnwepGnhXXfO6sMX2sWnTJsTGxmLv3r145JFHDNZ5eXkBAPLy8gyWFxUVoaSkpMZjNuS8NwVbvLb3sob6mENbtcV2ZA7nncia8REYohoMGzYMcvcz0fyxgp+ql5EpHYel/RhD1cCroqKiztv07dsX7777Lk6fPo2FCxcarHNzcwOAGgepubm5aNOmTb3i8/T0BAAsW7asWv2rZg41lrXVpzalpaUAUONfIGtja+1jxYoV2LBhA3744Ydq/7ABAD8/P7i4uOD8+fMGy8+cOQMA6N69e7VtGnLem4KtXduaWHJ9zKWt2lo7MpfzTmTNmAAhIiKTadWqFVQqFW7fvl2v7RYuXIjHHnsMR44cMVjetWtXODs749ChQwbL09LSUFpaip49e9brOG3btoVGo8HRo0frtV19WVt9alJ1jVu3bl3nbWylfYgIoqKikJ6ejtTU1Br/+gwA9vb2eOWVV7B//35UVlbql+/atQsqlarGr2A05Lw3BVu5tg9jafUxt7ZqK+3I3M47kTVjAoSIiExGp9OhQ4cOyMrKqtd2VdOY73/Rm0ajwbRp07Bt2zZs2LABeXl5SE9Px8SJE+Ht7Y2wsLB6H2fcuHHYuHEjEhISkJeXh4qKCmRlZeHKlSsAgNDQULRu3RqHDx+u176tuT41qbrG3bp1q/NxbKV9nDhxAkuWLMEnn3wCtVoNlUpl8LN06VJ92Xnz5uHatWt4//33UVhYiIMHDyImJgZjx47Fo48+Wm3f9593c2Er19ba6tOUbZX3iP9ji/cIIsUIERngZ3CtDz/b1jAw0mdwIyIiRK1WS1FRkX7Ztm3bxN/fXwBIy5YtZfLkyTXuc/r06dU+YVhZWSkxMTHSsWNHUavV4u7uLkFBQZKRkaEvEx8fLzqdTgBIx44dJTMzUxITE8XV1VUASLt27eTUqVMiInLnzh2JiooSX19fsbe3F09PTwkODpbjx4+LiEhQUJAAkOjo6Frrbm31ERE5ePCgPP300+Lt7S0ABIB4eXlJYGCg7Nu3r1r5gQMHio+Pj1RWVtbrOLbQPtLT0/XnsKaf+z9puW/fPvnTn/4kjo6O4u3tLdOnT5eSkpIa933/ea9iDp/BtYVra231acq2ynvE/7GUewTHU2QN2IKJ7sMEiPVhh90wxkqAnD59Wuzt7SUpKcmY4TWZiooK6d+/v6xdu1bpUIzCFPW5ceOGaDQaWbp0ab2Pw/bRcDWd9yrmkADhtTUv5tZWeY8wPWPfIzieImvAR2CIiMhoiouLsXv3bpw+fVr/4rWAgAAsWLAACxYsQEFBgcIR1k9FRQVSU1ORn5+P0NBQpcNpNFPVZ/78+XjiiScQERFR7+OwfTTc/eddRHD58mUcOXRd0QAAIABJREFUOHBA/1LEpsLfffOmdH14jzCP867kPYLIXDABQkRERnPz5k289NJL6NSpE9544w398lmzZmH48OEIDQ2t98vslLR3715s3boVu3btgk6nUzqcRjNFfWJjY3H06FF88803UKvVDToO20f91XTet2/fDh8fH/Tv3x87d+5s0nj4u2/ezK2t8h5heuZ2jyAyG0pPQSEyNw19BObo0aMSEhIi7du3FwcHB2nRooV0795dFi5caFBu586d4urqKl999ZWxQn6omJgY8fT0FACyatWqOm2zZcsW8fPzq/YcqqOjo7Rv317GjRsnf/zxxwO3GT16dLX9vvDCC+Ls7Cx2dnbSpUsX+eWXXxq8XV1xymbDoJ6PwNTF7t27JSoqyqj7JOWkpqbKRx99JOXl5UbZH9tH3Rj7vN/LVPdLXlvbxHuEMkx1j+B4iqyBSkREkcwLkZkaPnw4AGDz5s113iY9PR19+vTB+PHjERkZCS8vL1y4cAFr167FL7/8gj179ujL7ty5EyNHjsSGDRswaNAgo8dfmzNnzqBjx45YtWoVwsPD67xdQEAAbty4gdzcXFRWVuLGjRvYvXs3wsPD4ezsjBMnTqBFixbVtsnNzUVOTg527NiBgQMHGqz/9ttvsXr1aqSmphplu4dJSUlBSEgIeLurH5VKheTkZIwYMULpUIioifB+SUS14f2BrAEfgSEygqVLl8LNzQ1xcXFo3749NBoNOnXqhIULF0Kr1RqUHThwIG7fvt2kyQ9jsbOzQ6tWrfDaa69h8uTJyM7ONkju3Gv58uWws7NDWFhYvaarNnQ7c1dcXIzAwECLPwYRERERkaViAoTICHJycnD79m3cvHnTYLmDgwO+/vprhaIyrYCAAADA1atXa1wfGBiIyMhIXLp0Ce+9916d99vQ7czd2rVrkZ2dbfHHICIiIiKyVEyAEBlB7969UVhYiGeffRb/+c9/ai134MAB+Pr6QqVSYeXKlQCAuLg4ODk5wc7ODj179kTr1q2hVqvh5OSEp556Cv3790fbtm2h0Wjg5uaGGTNm6Pe3fPlyaDQatGrVCuHh4fD29oZGo0FgYCDS0tIeGndFRQWio6Ph6+sLrVaL7t27Izk5uU51Pn36NACgR48etZZZtGgROnXqhDVr1tQ6U8SY2xmTiCA2NhadO3eGo6Mj3N3dMWTIEJw8eVJfJiIiAg4ODvDy8tIve/vtt+Hk5ASVSoUbN24AACIjIzFt2jRkZmZCpVIhICCgzteuMccA7j425Orqig8//NCk54uIiIiIyNwxAUJkBDNmzECvXr3w66+/ol+/fnj88cexZMmSajNC+vXrhx9//NFgWWRkJKZPnw4RwapVq3D27FlcvXoV/+///T8cOXIEs2bNwpEjR3Dz5k2MGTMGMTEx+PXXXwHc/cfx2LFjUVRUhClTpuDcuXM4fPgwysvL8cILL+DixYsPjHvmzJlYsmQJli1bhitXrmDQoEEYOXIkDh06VOs2ubm5+OyzzxAfH4+BAwfiz3/+c61ltVot1q9fDzs7O4wfPx6FhYUPOZON286Y5s+fj1mzZmHOnDnIzs7G/v37cfHiRfTv3x/Xrl0DcDcBdf/7MeLj4/HBBx8YLIuLi8OgQYPg7+8PEcGZM2fqfO0acwzgbpILACorK413coiIiIiILND/b+/eg6Mu7z2Of5bcdpdcgUCiIUK4ySWoFRQCHLSOVqBcYgIEGj3glIHQNoDUhrvc5eIkFCXjYB06U8/BJIJQqdhOR4FhQFoHEAoHlNhEQpBwC7lCbs/5g8mOSwIkZJNNtu/XzP7z7PP7Pd/nt8/uwCe/CwEI4AI2m02HDh3S73//ez366KM6ffq0UlJS1LdvX+3fv7/B++nXr5/sdrs6duyoKVOmSJIiIyPVqVMn2e12JSYmSpLTWQiS5O3t7ThToV+/fkpPT1dxcbG2bdt217Fu3ryp9PR0xcbGKi4uTsHBwVqyZIl8fHzqbHfjxg1ZLBZZLBaFhIRo+vTpWrRokT7++OP7zmno0KGaN2+ecnJytGDBggYfiwfdzhXKy8uVmpqql156SYmJiQoKClJ0dLTeffddXblyRVu3bnXZWA/y2TXGmDFjVFRUpKVLl7pkfwAAAEBbRQACuIiPj4+Sk5P1f//3f/ryyy81YcIEFRQUaOLEibp+/Xqj9+fr6ytJqqqqchpDkiorK++57aBBg2S32+sEJT929uxZlZWVacCAAY42m82msLCwOtsFBQXJGCNjjONslaCgIEc997N69Wr16dNHW7Zs0cGDBxu0TVO2a6pTp06ppKREgwYNcmofPHiwfH19G3R50YNqyGcHAAAAoPEIQIBm8PTTT+vjjz9WUlKSLl++rC+++KLFa/Dz89Ply5fv+n7tZSVLlixxnN1hsViUm5ursrKyu263dOlShYWFadGiRfe9xKaW1WrVtm3bZLFY9Oqrr6q8vLxZt2uqwsJCSZK/v3+d94KDg1VcXNys49/vswMAAADQeAQggAvExcU5nalR6+WXX5akewYKzaGyslKFhYWKiIi4a5/Q0FBJUlpamuPsjtrX4cOH77pdQECA1q1bp+LiYs2ePbvBNQ0dOlSvvfaavv32W61atarZt2uK4OBgSao36LjfcW2qhnx2AAAAABqPAARwgVu3bun06dN12s+ePStJGjhwYIvWs2/fPhljNGTIkLv2qX2yzPHjxxu9/1deeUVPP/209uzZo8zMzAZvt2rVKj366KM6duxYo8Z70O0e1IABA+Tv71/nZrBHjhxRRUWFnnzySUebt7f3fS9Jaoz6PjtXjwEAAAD8JyIAAVwkNjZWmZmZKiws1I0bN7R7924tWLBA48ePb/YApKamRtevX1dVVZVOnDihuXPnKjIyUtOmTbvrNlarVdOnT9f27duVnp6uoqIiVVdXKy8vTxcvXrzneBaLRZs3b5bFYlFycnKD73FSe0mLl5dXY6b3wNs9KKvVqvnz52vnzp364IMPVFRUpJMnTyopKUnh4eGaOXOmo2/Pnj117do17dq1S5WVlbp8+bJyc3Pr7LNDhw7Kz89XTk6OiouLHYFGQz67poyxd+9eHoMLAAAAiAAEcIk5c+Zo8ODBWrRokcLCwtS5c2elpKQoKSlJGRkZjn7vvPOOBg8eLElKSUnR+PHj9fvf/14bN26UJEVHR+vgwYNav369Zs2aJUl68cUX9b//+7/KyMjQiy++KOn2428//PBDx35v3ryp6Oho2Ww2jRgxQr1799YXX3whPz8/SVJqaqqGDx8uSfrtb3+ruLg4SbcfnTpv3jytX79eHTt2VHh4uObOnavr16/r0KFD6tOnj7Kzs3Xjxg09/PDDSkpKcoz51FNP6b//+7916dIlRUVFad26dfr444/Vs2dPZWdna/DgwfrNb35T51gNGTJEr732mlPbg27XnN544w2tXbtWK1euVKdOnTRy5Eh169ZN+/btU/v27R39Zs+erWeffVZTpkxRnz59tGrVKtlsNkm3L9+pvU9KUlKSOnfurH79+mn06NGORyTf77NzxRgAAAAAJIsxxri7CKA1mThxoiQpKyvLzZU0zKxZs5SVlaWrV6+6u5RWKzMzU5MnT1Zr+7lr7Z+dxWJRRkaGJk2a5O5SALSQ1vp7CcD9+H2AJ+AMEMADVFdXu7sEPCA+OwAAAKBlEIAAAAAAAACPRwACtGGLFi3Stm3bdOPGDXXv3l0fffSRu0tCA/HZAQAAAC3L290FAHhwa9eu1dq1a91dBh4Anx0AAADQsjgDBAAAAAAAeDwCEAAAAAAA4PEIQAAAAAAAgMcjAAEAAAAAAB6Pm6AC9fjyyy81ceJEd5cBF8nLy5MkPtMHkJaWpqysLHeXAaCF8HsJ4G5qfx+AtsxijDHuLgJoTVJTU3X48GF3lwEAkLR371498cQTCgsLc3cpAACJP4ygTSMAAQAArZbFYlFGRoYmTZrk7lIAAEAbxz1AAAAAAACAxyMAAQAAAAAAHo8ABAAAAAAAeDwCEAAAAAAA4PEIQAAAAAAAgMcjAAEAAAAAAB6PAAQAAAAAAHg8AhAAAAAAAODxCEAAAAAAAIDHIwABAAAAAAAejwAEAAAAAAB4PAIQAAAAAADg8QhAAAAAAACAxyMAAQAAAAAAHo8ABAAAAAAAeDwCEAAAAAAA4PEIQAAAAAAAgMcjAAEAAAAAAB6PAAQAAAAAAHg8AhAAAAAAAODxCEAAAAAAAIDHIwABAAAAAAAejwAEAAAAAAB4PAIQAAAAAADg8QhAAAAAAACAxyMAAQAAAAAAHo8ABAAAAAAAeDwCEAAAAAAA4PEIQAAAAAAAgMcjAAEAAAAAAB6PAAQAAAAAAHg8AhAAAAAAAODxvN1dAAAAgCQVFhbKGFOnvbS0VNevX3dq8/f3l4+PT0uVBgAAPIDF1PcvDQAAgBb205/+VF988cV9+3l5eenChQvq0qVLC1QFAAA8BZfAAACAVmHKlCmyWCz37NOuXTv913/9F+EHAABoNAIQAADQKsTHx8vb+95X51osFr3yyistVBEAAPAkBCAAAKBVCAkJ0QsvvCAvL6+79mnXrp1iY2NbsCoAAOApCEAAAECrkZiYqJqamnrf8/b21pgxYxQUFNTCVQEAAE9AAAIAAFqNcePGyc/Pr973qqurlZiY2MIVAQAAT0EAAgAAWg273a7Y2Nh6H3Frs9k0evRoN1QFAAA8AQEIAABoVaZOnarKykqnNh8fH8XHx8tms7mpKgAA0NYRgAAAgFblZz/7WZ37fFRWVmrq1KluqggAAHgCAhAAANCq+Pj4KCEhQb6+vo624OBgPffcc26sCgAAtHUEIAAAoNWZMmWKKioqJN0ORBITE+Xt7e3mqgAAQFtmMcYYdxcBAADwYzU1NXrooYd06dIlSdLBgwc1bNgwN1cFAADaMs4AAQAArU67du308ssvS5LCw8MVExPj5ooAAEBbx7mkAFqdvLw8HTp0yN1lAHCzTp06SZKefvppZWVlubkaAO7WtWtXDR061N1lAGjDuAQGQKuTmZmpyZMnu7sMAADQisTHxxOGAmgSzgAB0GqRz+JOEydOlCT+AdwItYFiW/0+ffTRR4qPj3d3GXgAfF/hSrXrCQCagnuAAACAVovwAwAAuAoBCAAAAAAA8HgEIAAAAAAAwOMRgAAAAAAAAI9HAAIAAAAAADweAQgAAAAAAPB4BCAAPNIvf/lLBQQEyGKx6Pjx4+4up9XU01rqcLdPP/1UQUFB+uSTT9xdCgAAAFoIAQgAj/SHP/xB7733nrvLcGgt9bSWOtzNGOPuEgAAANDCvN1dAAAALW3MmDG6ceOGu8uQJJWXl+u5557ToUOH3F0KAACAR+MMEAAey2KxuLsEJ62lntZSB257//33VVBQ4O4yAAAAPB4BCACPYIzRxo0b1adPH/n5+SkoKEivv/56nX7V1dVatmyZIiMjZbPZNHDgQGVkZDj1+dOf/qRBgwbJarWqffv26tatm1atWuUYJzU1VX379pWfn59CQkI0YcIEnTlzxuX1bNiwQXa7XQEBASooKND8+fP18MMP6+zZsy16XNLT09W+fXvZ7Xbt3r1bo0aNUmBgoCIiIrR9+3an/ezfv19PPfWU7Ha7AgMDFR0draKiogYf+5Zw8OBBRUZGymKx6J133mnUHDdv3iyr1arOnTtr1qxZCg8Pl9VqVUxMjI4cOeLol5ycLF9fX4WFhTnafvWrX6l9+/ayWCy6cuWKJGnu3LmaP3++srOzZbFY1LNnT0nSZ599psDAQK1Zs6YlDgkAAMB/BAIQAB5h6dKlSklJ0cyZM3Xp0iX98MMPWrBgQZ1+CxYs0IYNG5SWlqaLFy9q7Nixmjp1qr766itJ0qZNm/TKK68oPj5e+fn5ysvL06JFixyhw/Lly7Vw4UItXrxYBQUFOnDggM6fP68RI0bo0qVLLq3nd7/7nV577TWVlJRo7dq16t69u4YMGdKo+1e4oo7Zs2dr3rx5Ki8vV0BAgDIyMpSdna2oqCjNmDFDlZWVkqTS0lKNGzdO8fHxunbtmr799lv17t1bFRUVDTr2LWX48OF1Ljdp6ByTk5M1bdo0lZWVac6cOcrJydHRo0dVVVWl559/XufPn5d0OyiZNGmS0xhbtmzRihUrnNo2bdqksWPHqkePHjLG6Ny5c5Juh0WSVFNT0yzHAAAA4D+SAYBWJiMjwzTm56msrMzY7Xbz/PPPO7Vv377dSDLHjh0zxhhTXl5u7Ha7SUhIcNrWz8/PzJ4921RUVJjg4GDz7LPPOu2nqqrKbNq0yZSVlRl/f3+n7Y0x5h//+IeRZFauXOnSeowxZvHixUaSKS8vb/DxcPVxuVsdW7ZsMZLMuXPnjDHG/Otf/zKSzJ49e+rU0pAxGiI+Pt7Ex8c3uP/dnD9/3kgyb7/9tqOtIXM0xpiZM2eaoKAgp/3985//NJLMihUrHG2/+MUvTJcuXZz6bdy40Ugyly9fdrTFxcWZHj16NHlOd9PY7xPgKq76vgLGsJ4AuAZngABo886dO6eysjI999xz9+x39uxZlZWVacCAAY42m82msLAwnTlzRidOnFBhYaF+9rOfOW3n5eWlOXPm6NSpUyopKdGgQYOc3h88eLB8fX0dl0C4qp6mau46fH19JclxdkRUVJQ6d+6sxMRELV++XDk5OU0ew93unOPdDBo0SHa7vVXPBQAA4D8dAQiANi8vL0+SFBoaes9+paWlkqQlS5bIYrE4Xrm5uSorK3PcqyI4OLje7QsLCyVJ/v7+dd4LDg5WcXGxS+tpqpauw2az6fPPP9fw4cO1Zs0aRUVFKSEhQeXl5c0+19bAz89Ply9fdncZAAAAuAsCEABtntVqlSTdunXrnv1qg4C0tDQZY5xehw8f1kMPPSRJjhtU3qk2GKkNOn6ssLBQERERLq2nqdxRR//+/fXJJ58oPz9fKSkpysjI0FtvvdXsc3W3yspKpzUAAACA1ocABECbN2DAALVr10779++/Z7+uXbvKarXq+PHj9b7frVs3dejQQX/729/uOo6/v3+dm3YeOXJEFRUVevLJJ11aT1O1dB35+fk6ffq0pNuhyptvvqmf/OQnOn36dLPP1d327dsnY4yGDBniaPP29r7vpTMAAABoOQQgANq80NBQxcXF6aOPPtL777+voqIinThxQlu3bnXqZ7VaNX36dG3fvl3p6ekqKipSdXW18vLydPHiRfn5+WnRokU6cOCAkpOTdeHCBdXU1Ki4uFinT5+W1WrV/PnztXPnTn3wwQcqKirSyZMnlZSUpPDwcM2cOdOl9bSW49JQ+fn5mjVrls6cOaOKigodO3ZMubm5GjJkSLPPtaXV1NTo+vXrqqqq0okTJzR37lxFRkZq2rRpjj49e/bUtWvXtGvXLlVWVury5cvKzc2ts68OHTooPz9fOTk5Ki4uVmVlpfbu3ctjcAEAAFytxW+7CgD38SBPrSguLja//OUvTceOHY2/v78ZPny4WbZsmZFkIiIizNdff22MMebWrVsmJSXFREZGGm9vbxMaGmri4uLMqVOnHPt65513THR0tLFarcZqtZonnnjCbNmyxRhjTE1Njdm4caPp1auX8fHxMSEhISY2NtacPXvW5fWsX7/e2Gw2I8l07drV/OlPf2r0sXRFHVu2bDF2u91IMr169TLZ2dlm69atJjAw0EgyjzzyiPnmm29MTk6OiYmJMSEhIcbLy8s89NBDZvHixaaqqqrBx/5+XPEUgLffftuEhYUZScZut5tx48Y1eI7G3H4KjI+Pj3n44YeNt7e3CQwMNBMmTDDZ2dlO41y9etU8++yzxmq1mu7du5vf/OY35vXXXzeSTM+ePc33339vjDHm6NGj5pFHHjE2m80MHz7c/PDDD+bTTz81AQEBZvXq1U2aqzE8BQbuw1M74EqsJwCuYDHGGPdELwBQv8zMTE2ePFn8POFOEydOlCRlZWW5rYZZs2YpKytLV69edVsNjcH3Ce7SGr6v8BysJwCuwCUwAAA0UnV1tbtLAAAAQCMRgABAG3LmzBmnx8je7ZWQkODuUuEh/v73v2vhwoXasWOHoqKiHGvs5ZdfrtP3hRdeUEBAgLy8vNS/f38dPXrUDRU3jKfNR5JWrlypfv36KTAwUH5+furZs6d+97vfqaSkpE7fgwcPatiwYbLb7QoPD1dKSorTE6P+/Oc/a/369W4N+1h7bWM+P1ZTU6O0tDTFxMTUea81rCkA4KJgAK0O9yzA3bj7GvCFCxcaX19fI8l069bNZGVlua2WhmrK92nZsmVm7NixpqioyNHWo0cP07FjRyPJ7Nmzp842e/fuNePHj3/geluaJ81n5MiRZsuWLebq1aumqKjIZGRkGB8fH/Piiy869fvXv/5lbDabWbp0qSkpKTGHDh0ynTp1MtOnT3fqt2nTJjNy5Ehz/fr1B6qnKd9X1l7bm88333xjhg0bZiSZxx57rN4+TVlT7v79B+AZOAMEAIAGWrt2rW7duiVjjP79738rPj7e3SU1m3Xr1unDDz9UZmamAgICnN7bvHmz2rVrp5kzZ+rGjRtuqtB1PGU+/v7+mjlzpjp06KCAgABNmjRJsbGx+uyzz3T+/HlHv1WrViksLEwrVqxQ+/btNXToUKWkpOiPf/yjzpw54+g3Z84cPfbYYxo9erSqqqpabB6svbbn66+/1oIFC5SUlKTHH3/8rv3ctaYAoBYBCAAAcHLu3DktXbpUK1askNVqrfN+TEyM5s6dqwsXLui3v/2tGyp0LU+Zz549e+Tl5eXU1qlTJ0lSWVmZJKmqqkp/+ctfNHLkSFksFke/UaNGyRij3bt3O22/fPlyHT9+XJs2bWrm6m9j7bVNjz32mHbs2KFf/OIX8vPzu2ffll5TAPBjBCAAAMDJ5s2bZYzRuHHj7tpn9erV6t27t/7whz/o73//+z33Z4xRamqq+vbtKz8/P4WEhGjChAlOZxukp6erffv2stvt2r17t0aNGqXAwEBFRERo+/btTvurrq7WsmXLFBkZKZvNpoEDByojI6NJc/a0+dS6cOGCbDabunfvLkn67rvvVFJSosjISKd+PXr0kCSdOHHCqT0kJEQjR47Upk2bWuRJQqy9tj+f+2npNQUAP0YAAgAAnPzlL39Rnz59ZLfb79rHZrPpj3/8o9q1a6cZM2aotLT0rn2XL1+uhQsXavHixSooKNCBAwd0/vx5jRgxQpcuXZIkzZ49W/PmzVN5ebkCAgKUkZGh7OxsRUVFacaMGaqsrHTsb8GCBdqwYYPS0tJ08eJFjR07VlOnTtVXX331wHP2tPlIt8/6+PzzzzVjxgz5+vpKkn744QdJqnNpidVqlc1mc9T/Y0888YQuXLigr7/+ukn1NARrr+3PpyFack0BwI8RgAAAAIfS0lL9+9//dpwRcC9Dhw7VvHnzlJOTowULFtTbp7y8XKmpqXrppZeUmJiooKAgRUdH691339WVK1e0devWOtvExMQoMDBQoaGhSkhIUGlpqb7//ntJ0s2bN5Wenq7Y2FjFxcUpODhYS5YskY+Pj7Zt29akuXvafNauXavw8HCtXr3a0Vb7pJc7L5WRJB8fH5WXl9dp79WrlyTp5MmTTarnflh7njOf+2mpNQUAd/J2dwEAcDcTJ050dwloZb788ktJrI3GyMvLa1T/goICGWPu+Rf4H1u9erX27NmjLVu2aPLkyXXeP3XqlEpKSjRo0CCn9sGDB8vX11dHjhy55/5rz1yo/av12bNnVVZWpgEDBjj62Gw2hYWFOV0G8KA8ZT47d+5UZmam/va3vzmd7VF7X436bkBZUVEhm81Wp712LdR3dogrsfY8az730lJrCgDuxBkgAADA4ebNm5J03xsZ1rJardq2bZssFoteffXVOmcQFBYWSrr9hJI7BQcHq7i4uFH11V4esGTJElksFscrNzfXcaPPpvCE+Xz44Ydat26d9u3bp27dujm9FxYWJkkqKipyai8rK9PNmzcVHh5eZ3+1oUjt2mgurD3Pms+9tNSaAoA7cQYIgFYrKyvL3SWglak984O10XCZmZn1/jX5bmr/Y1JdXd3gbYYOHarXXntNb731llatWuV0g83g4GBJqvc/Z4WFhYqIiGjwOJIUGhoqSUpLS9PcuXMbtW1DteX5vP322/rrX/+qzz//vN7/KHfv3l0BAQHKzc11aj937pwkaeDAgXW2qaiokKR6zw5xJdae583nblpqTQHAnTgDBAAAOHTu3FkWi0U3btxo1HarVq3So48+qmPHjjm1DxgwQP7+/nVuqnjkyBFVVFToySefbNQ4Xbt2ldVq1fHjxxu1XWO1tfkYY5SSkqKTJ09q165d9YYfkuTt7a3Ro0frwIEDqqmpcbTv3btXFoul3qev1K6FLl26NKnG+2Ht3eZp86lPS60pALgTAQgAAHCw2+2Kiopq9L1Dak/fv/PmmlarVfPnz9fOnTv1wQcfqKioSCdPnlRSUpLCw8M1c+bMRo8zffp0bd++Xenp6SoqKlJ1dbXy8vJ08eJFSVJCQoK6dOmio0ePNmrfbXk+p0+f1oYNG/Tee+/Jx8fH6ZIGi8Wit956y9F36dKlunTpkt544w2Vlpbq8OHD2rhxo6ZNm6Y+ffrU2XftWoiOjm7U3BqLteeZ86lPS60pAKjDAEArk5GRYfh5Qn3i4+NNfHy8u8toUx7k+5ScnGx8fHxMWVmZo23nzp2mR48eRpLp1KmT+fWvf13vtq+//roZP368U1tNTY3ZuHGj6dWrl/Hx8TEhISEmNjbWnD171tFny5Ytxm63G0mmV69eJjs722zdutUEBgYaSeaRRx4x33zzjTHGmFu3bpmUlBQTGRlpvL29TWhoqImLizOnTp0yxhgTGxtrJJlly5bddY6eNp+TJ08aSXd9bdy40an//v37zVNPPWX8/PxMeHjgTUxZAAAJMUlEQVS4ef31183Nmzfr3feYMWPMww8/bGpqau46fn0e5PvK2mt78zHGmMOHD5thw4aZ8PBwx5oLCwszMTExZv/+/XX6P8ia4vcfgCtYjDGmhbIWAGiQ2nsW8POEO3EPkMZ7kO/TuXPn1LdvX23btk2JiYnNWF3zqKmp0TPPPKNp06bp1VdfdXc5TebO+Vy9elURERFavXq15s+f36htH+T7ytprXZpjPg+6pvj9B+AKXAIDAACc9OzZUytXrtTKlStVUlLi7nIapbq6Wrt27VJxcbESEhLcXU6TuXs+y5cv1+OPP67k5OQWGY+113o013xaek0BwI8RgACAC+zYsUNRUVF1rrv39fVV586d9cwzz2jjxo26fv26u0sFGmThwoWaOHGiEhISGn1TSnfat2+fduzYob1798put7u7nCZz53xSU1N1/Phxffrpp/Lx8WmxcVl7rUNzzMddawoAahGAAIALxMXF6bvvvlOPHj0UFBQkY4xqampUUFCgzMxMde/eXSkpKerfv3+dO/gDrdWaNWuUnJysN998092lNNhzzz2n//mf/1FYWJi7S3EJd81n9+7dunXrlvbt26eQkJAWHVti7bUGrp6Pu9cUAEgEIADQbCwWi4KDg/XMM89o27ZtyszM1KVLlzRmzJg29VdNOCsvL1dMTEybH6OhXnjhBa1bt87dZaCFjR8/XgsXLqzzJJKWxNrzLK1hTQEAAQgAtJD4+HhNmzZNBQUFevfdd91dDh7Q+++/r4KCgjY/BgAAwH8aAhAAaEHTpk2TJO3du9fRVl1drWXLlikyMlI2m00DBw5URkaGJCk9PV3t27eX3W7X7t27NWrUKAUGBioiIkLbt2932vf+/fv11FNPyW63KzAwUNHR0SoqKrrvGJ7OGKPU1FT17dtXfn5+CgkJ0YQJE3TmzBlHn+TkZPn6+jqd6v2rX/1K7du3l8Vi0ZUrVyRJc+fO1fz585WdnS2LxaKePXtq8+bNslqt6ty5s2bNmqXw8HBZrVbFxMToyJEjLhlDkj777DMFBgZqzZo1zXq8AAAAPBUBCAC0oMcff1yS9N133znaFixYoA0bNigtLU0XL17U2LFjNXXqVH311VeaPXu25s2bp/LycgUEBCgjI0PZ2dmKiorSjBkzVFlZKUkqLS3VuHHjFB8fr2vXrunbb79V7969VVFRcd8xPN3y5cu1cOFCLV68WAUFBTpw4IDOnz+vESNG6NKlS5KkzZs3a9KkSU7bbdmyRStWrHBq27Rpk8aOHasePXrIGKNz584pOTlZ06ZNU1lZmebMmaOcnBwdPXpUVVVVev7553X+/PkmjyHdDrGk24+lBAAAQOMRgABACwoICJDFYlFxcbEk6ebNm0pPT1dsbKzi4uIUHBysJUuWyMfHR9u2bXPaNiYmRoGBgQoNDVVCQoJKS0v1/fffS5JycnJUVFSk/v37y2q1qkuXLtqxY4c6derUqDE8TXl5uVJTU/XSSy8pMTFRQUFBio6O1rvvvqsrV65o69atLhvL29vbcZZJv379lJ6eruLiYpcd4zFjxqioqEhLly51yf4AAAD+0xCAAEALKi0tlTFGgYGBkqSzZ8+qrKxMAwYMcPSx2WwKCwtzukTjTr6+vpLkOAMkKipKnTt3VmJiopYvX66cnBxH3wcdwxOcOnVKJSUlGjRokFP74MGD5evr63SJiqsNGjRIdrvd448xAABAW0EAAgAt6JtvvpEkPfroo5JuByKStGTJElksFscrNzdXZWVlDd6vzWbT559/ruHDh2vNmjWKiopSQkKCysvLXTZGW1RYWChJ8vf3r/NecHCw40yc5uLn56fLly836xgAAABoGAIQAGhBn332mSRp1KhRkqTQ0FBJUlpamowxTq/Dhw83at/9+/fXJ598ovz8fKWkpCgjI0NvvfWWS8doa4KDgyWp3qCjsLBQERERzTZ2ZWVls48BAACAhiMAAYAW8sMPPygtLU0RERF69dVXJUldu3aV1WrV8ePHm7Tv/Px8nT59WtLtUOXNN9/UT37yE50+fdplY7RFAwYMkL+/f52bvR45ckQVFRV68sknHW3e3t6OS4pcYd++fTLGaMiQIc02BgAAABqOAAQAXMwYo5KSEtXU1MgYo8uXLysjI0PDhg2Tl5eXdu3a5bgHiNVq1fTp07V9+3alp6erqKhI1dXVysvL08WLFxs8Zn5+vmbNmqUzZ86ooqJCx44dU25uroYMGeKyMdoiq9Wq+fPna+fOnfrggw9UVFSkkydPKikpSeHh4Zo5c6ajb8+ePXXt2jXt2rVLlZWVunz5snJzc+vss0OHDsrPz1dOTo6Ki4sdgUZNTY2uX7+uqqoqnThxQnPnzlVkZKTj0cdNHWPv3r08BhcAAKAJCEAAwAU++eQTPfbYY7p48aJu3rypoKAgeXl5ycvLS71791ZqaqqmTZumU6dOOZ11IN1+7Om8efO0fv16dezYUeHh4Zo7d66uX7+u9PR0paWlSZIGDhyo7777Tu+9957mz58vSXrxxRf17bffKjQ0VNXV1YqJiZHdbtfPf/5zzZo1S7/+9a/vO4ane+ONN7R27VqtXLlSnTp10siRI9WtWzft27dP7du3d/SbPXu2nn32WU2ZMkV9+vTRqlWrZLPZJElDhw51PM42KSlJnTt3Vr9+/TR69Ghdu3ZN0u0n+kRHR8tms2nEiBHq3bu3vvjiC/n5+blsDAAAADw4izHGuLsIAPixzMxMTZ48Wfw84U4TJ06UJGVlZbm5EmezZs1SVlaWrl696u5S6uD7BHdprd9XtE2sJwCuwBkgAAC4QHV1tbtLAAAAwD0QgAAAAAAAAI9HAAIAQBMsWrRI27Zt040bN9S9e3d99NFH7i4JAAAA9fB2dwEAALRla9eu1dq1a91dBgAAAO6DM0AAAAAAAIDHIwABAAAAAAAejwAEAAAAAAB4PAIQAAAAAADg8QhAAAAAAACAx+MpMABaLYvF4u4S0EqxNhqPYwZ3Ye3BVeLj491dAoA2zmKMMe4uAgB+LC8vT4cOHXJ3GQAAoBXp2rWrhg4d6u4yALRhBCAAAAAAAMDjcQ8QAAAAAADg8QhAAAAAAACAxyMAAQAAAAAAHs9bUpa7iwAAAAAAAGhO/w/7WeLKkqeV+AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zzWYiIVCHywT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Prepare data with one-step output"
      ],
      "metadata": {
        "id": "BGN4pPQB93F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to train the unified ***seq2seq_model*** model, we need to prepare the following inputs and outputs:\n",
        "\n",
        "\n",
        "*   input1 : encoder_input_x : an input sequence for the encoder (later we will refer to it sas ***encoder_x***)\n",
        "*   input2 : decoder_input_x an input sequence for the decoder (later we will refer to it sas ***decoder_x***)\n",
        "*   output : decode_dense.output a prediction output of decoder (later we will refer to it sas ***decoder_y***)\n",
        "\n",
        "values of encoder_x and decoder_y are straightforward. For example, one training sampling with 5-step inputs and 3-step prediction output will be link encder_x[i] = [2,4,6,8,10] and decoder_y[i] = [12,14,16] \n",
        "\n",
        "the one whose calue need additional consideration is decoder_x. Here we use ***Teacher Forcing***, the popular training technique in meching translation, so if encder_x[i] = [2,4,6,8,10] and decoder_y[i] = [12,14,16] then decoder_x[i] = ['<\\s>',12,14]"
      ],
      "metadata": {
        "id": "1ByWUinrMW8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Genarate squence data"
      ],
      "metadata": {
        "id": "XutHJeZ1MKzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_data = 2000 #Number of genarate data\n",
        "\n",
        "#TimeseriesGenerator\n",
        "sampling_rate = 2     #for 2 consecutive numbers, sample only one\n",
        "n_input_timesteps = 5 #How many timestep for the input sequence\n",
        "\n",
        "dataset = np.array([ i for i in range(n_data*-sampling_rate, n_data*sampling_rate)])\n",
        "\n",
        "gen_dataset = tf.keras.preprocessing.sequence.TimeseriesGenerator( dataset, dataset, length=sampling_rate*n_input_timesteps, batch_size=n_data, sampling_rate=sampling_rate)\n",
        "\n",
        "x, y = gen_dataset[0]"
      ],
      "metadata": {
        "id": "wbNpyLEYMEhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview the first five rows and the last five rows\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640d285f-5b1b-46ad-fc42-623bd571215d",
        "id": "rfiXKcgGMEhf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(2000, 5), y-shape:(2000,)\n",
            "0 : [-4000 -3998 -3996 -3994 -3992] , -3990\n",
            "1 : [-3999 -3997 -3995 -3993 -3991] , -3989\n",
            "2 : [-3998 -3996 -3994 -3992 -3990] , -3988\n",
            "3 : [-3997 -3995 -3993 -3991 -3989] , -3987\n",
            "4 : [-3996 -3994 -3992 -3990 -3988] , -3986\n",
            "-1 : [-2001 -1999 -1997 -1995 -1993] , -1991\n",
            "-2 : [-2002 -2000 -1998 -1996 -1994] , -1992\n",
            "-3 : [-2003 -2001 -1999 -1997 -1995] , -1993\n",
            "-4 : [-2004 -2002 -2000 -1998 -1996] , -1994\n",
            "-5 : [-2005 -2003 -2001 -1999 -1997] , -1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data (before splitting it in to train/val/test sets later inthe next cell)\n",
        "\n",
        "#Shuffle the data\n",
        "seed=1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(x)\n",
        "\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(y)\n",
        "\n",
        "# Preview the first five rows of data\n",
        "print(f\"x-shape:{x.shape}, y-shape:{y.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")\n",
        "for i in range(-1, -6, -1):\n",
        "  print(f\"{i} : {x[i]} , {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd70a37-23d1-42f1-9535-bf86959ad5a3",
        "id": "q9x6R2S_MEhf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-shape:(2000, 5), y-shape:(2000,)\n",
            "0 : [-3033 -3031 -3029 -3027 -3025] , -3023\n",
            "1 : [-3372 -3370 -3368 -3366 -3364] , -3362\n",
            "2 : [-3423 -3421 -3419 -3417 -3415] , -3413\n",
            "3 : [-3911 -3909 -3907 -3905 -3903] , -3901\n",
            "4 : [-2829 -2827 -2825 -2823 -2821] , -2819\n",
            "-1 : [-2825 -2823 -2821 -2819 -2817] , -2815\n",
            "-2 : [-3811 -3809 -3807 -3805 -3803] , -3801\n",
            "-3 : [-3140 -3138 -3136 -3134 -3132] , -3130\n",
            "-4 : [-2744 -2742 -2740 -2738 -2736] , -2734\n",
            "-5 : [-2809 -2807 -2805 -2803 -2801] , -2799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = int(n_data * 0.8)       # Split 80% to train set\n",
        "n_test = int(n_data * 0.1)        # Split 10% to test set\n",
        "n_val = n_data -n_train -n_test   # 10% to validate set\n",
        "\n",
        "encoder_x_train, ynext_train = x[:n_train] , y[:n_train] \n",
        "encoder_x_val, ynext_val = x[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "encoder_x_test, ynext_test = x[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"x_train-shape:{encoder_x_train.shape}, y_train-shape:{ynext_train.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} x:{encoder_x_train[i]}, y:{ynext_train[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"x_val-shape:{encoder_x_val.shape}, y_val-shape:{ynext_val.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} x:{encoder_x_val[i]}, y:{ynext_val[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"x_test-shape:{encoder_x_test.shape}, y_test-shape:{ynext_test.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} x:{encoder_x_test[i]}, y:{ynext_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7489bcb3-8b4e-47b6-f4a1-b77a3237e66e",
        "id": "coYVjxAvMEhg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "x_train-shape:(1600, 5), y_train-shape:(1600,)\n",
            "0 x:[-3033 -3031 -3029 -3027 -3025], y:-3023\n",
            "1 x:[-3372 -3370 -3368 -3366 -3364], y:-3362\n",
            "2 x:[-3423 -3421 -3419 -3417 -3415], y:-3413\n",
            "3 x:[-3911 -3909 -3907 -3905 -3903], y:-3901\n",
            "4 x:[-2829 -2827 -2825 -2823 -2821], y:-2819\n",
            "\n",
            "===== Validation data =====\n",
            "x_val-shape:(200, 5), y_val-shape:(200,)\n",
            "0 x:[-3200 -3198 -3196 -3194 -3192], y:-3190\n",
            "1 x:[-3488 -3486 -3484 -3482 -3480], y:-3478\n",
            "2 x:[-2285 -2283 -2281 -2279 -2277], y:-2275\n",
            "3 x:[-3846 -3844 -3842 -3840 -3838], y:-3836\n",
            "4 x:[-2724 -2722 -2720 -2718 -2716], y:-2714\n",
            "\n",
            "===== Test data =====\n",
            "x_test-shape:(200, 5), y_test-shape:(200,)\n",
            "0 x:[-2126 -2124 -2122 -2120 -2118], y:-2116\n",
            "1 x:[-3343 -3341 -3339 -3337 -3335], y:-3333\n",
            "2 x:[-3710 -3708 -3706 -3704 -3702], y:-3700\n",
            "3 x:[-3995 -3993 -3991 -3989 -3987], y:-3985\n",
            "4 x:[-2885 -2883 -2881 -2879 -2877], y:-2875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Prepare the 3-step output (decoder_y)"
      ],
      "metadata": {
        "id": "pHaCl0ERPKy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_output_timesteps = 3 #how many time step a head to predict\n",
        "\n",
        "#Create decoder_y from ynext\n",
        "decoder_y_train = np.zeros( (ynext_train.shape[0],n_output_timesteps), dtype=ynext_train.dtype)\n",
        "decoder_y_test  = np.zeros( (ynext_test.shape[0],n_output_timesteps) , dtype=ynext_test.dtype)\n",
        "decoder_y_val   = np.zeros( (ynext_val.shape[0],n_output_timesteps)  , dtype=ynext_val.dtype)\n",
        "\n",
        "#Copy original value to vector\n",
        "decoder_y_train[:,0] = ynext_train[:]\n",
        "decoder_y_test[:,0]  = ynext_test[:]\n",
        "decoder_y_val[:,0]   = ynext_val[:]\n",
        "\n",
        "print(decoder_y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUV5XQ1nMEhg",
        "outputId": "c4dd0be2-c481-47aa-8e69-30bc9c832a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3023     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute values for the 1stand 2nd columns of each array\n",
        "for i in range(1,n_output_timesteps):\n",
        "  decoder_y_train[:,i] = decoder_y_train[:,i-1] +2\n",
        "  decoder_y_test[:,i]  = decoder_y_test[:,i-1] +2\n",
        "  decoder_y_val[:,i]   = decoder_y_val[:,i-1] +2\n",
        "\n",
        "print(decoder_y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AUOKjUoMEhg",
        "outputId": "a1b85a47-7f91-43a7-e0ee-019e6eb8925c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3023 -3021 -3019]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview Before-After result\n",
        "print(f\"\\n========== y_train ==========\")\n",
        "print(f\"Shape before:{ynext_train.shape} after:{decoder_y_train.shape}\")\n",
        "print(f\"Example befor : {ynext_train[0]} , after ; {decoder_y_train[0]}\")\n",
        "\n",
        "print(f\"\\n========== y_test ==========\")\n",
        "print(f\"Shape before:{ynext_test.shape} after:{decoder_y_test.shape}\")\n",
        "print(f\"Example befor : {ynext_test[0]} , after ; {decoder_y_test[0]}\")\n",
        "\n",
        "print(f\"\\n========== y_val ==========\")\n",
        "print(f\"Shape before:{ynext_val.shape} after:{decoder_y_val.shape}\")\n",
        "print(f\"Example befor : {ynext_val[0]} , after ; {decoder_y_val[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b1a71e-6ea6-4fe9-f281-767298cb69bf",
        "id": "WGYnS1teMEhh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== y_train ==========\n",
            "Shape before:(1600,) after:(1600, 3)\n",
            "Example befor : -3023 , after ; [-3023 -3021 -3019]\n",
            "\n",
            "========== y_test ==========\n",
            "Shape before:(200,) after:(200, 3)\n",
            "Example befor : -2116 , after ; [-2116 -2114 -2112]\n",
            "\n",
            "========== y_val ==========\n",
            "Shape before:(200,) after:(200, 3)\n",
            "Example befor : -3190 , after ; [-3190 -3188 -3186]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 Normalize the data"
      ],
      "metadata": {
        "id": "XXJyaEuuR2vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max scaling to normalize the data to range [0, 1]\n",
        "#.fit_transfrom expects 2D input\n",
        "minmax_norm = MinMaxScaler().fit(encoder_x_train.reshape(-1,1))\n",
        "print(f\"Dataset min-max: {minmax_norm.data_min_}, {minmax_norm.data_max_}\")\n",
        "\n",
        "encoder_x_train_norm = minmax_norm.transform( encoder_x_train.reshape(-1,1)).reshape(encoder_x_train.shape)\n",
        "decoder_y_train_norm = minmax_norm.transform( decoder_y_train.reshape(-1,1)).reshape(decoder_y_train.shape)\n",
        "\n",
        "encoder_x_val_norm = minmax_norm.transform( encoder_x_val.reshape(-1,1)).reshape(encoder_x_val.shape)\n",
        "decoder_y_val_norm = minmax_norm.transform( decoder_y_val.reshape(-1,1)).reshape(decoder_y_val.shape)\n",
        "\n",
        "encoder_x_test_norm = minmax_norm.transform( encoder_x_test.reshape(-1,1)).reshape(encoder_x_test.shape)\n",
        "decoder_y_test_norm = minmax_norm.transform( decoder_y_test.reshape(-1,1)).reshape(decoder_y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a82c1b-9081-44ea-a5a8-5feb17cabc22",
        "id": "DNK86VRcMEhh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset min-max: [-4000.], [-1993.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into (batch_size, time_step, input_dim) as required by the SimpleRNN layer\n",
        "print(\"\\n===== Train data after normalization (encoder_x,decoder_y) =====\")\n",
        "print(f\"x_train_norm:{encoder_x_train_norm.shape}, y_train_norm:{decoder_y_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {encoder_x_train_norm[i]} , {decoder_y_train_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Validation data after normalization (encoder_x,decoder_y) =====\")\n",
        "print(f\"x_val_norm:{encoder_x_val_norm.shape}, y_val_norm:{decoder_y_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {encoder_x_val_norm[i]} , {decoder_y_val_norm[i]}\")\n",
        "\n",
        "print(\"\\n===== Test data after normalization (encoder_x,decoder_y) =====\")\n",
        "print(f\"x_test_norm:{encoder_x_test_norm.shape}, y_test_norm:{decoder_y_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {encoder_x_test_norm[i]} , {decoder_y_test_norm[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f06eb94-426c-436b-9952-0eb6758ae51e",
        "id": "Lp8hNQgCMEhh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data after normalization (encoder_x,decoder_y) =====\n",
            "x_train_norm:(1600, 5), y_train_norm:(1600, 3)\n",
            "0 : [0.48181365 0.48281016 0.48380668 0.48480319 0.4857997 ] , [0.48679621 0.48779273 0.48878924]\n",
            "1 : [0.31290483 0.31390135 0.31489786 0.31589437 0.31689088] , [0.31788739 0.31888391 0.31988042]\n",
            "2 : [0.28749377 0.28849028 0.2894868  0.29048331 0.29147982] , [0.29247633 0.29347285 0.29446936]\n",
            "3 : [0.04434479 0.04534131 0.04633782 0.04733433 0.04833084] , [0.04932735 0.05032387 0.05132038]\n",
            "4 : [0.5834579  0.58445441 0.58545092 0.58644743 0.58744395] , [0.58844046 0.58943697 0.59043348]\n",
            "\n",
            "===== Validation data after normalization (encoder_x,decoder_y) =====\n",
            "x_val_norm:(200, 5), y_val_norm:(200, 3)\n",
            "0 : [0.39860488 0.3996014  0.40059791 0.40159442 0.40259093] , [0.40358744 0.40458396 0.40558047]\n",
            "1 : [0.25510713 0.25610364 0.25710015 0.25809666 0.25909317] , [0.26008969 0.2610862  0.26208271]\n",
            "2 : [0.85450922 0.85550573 0.85650224 0.85749875 0.85849527] , [0.85949178 0.86048829 0.8614848 ]\n",
            "3 : [0.07673144 0.07772795 0.07872446 0.07972098 0.08071749] , [0.081714   0.08271051 0.08370703]\n",
            "4 : [0.63577479 0.6367713  0.63776781 0.63876432 0.63976084] , [0.64075735 0.64175386 0.64275037]\n",
            "\n",
            "===== Test data after normalization (encoder_x,decoder_y) =====\n",
            "x_test_norm:(200, 5), y_test_norm:(200, 3)\n",
            "0 : [0.93373194 0.93472845 0.93572496 0.93672147 0.93771799] , [0.9387145  0.93971101 0.94070752]\n",
            "1 : [0.32735426 0.32835077 0.32934728 0.3303438  0.33134031] , [0.33233682 0.33333333 0.33432985]\n",
            "2 : [0.14449427 0.14549078 0.14648729 0.14748381 0.14848032] , [0.14947683 0.15047334 0.15146986]\n",
            "3 : [0.00249128 0.00348779 0.0044843  0.00548082 0.00647733] , [0.00747384 0.00847035 0.00946687]\n",
            "4 : [0.55555556 0.55655207 0.55754858 0.55854509 0.5595416 ] , [0.56053812 0.56153463 0.56253114]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 Prepare the decoder's input (decoder_x) according to Teacher forcing"
      ],
      "metadata": {
        "id": "nWWVMWHjS7pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_decoder_x(decoder_ytrain, decoder_ytest, decoder_yval, start_token=-0.1):\n",
        "  # Initial all with zero\n",
        "  decoder_xtrain = np.zeros_like(decoder_ytrain)\n",
        "  decoder_xtest  = np.zeros_like(decoder_ytest)\n",
        "  decoder_xval   = np.zeros_like(decoder_yval)\n",
        "\n",
        "  #set the stert token for the first time step\n",
        "  decoder_xtrain[:,0] = start_token\n",
        "  decoder_xtest[:,0]  = start_token\n",
        "  decoder_xval[:,0]   = start_token\n",
        "\n",
        "  # Teacher forcing\n",
        "  n_timesteps = decoder_ytrain.shape[-1]\n",
        "  decoder_xtrain[:,1:] = decoder_ytrain[:, 0:n_timesteps-1]\n",
        "  decoder_xtest[:,1:]  = decoder_ytest[:, 0:n_timesteps-1]\n",
        "  decoder_xval[:,1:]   = decoder_yval[:, 0:n_timesteps-1]\n",
        "\n",
        "  return decoder_xtrain,decoder_xtest,decoder_xval"
      ],
      "metadata": {
        "id": "wNkc1X8yTPbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = -0.01 # the start of sequence for teacher forcing\n",
        "gen_results = gen_decoder_x(decoder_y_train_norm, decoder_y_test_norm, decoder_y_val_norm, start_token)\n",
        "decoder_x_train_norm, decoder_x_test_norm, decoder_X_val_norm = gen_results\n",
        "\n",
        "print(decoder_x_train_norm[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXNqYsZ8Uqx9",
        "outputId": "2a86c1ce-4678-47c9-bc02-12c8a480e564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01        0.48679621  0.48779273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"****** use teacher forcing with start_token={start_token:.2f} for decoder_x ******\")\n",
        "print(f\"\\n ======= decoder_x_train_norm =======\")\n",
        "print(f\" shape:{decoder_x_train_norm.shape} dacoder_y:{decoder_y_train_norm[0]} ==> decoder_x:{decoder_x_train_norm[0]}\")\n",
        "print(f\"\\n ======= decoder_x_test_norm =======\")\n",
        "print(f\" shape:{decoder_x_test_norm.shape} dacoder_y:{decoder_y_test_norm[0]} ==> decoder_x:{decoder_x_test_norm[0]}\")\n",
        "print(f\"\\n ======= decoder_X_val_norm =======\")\n",
        "print(f\" shape:{decoder_X_val_norm.shape} dacoder_y:{decoder_y_val_norm[0]} ==> decoder_x:{decoder_X_val_norm[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25EWQQ9gTPfA",
        "outputId": "99ecb576-d35e-4339-dbff-ea960731ee93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** use teacher forcing with start_token=-0.01 for decoder_x ******\n",
            "\n",
            " ======= decoder_x_train_norm =======\n",
            " shape:(1600, 3) dacoder_y:[0.48679621 0.48779273 0.48878924] ==> decoder_x:[-0.01        0.48679621  0.48779273]\n",
            "\n",
            " ======= decoder_x_test_norm =======\n",
            " shape:(200, 3) dacoder_y:[0.9387145  0.93971101 0.94070752] ==> decoder_x:[-0.01        0.9387145   0.93971101]\n",
            "\n",
            " ======= decoder_X_val_norm =======\n",
            " shape:(200, 3) dacoder_y:[0.40358744 0.40458396 0.40558047] ==> decoder_x:[-0.01        0.40358744  0.40458396]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 Set Format data according to seq2seq_model's requiremants"
      ],
      "metadata": {
        "id": "2o-xF9CyX-ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'#'*10} Dimension before changed {'#'*10}\")\n",
        "print(f\"encoder_x_train_norm: {encoder_x_train_norm.shape} ,decoder_x_train_norm: {decoder_x_train_norm.shape} ,decoder_y_train_norm: {decoder_y_train_norm.shape}\")\n",
        "print(f\"encoder_x_test_norm: {encoder_x_test_norm.shape} ,decoder_x_test_norm: {decoder_x_test_norm.shape} ,decoder_y_test_norm: {decoder_y_test_norm.shape}\")\n",
        "print(f\"encoder_x_val_norm: {encoder_x_val_norm.shape} ,decoder_X_val_norm: {decoder_X_val_norm.shape} ,decoder_y_val_norm: {decoder_y_val_norm.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBJQbpgHYYaD",
        "outputId": "800dc62a-59ad-4d5d-d707-ca2946b0059f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Dimension before changed ##########\n",
            "encoder_x_train_norm: (1600, 5) ,decoder_x_train_norm: (1600, 3) ,decoder_y_train_norm: (1600, 3)\n",
            "encoder_x_test_norm: (200, 5) ,decoder_x_test_norm: (200, 3) ,decoder_y_test_norm: (200, 3)\n",
            "encoder_x_val_norm: (200, 5) ,decoder_X_val_norm: (200, 3) ,decoder_y_val_norm: (200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_x_train_norm = np.expand_dims(encoder_x_train_norm, axis=2)\n",
        "encoder_x_test_norm = np.expand_dims(encoder_x_test_norm, axis=2)\n",
        "encoder_x_val_norm = np.expand_dims(encoder_x_val_norm, axis=2)\n",
        "\n",
        "decoder_x_train_norm = np.expand_dims(decoder_x_train_norm, axis=2)\n",
        "decoder_x_test_norm = np.expand_dims(decoder_x_test_norm, axis=2)\n",
        "decoder_X_val_norm = np.expand_dims(decoder_X_val_norm, axis=2)\n",
        "\n",
        "decoder_y_train_norm = np.expand_dims(decoder_y_train_norm, axis=2)\n",
        "decoder_y_test_norm = np.expand_dims(decoder_y_test_norm, axis=2)\n",
        "decoder_y_val_norm = np.expand_dims(decoder_y_val_norm, axis=2)"
      ],
      "metadata": {
        "id": "C9PQhRh9YYdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'#'*10} Dimension After changed {'#'*10}\")\n",
        "print(f\"encoder_x_train_norm: {encoder_x_train_norm.shape} ,decoder_x_train_norm: {decoder_x_train_norm.shape} ,decoder_y_train_norm: {decoder_y_train_norm.shape}\")\n",
        "print(f\"encoder_x_test_norm: {encoder_x_test_norm.shape} ,decoder_x_test_norm: {decoder_x_test_norm.shape} ,decoder_y_test_norm: {decoder_y_test_norm.shape}\")\n",
        "print(f\"encoder_x_val_norm: {encoder_x_val_norm.shape} ,decoder_X_val_norm: {decoder_X_val_norm.shape} ,decoder_y_val_norm: {decoder_y_val_norm.shape}\")\n"
      ],
      "metadata": {
        "id": "N3F7dnqmYYi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58967654-2201-4b6a-d8e2-a2917cccbabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Dimension After changed ##########\n",
            "encoder_x_train_norm: (1600, 5, 1) ,decoder_x_train_norm: (1600, 3, 1) ,decoder_y_train_norm: (1600, 3, 1)\n",
            "encoder_x_test_norm: (200, 5, 1) ,decoder_x_test_norm: (200, 3, 1) ,decoder_y_test_norm: (200, 3, 1)\n",
            "encoder_x_val_norm: (200, 5, 1) ,decoder_X_val_norm: (200, 3, 1) ,decoder_y_val_norm: (200, 3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Covert everything to the drfult of float32\n",
        "encoder_x_train_norm = encoder_x_train_norm.astype(np.float32)\n",
        "encoder_x_test_norm = encoder_x_test_norm.astype(np.float32)\n",
        "encoder_x_val_norm = encoder_x_val_norm.astype(np.float32)\n",
        "\n",
        "decoder_x_train_norm = decoder_x_train_norm.astype(np.float32)\n",
        "decoder_x_test_norm = decoder_x_test_norm.astype(np.float32)\n",
        "decoder_X_val_norm = decoder_X_val_norm.astype(np.float32)\n",
        "\n",
        "decoder_y_train_norm = decoder_y_train_norm.astype(np.float32)\n",
        "decoder_y_test_norm = decoder_y_test_norm.astype(np.float32)\n",
        "decoder_y_val_norm = decoder_y_val_norm.astype(np.float32)"
      ],
      "metadata": {
        "id": "BEx4s5pgbP-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_x_train_norm[0].ravel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW9zmxIBfh2k",
        "outputId": "94c6a5a5-e8ef-473d-a135-3d6ef84dd40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48181364, 0.48281017, 0.48380667, 0.4848032 , 0.4857997 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== Train data =====\")\n",
        "print(f\"encoder_x_train_norm:{encoder_x_train_norm.shape}, decoder_y_train_norm:{decoder_y_train_norm.shape}, decoder_x_train_norm:{decoder_x_train_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {encoder_x_train_norm[i].ravel()} , {decoder_y_train_norm[i].ravel()} , {decoder_x_train_norm[i].ravel()}\")\n",
        "\n",
        "print(\"\\n===== Validation data =====\")\n",
        "print(f\"encoder_x_val_norm:{encoder_x_val_norm.shape}, decoder_y_val_norm:{decoder_y_val_norm.shape}, decoder_x_test_norm:{decoder_x_test_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {encoder_x_val_norm[i].ravel()} , {decoder_y_val_norm[i].ravel()} , {decoder_x_test_norm[i].ravel()}\")\n",
        "\n",
        "print(\"\\n===== Test data =====\")\n",
        "print(f\"encoder_x_test_norm:{encoder_x_test_norm.shape}, decoder_y_test_norm:{decoder_y_test_norm.shape}, decoder_X_val_norm:{decoder_X_val_norm.shape}\")\n",
        "for i in range(5):\n",
        "  print(f\"{i} : {encoder_x_test_norm[i].ravel()} , {decoder_y_test_norm[i].ravel()} , {decoder_X_val_norm[i].ravel()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLAMpASOfLhK",
        "outputId": "e92cb13d-d087-4f05-9f76-d9ad7688db0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Train data =====\n",
            "encoder_x_train_norm:(1600, 5, 1), decoder_y_train_norm:(1600, 3, 1), decoder_x_train_norm:(1600, 3, 1)\n",
            "0 : [0.48181364 0.48281017 0.48380667 0.4848032  0.4857997 ] , [0.4867962  0.48779273 0.48878923] , [-0.01        0.4867962   0.48779273]\n",
            "1 : [0.31290483 0.31390134 0.31489787 0.31589437 0.3168909 ] , [0.3178874  0.3188839  0.31988043] , [-0.01       0.3178874  0.3188839]\n",
            "2 : [0.28749377 0.2884903  0.2894868  0.2904833  0.29147983] , [0.29247633 0.29347286 0.29446936] , [-0.01        0.29247633  0.29347286]\n",
            "3 : [0.04434479 0.04534131 0.04633782 0.04733433 0.04833084] , [0.04932735 0.05032387 0.05132038] , [-0.01        0.04932735  0.05032387]\n",
            "4 : [0.5834579  0.5844544  0.58545095 0.5864474  0.58744395] , [0.5884405  0.58943695 0.5904335 ] , [-0.01        0.5884405   0.58943695]\n",
            "\n",
            "===== Validation data =====\n",
            "encoder_x_val_norm:(200, 5, 1), decoder_y_val_norm:(200, 3, 1), decoder_x_test_norm:(200, 3, 1)\n",
            "0 : [0.39860487 0.3996014  0.4005979  0.40159443 0.40259093] , [0.40358743 0.40458396 0.40558046] , [-0.01        0.9387145   0.93971103]\n",
            "1 : [0.25510713 0.25610363 0.25710014 0.25809667 0.25909317] , [0.2600897 0.2610862 0.2620827] , [-0.01        0.3323368   0.33333334]\n",
            "2 : [0.85450923 0.8555057  0.85650223 0.85749876 0.8584953 ] , [0.85949177 0.8604883  0.8614848 ] , [-0.01        0.14947683  0.15047334]\n",
            "3 : [0.07673144 0.07772795 0.07872447 0.07972097 0.08071749] , [0.081714   0.08271051 0.08370703] , [-0.01        0.00747384  0.00847035]\n",
            "4 : [0.6357748  0.6367713  0.6377678  0.6387643  0.63976085] , [0.6407573  0.64175385 0.6427504 ] , [-0.01        0.5605381   0.56153464]\n",
            "\n",
            "===== Test data =====\n",
            "encoder_x_test_norm:(200, 5, 1), decoder_y_test_norm:(200, 3, 1), decoder_X_val_norm:(200, 3, 1)\n",
            "0 : [0.9337319  0.93472844 0.935725   0.9367215  0.937718  ] , [0.9387145  0.93971103 0.9407075 ] , [-0.01        0.40358743  0.40458396]\n",
            "1 : [0.32735425 0.32835078 0.32934728 0.33034378 0.3313403 ] , [0.3323368  0.33333334 0.33432984] , [-0.01       0.2600897  0.2610862]\n",
            "2 : [0.14449427 0.14549078 0.1464873  0.14748381 0.14848033] , [0.14947683 0.15047334 0.15146986] , [-0.01        0.85949177  0.8604883 ]\n",
            "3 : [0.00249128 0.00348779 0.00448431 0.00548082 0.00647733] , [0.00747384 0.00847035 0.00946687] , [-0.01        0.081714    0.08271051]\n",
            "4 : [0.5555556  0.55655205 0.5575486  0.5585451  0.5595416 ] , [0.5605381  0.56153464 0.5625311 ] , [-0.01        0.6407573   0.64175385]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Complie and Train the model"
      ],
      "metadata": {
        "id": "uieLsvij93jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = \"RNN_ex6_bestmodel_epoch{epoch:03d}.hdf5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                               save_weights_only=False,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)"
      ],
      "metadata": {
        "id": "tuJfZaPxb0B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras's callback can only save the unified seq2seq_model model not the two separated model (encoder_model and decoder_model) that share the same computational graph as seq2seq_model's \n",
        "\n",
        "So we have to subclass tf.keras.call.backs to save the best encoder_model and decoder_model models outselves at the end of each epoch."
      ],
      "metadata": {
        "id": "2PUOFiYvb-cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "\n",
        "    #The encoder and Decoder model to be save\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.start_time = None\n",
        "    self.min_valloss = None\n",
        "    \n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    self.start_time = time.time()\n",
        "    self.min_valloss = None\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    # compute the totla runtime since the trainig started\n",
        "    total_run_time =int(time.time() - self.start_time)\n",
        "    msg = f\" Train time{datetime.timedelta(seconds=total_run_time)}\"\n",
        "\n",
        "    #Save the best encoder and decoder models\n",
        "    if 'val_loss' in logs.keys():\n",
        "      if self.min_valloss is None:\n",
        "        self.min_valloss = logs['val_loss']\n",
        "      if logs['val_loss'] < self.min_valloss:\n",
        "        self.min_valloss = logs['val_loss']\n",
        "        self.encoder.save(\"RNN_ex6_bestencoder.hdf5\")\n",
        "        self.decoder.save(\"RNN_ex6_bestdecoder.hdf5\")\n",
        "        msg += \"**best**\"\n",
        "    \n",
        "    # Print total run time at the beginning of each epoh's log\n",
        "    print( msg, end='-')\n",
        "\n",
        "my_cellback = CustomCallback(encoder_model, decoder_model)"
      ],
      "metadata": {
        "id": "h-J3jZa1dCnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and Train"
      ],
      "metadata": {
        "id": "w3-FqjYXnfEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "seq2seq_model.compile( loss=\"mse\", optimizer=adam, metrics=[\"mean_absolute_error\"] )"
      ],
      "metadata": {
        "id": "qCrc_Ds7dCs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supress TF's warning messages\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "metadata": {
        "id": "zFNJyuZFtp-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_ex6 = seq2seq_model.fit( [encoder_x_train_norm, decoder_x_train_norm], decoder_y_train_norm, \n",
        "                             validation_data=([encoder_x_val_norm, decoder_X_val_norm], decoder_y_val_norm),\n",
        "                             batch_size=64, epochs=500, callbacks=[model_checkpoint_callback, my_cellback],\n",
        "                             verbose=2\n",
        "                             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZnZav-ztqDV",
        "outputId": "e4998154-1016-455a-8d82-115fe6d68d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            " Train time0:00:04-25/25 - 4s - loss: 0.3372 - mean_absolute_error: 0.4448 - val_loss: 0.0473 - val_mean_absolute_error: 0.1866 - 4s/epoch - 159ms/step\n",
            "Epoch 2/500\n",
            " Train time0:00:04**best**-25/25 - 0s - loss: 0.0443 - mean_absolute_error: 0.1825 - val_loss: 0.0225 - val_mean_absolute_error: 0.1248 - 184ms/epoch - 7ms/step\n",
            "Epoch 3/500\n",
            " Train time0:00:04**best**-25/25 - 0s - loss: 0.0179 - mean_absolute_error: 0.1105 - val_loss: 0.0093 - val_mean_absolute_error: 0.0818 - 184ms/epoch - 7ms/step\n",
            "Epoch 4/500\n",
            " Train time0:00:04**best**-25/25 - 0s - loss: 0.0075 - mean_absolute_error: 0.0716 - val_loss: 0.0045 - val_mean_absolute_error: 0.0552 - 190ms/epoch - 8ms/step\n",
            "Epoch 5/500\n",
            " Train time0:00:04**best**-25/25 - 0s - loss: 0.0047 - mean_absolute_error: 0.0552 - val_loss: 0.0034 - val_mean_absolute_error: 0.0461 - 187ms/epoch - 7ms/step\n",
            "Epoch 6/500\n",
            " Train time0:00:04**best**-25/25 - 0s - loss: 0.0038 - mean_absolute_error: 0.0491 - val_loss: 0.0027 - val_mean_absolute_error: 0.0406 - 193ms/epoch - 8ms/step\n",
            "Epoch 7/500\n",
            " Train time0:00:05**best**-25/25 - 0s - loss: 0.0031 - mean_absolute_error: 0.0445 - val_loss: 0.0023 - val_mean_absolute_error: 0.0375 - 204ms/epoch - 8ms/step\n",
            "Epoch 8/500\n",
            " Train time0:00:05**best**-25/25 - 0s - loss: 0.0027 - mean_absolute_error: 0.0410 - val_loss: 0.0020 - val_mean_absolute_error: 0.0361 - 191ms/epoch - 8ms/step\n",
            "Epoch 9/500\n",
            " Train time0:00:05**best**-25/25 - 0s - loss: 0.0023 - mean_absolute_error: 0.0377 - val_loss: 0.0018 - val_mean_absolute_error: 0.0338 - 182ms/epoch - 7ms/step\n",
            "Epoch 10/500\n",
            " Train time0:00:05**best**-25/25 - 0s - loss: 0.0019 - mean_absolute_error: 0.0353 - val_loss: 0.0015 - val_mean_absolute_error: 0.0307 - 179ms/epoch - 7ms/step\n",
            "Epoch 11/500\n",
            " Train time0:00:05**best**-25/25 - 0s - loss: 0.0017 - mean_absolute_error: 0.0326 - val_loss: 0.0013 - val_mean_absolute_error: 0.0286 - 177ms/epoch - 7ms/step\n",
            "Epoch 12/500\n",
            " Train time0:00:06**best**-25/25 - 0s - loss: 0.0014 - mean_absolute_error: 0.0305 - val_loss: 0.0011 - val_mean_absolute_error: 0.0270 - 179ms/epoch - 7ms/step\n",
            "Epoch 13/500\n",
            " Train time0:00:06**best**-25/25 - 0s - loss: 0.0012 - mean_absolute_error: 0.0280 - val_loss: 9.8905e-04 - val_mean_absolute_error: 0.0256 - 181ms/epoch - 7ms/step\n",
            "Epoch 14/500\n",
            " Train time0:00:06**best**-25/25 - 0s - loss: 0.0011 - mean_absolute_error: 0.0263 - val_loss: 8.0158e-04 - val_mean_absolute_error: 0.0228 - 180ms/epoch - 7ms/step\n",
            "Epoch 15/500\n",
            " Train time0:00:06**best**-25/25 - 0s - loss: 9.0848e-04 - mean_absolute_error: 0.0238 - val_loss: 6.6364e-04 - val_mean_absolute_error: 0.0202 - 176ms/epoch - 7ms/step\n",
            "Epoch 16/500\n",
            " Train time0:00:06**best**-25/25 - 0s - loss: 7.6185e-04 - mean_absolute_error: 0.0222 - val_loss: 5.6042e-04 - val_mean_absolute_error: 0.0188 - 180ms/epoch - 7ms/step\n",
            "Epoch 17/500\n",
            " Train time0:00:07**best**-25/25 - 0s - loss: 6.2672e-04 - mean_absolute_error: 0.0200 - val_loss: 4.6879e-04 - val_mean_absolute_error: 0.0172 - 187ms/epoch - 7ms/step\n",
            "Epoch 18/500\n",
            " Train time0:00:07**best**-25/25 - 0s - loss: 5.2600e-04 - mean_absolute_error: 0.0182 - val_loss: 3.8613e-04 - val_mean_absolute_error: 0.0153 - 190ms/epoch - 8ms/step\n",
            "Epoch 19/500\n",
            " Train time0:00:07**best**-25/25 - 0s - loss: 4.3401e-04 - mean_absolute_error: 0.0166 - val_loss: 3.2225e-04 - val_mean_absolute_error: 0.0143 - 180ms/epoch - 7ms/step\n",
            "Epoch 20/500\n",
            " Train time0:00:07**best**-25/25 - 0s - loss: 3.5077e-04 - mean_absolute_error: 0.0148 - val_loss: 2.7184e-04 - val_mean_absolute_error: 0.0131 - 181ms/epoch - 7ms/step\n",
            "Epoch 21/500\n",
            " Train time0:00:07**best**-25/25 - 0s - loss: 2.8371e-04 - mean_absolute_error: 0.0132 - val_loss: 2.1044e-04 - val_mean_absolute_error: 0.0113 - 181ms/epoch - 7ms/step\n",
            "Epoch 22/500\n",
            " Train time0:00:07**best**-25/25 - 0s - loss: 2.2566e-04 - mean_absolute_error: 0.0115 - val_loss: 1.7404e-04 - val_mean_absolute_error: 0.0103 - 180ms/epoch - 7ms/step\n",
            "Epoch 23/500\n",
            " Train time0:00:08**best**-25/25 - 0s - loss: 1.8053e-04 - mean_absolute_error: 0.0102 - val_loss: 1.3179e-04 - val_mean_absolute_error: 0.0084 - 180ms/epoch - 7ms/step\n",
            "Epoch 24/500\n",
            " Train time0:00:08**best**-25/25 - 0s - loss: 1.4622e-04 - mean_absolute_error: 0.0089 - val_loss: 1.0728e-04 - val_mean_absolute_error: 0.0074 - 196ms/epoch - 8ms/step\n",
            "Epoch 25/500\n",
            " Train time0:00:08**best**-25/25 - 0s - loss: 1.1566e-04 - mean_absolute_error: 0.0078 - val_loss: 9.0866e-05 - val_mean_absolute_error: 0.0071 - 185ms/epoch - 7ms/step\n",
            "Epoch 26/500\n",
            " Train time0:00:08**best**-25/25 - 0s - loss: 9.3744e-05 - mean_absolute_error: 0.0070 - val_loss: 7.3498e-05 - val_mean_absolute_error: 0.0064 - 176ms/epoch - 7ms/step\n",
            "Epoch 27/500\n",
            " Train time0:00:08**best**-25/25 - 0s - loss: 7.8357e-05 - mean_absolute_error: 0.0065 - val_loss: 6.1683e-05 - val_mean_absolute_error: 0.0059 - 185ms/epoch - 7ms/step\n",
            "Epoch 28/500\n",
            " Train time0:00:09**best**-25/25 - 0s - loss: 6.3536e-05 - mean_absolute_error: 0.0059 - val_loss: 4.8226e-05 - val_mean_absolute_error: 0.0051 - 178ms/epoch - 7ms/step\n",
            "Epoch 29/500\n",
            " Train time0:00:09**best**-25/25 - 0s - loss: 5.3749e-05 - mean_absolute_error: 0.0054 - val_loss: 4.2303e-05 - val_mean_absolute_error: 0.0050 - 177ms/epoch - 7ms/step\n",
            "Epoch 30/500\n",
            " Train time0:00:09**best**-25/25 - 0s - loss: 4.5244e-05 - mean_absolute_error: 0.0051 - val_loss: 3.6780e-05 - val_mean_absolute_error: 0.0047 - 176ms/epoch - 7ms/step\n",
            "Epoch 31/500\n",
            " Train time0:00:09**best**-25/25 - 0s - loss: 3.9176e-05 - mean_absolute_error: 0.0047 - val_loss: 3.1074e-05 - val_mean_absolute_error: 0.0042 - 181ms/epoch - 7ms/step\n",
            "Epoch 32/500\n",
            " Train time0:00:09**best**-25/25 - 0s - loss: 3.4141e-05 - mean_absolute_error: 0.0044 - val_loss: 2.7749e-05 - val_mean_absolute_error: 0.0041 - 180ms/epoch - 7ms/step\n",
            "Epoch 33/500\n",
            " Train time0:00:09**best**-25/25 - 0s - loss: 3.0347e-05 - mean_absolute_error: 0.0042 - val_loss: 2.4667e-05 - val_mean_absolute_error: 0.0038 - 178ms/epoch - 7ms/step\n",
            "Epoch 34/500\n",
            " Train time0:00:10**best**-25/25 - 0s - loss: 2.6860e-05 - mean_absolute_error: 0.0039 - val_loss: 2.1868e-05 - val_mean_absolute_error: 0.0036 - 173ms/epoch - 7ms/step\n",
            "Epoch 35/500\n",
            " Train time0:00:10**best**-25/25 - 0s - loss: 2.3971e-05 - mean_absolute_error: 0.0037 - val_loss: 2.0439e-05 - val_mean_absolute_error: 0.0035 - 192ms/epoch - 8ms/step\n",
            "Epoch 36/500\n",
            " Train time0:00:10**best**-25/25 - 0s - loss: 2.1752e-05 - mean_absolute_error: 0.0035 - val_loss: 1.8376e-05 - val_mean_absolute_error: 0.0033 - 182ms/epoch - 7ms/step\n",
            "Epoch 37/500\n",
            " Train time0:00:10**best**-25/25 - 0s - loss: 1.9946e-05 - mean_absolute_error: 0.0034 - val_loss: 1.6263e-05 - val_mean_absolute_error: 0.0031 - 182ms/epoch - 7ms/step\n",
            "Epoch 38/500\n",
            " Train time0:00:10-25/25 - 0s - loss: 1.8032e-05 - mean_absolute_error: 0.0032 - val_loss: 1.8105e-05 - val_mean_absolute_error: 0.0033 - 142ms/epoch - 6ms/step\n",
            "Epoch 39/500\n",
            " Train time0:00:11**best**-25/25 - 0s - loss: 1.7636e-05 - mean_absolute_error: 0.0031 - val_loss: 1.3918e-05 - val_mean_absolute_error: 0.0029 - 180ms/epoch - 7ms/step\n",
            "Epoch 40/500\n",
            " Train time0:00:11**best**-25/25 - 0s - loss: 1.5695e-05 - mean_absolute_error: 0.0029 - val_loss: 1.3251e-05 - val_mean_absolute_error: 0.0028 - 175ms/epoch - 7ms/step\n",
            "Epoch 41/500\n",
            " Train time0:00:11**best**-25/25 - 0s - loss: 1.4510e-05 - mean_absolute_error: 0.0028 - val_loss: 1.2262e-05 - val_mean_absolute_error: 0.0028 - 196ms/epoch - 8ms/step\n",
            "Epoch 42/500\n",
            " Train time0:00:11-25/25 - 0s - loss: 1.3823e-05 - mean_absolute_error: 0.0028 - val_loss: 1.2599e-05 - val_mean_absolute_error: 0.0026 - 141ms/epoch - 6ms/step\n",
            "Epoch 43/500\n",
            " Train time0:00:11**best**-25/25 - 0s - loss: 1.3106e-05 - mean_absolute_error: 0.0027 - val_loss: 1.2049e-05 - val_mean_absolute_error: 0.0027 - 178ms/epoch - 7ms/step\n",
            "Epoch 44/500\n",
            " Train time0:00:11**best**-25/25 - 0s - loss: 1.2477e-05 - mean_absolute_error: 0.0026 - val_loss: 1.0657e-05 - val_mean_absolute_error: 0.0026 - 178ms/epoch - 7ms/step\n",
            "Epoch 45/500\n",
            " Train time0:00:12**best**-25/25 - 0s - loss: 1.2585e-05 - mean_absolute_error: 0.0027 - val_loss: 9.9656e-06 - val_mean_absolute_error: 0.0025 - 179ms/epoch - 7ms/step\n",
            "Epoch 46/500\n",
            " Train time0:00:12**best**-25/25 - 0s - loss: 1.1717e-05 - mean_absolute_error: 0.0026 - val_loss: 9.7701e-06 - val_mean_absolute_error: 0.0025 - 185ms/epoch - 7ms/step\n",
            "Epoch 47/500\n",
            " Train time0:00:12**best**-25/25 - 0s - loss: 1.1037e-05 - mean_absolute_error: 0.0025 - val_loss: 9.4965e-06 - val_mean_absolute_error: 0.0024 - 177ms/epoch - 7ms/step\n",
            "Epoch 48/500\n",
            " Train time0:00:12**best**-25/25 - 0s - loss: 1.0938e-05 - mean_absolute_error: 0.0025 - val_loss: 9.4078e-06 - val_mean_absolute_error: 0.0024 - 179ms/epoch - 7ms/step\n",
            "Epoch 49/500\n",
            " Train time0:00:12-25/25 - 0s - loss: 1.0395e-05 - mean_absolute_error: 0.0025 - val_loss: 9.4151e-06 - val_mean_absolute_error: 0.0025 - 146ms/epoch - 6ms/step\n",
            "Epoch 50/500\n",
            " Train time0:00:12-25/25 - 0s - loss: 1.0462e-05 - mean_absolute_error: 0.0025 - val_loss: 1.0010e-05 - val_mean_absolute_error: 0.0025 - 148ms/epoch - 6ms/step\n",
            "Epoch 51/500\n",
            " Train time0:00:13**best**-25/25 - 0s - loss: 1.0363e-05 - mean_absolute_error: 0.0025 - val_loss: 8.5077e-06 - val_mean_absolute_error: 0.0023 - 176ms/epoch - 7ms/step\n",
            "Epoch 52/500\n",
            " Train time0:00:13**best**-25/25 - 0s - loss: 1.0269e-05 - mean_absolute_error: 0.0025 - val_loss: 8.4727e-06 - val_mean_absolute_error: 0.0023 - 182ms/epoch - 7ms/step\n",
            "Epoch 53/500\n",
            " Train time0:00:13-25/25 - 0s - loss: 9.7768e-06 - mean_absolute_error: 0.0024 - val_loss: 8.8923e-06 - val_mean_absolute_error: 0.0024 - 144ms/epoch - 6ms/step\n",
            "Epoch 54/500\n",
            " Train time0:00:13**best**-25/25 - 0s - loss: 9.3690e-06 - mean_absolute_error: 0.0024 - val_loss: 7.9851e-06 - val_mean_absolute_error: 0.0023 - 184ms/epoch - 7ms/step\n",
            "Epoch 55/500\n",
            " Train time0:00:13-25/25 - 0s - loss: 9.2997e-06 - mean_absolute_error: 0.0024 - val_loss: 1.1443e-05 - val_mean_absolute_error: 0.0026 - 145ms/epoch - 6ms/step\n",
            "Epoch 56/500\n",
            " Train time0:00:13-25/25 - 0s - loss: 9.5062e-06 - mean_absolute_error: 0.0024 - val_loss: 8.0497e-06 - val_mean_absolute_error: 0.0023 - 147ms/epoch - 6ms/step\n",
            "Epoch 57/500\n",
            " Train time0:00:14**best**-25/25 - 0s - loss: 8.7015e-06 - mean_absolute_error: 0.0023 - val_loss: 7.6554e-06 - val_mean_absolute_error: 0.0022 - 178ms/epoch - 7ms/step\n",
            "Epoch 58/500\n",
            " Train time0:00:14-25/25 - 0s - loss: 8.7768e-06 - mean_absolute_error: 0.0023 - val_loss: 8.0301e-06 - val_mean_absolute_error: 0.0022 - 144ms/epoch - 6ms/step\n",
            "Epoch 59/500\n",
            " Train time0:00:14**best**-25/25 - 0s - loss: 8.7867e-06 - mean_absolute_error: 0.0023 - val_loss: 7.1792e-06 - val_mean_absolute_error: 0.0022 - 196ms/epoch - 8ms/step\n",
            "Epoch 60/500\n",
            " Train time0:00:14**best**-25/25 - 0s - loss: 8.2949e-06 - mean_absolute_error: 0.0022 - val_loss: 6.9060e-06 - val_mean_absolute_error: 0.0021 - 178ms/epoch - 7ms/step\n",
            "Epoch 61/500\n",
            " Train time0:00:14-25/25 - 0s - loss: 8.4527e-06 - mean_absolute_error: 0.0023 - val_loss: 8.2647e-06 - val_mean_absolute_error: 0.0023 - 141ms/epoch - 6ms/step\n",
            "Epoch 62/500\n",
            " Train time0:00:14-25/25 - 0s - loss: 8.1477e-06 - mean_absolute_error: 0.0022 - val_loss: 1.0014e-05 - val_mean_absolute_error: 0.0024 - 144ms/epoch - 6ms/step\n",
            "Epoch 63/500\n",
            " Train time0:00:15-25/25 - 0s - loss: 8.8973e-06 - mean_absolute_error: 0.0023 - val_loss: 8.1900e-06 - val_mean_absolute_error: 0.0022 - 142ms/epoch - 6ms/step\n",
            "Epoch 64/500\n",
            " Train time0:00:15-25/25 - 0s - loss: 8.2334e-06 - mean_absolute_error: 0.0022 - val_loss: 7.0513e-06 - val_mean_absolute_error: 0.0021 - 148ms/epoch - 6ms/step\n",
            "Epoch 65/500\n",
            " Train time0:00:15**best**-25/25 - 0s - loss: 7.5587e-06 - mean_absolute_error: 0.0021 - val_loss: 6.4503e-06 - val_mean_absolute_error: 0.0020 - 181ms/epoch - 7ms/step\n",
            "Epoch 66/500\n",
            " Train time0:00:15-25/25 - 0s - loss: 7.5431e-06 - mean_absolute_error: 0.0021 - val_loss: 6.9079e-06 - val_mean_absolute_error: 0.0021 - 145ms/epoch - 6ms/step\n",
            "Epoch 67/500\n",
            " Train time0:00:15**best**-25/25 - 0s - loss: 7.6142e-06 - mean_absolute_error: 0.0021 - val_loss: 6.3568e-06 - val_mean_absolute_error: 0.0020 - 177ms/epoch - 7ms/step\n",
            "Epoch 68/500\n",
            " Train time0:00:15-25/25 - 0s - loss: 7.2381e-06 - mean_absolute_error: 0.0021 - val_loss: 6.7221e-06 - val_mean_absolute_error: 0.0020 - 142ms/epoch - 6ms/step\n",
            "Epoch 69/500\n",
            " Train time0:00:16-25/25 - 0s - loss: 7.1649e-06 - mean_absolute_error: 0.0021 - val_loss: 7.0638e-06 - val_mean_absolute_error: 0.0021 - 141ms/epoch - 6ms/step\n",
            "Epoch 70/500\n",
            " Train time0:00:16**best**-25/25 - 0s - loss: 7.0607e-06 - mean_absolute_error: 0.0020 - val_loss: 5.8662e-06 - val_mean_absolute_error: 0.0020 - 185ms/epoch - 7ms/step\n",
            "Epoch 71/500\n",
            " Train time0:00:16-25/25 - 0s - loss: 7.0347e-06 - mean_absolute_error: 0.0020 - val_loss: 5.9694e-06 - val_mean_absolute_error: 0.0019 - 154ms/epoch - 6ms/step\n",
            "Epoch 72/500\n",
            " Train time0:00:16**best**-25/25 - 0s - loss: 6.7851e-06 - mean_absolute_error: 0.0020 - val_loss: 5.6148e-06 - val_mean_absolute_error: 0.0019 - 176ms/epoch - 7ms/step\n",
            "Epoch 73/500\n",
            " Train time0:00:16**best**-25/25 - 0s - loss: 6.5131e-06 - mean_absolute_error: 0.0020 - val_loss: 5.4243e-06 - val_mean_absolute_error: 0.0018 - 182ms/epoch - 7ms/step\n",
            "Epoch 74/500\n",
            " Train time0:00:16-25/25 - 0s - loss: 6.5107e-06 - mean_absolute_error: 0.0020 - val_loss: 5.4451e-06 - val_mean_absolute_error: 0.0019 - 145ms/epoch - 6ms/step\n",
            "Epoch 75/500\n",
            " Train time0:00:17-25/25 - 0s - loss: 6.6845e-06 - mean_absolute_error: 0.0020 - val_loss: 6.2725e-06 - val_mean_absolute_error: 0.0019 - 144ms/epoch - 6ms/step\n",
            "Epoch 76/500\n",
            " Train time0:00:17-25/25 - 0s - loss: 6.3993e-06 - mean_absolute_error: 0.0019 - val_loss: 6.5000e-06 - val_mean_absolute_error: 0.0019 - 140ms/epoch - 6ms/step\n",
            "Epoch 77/500\n",
            " Train time0:00:17-25/25 - 0s - loss: 6.8511e-06 - mean_absolute_error: 0.0020 - val_loss: 6.4211e-06 - val_mean_absolute_error: 0.0019 - 142ms/epoch - 6ms/step\n",
            "Epoch 78/500\n",
            " Train time0:00:17-25/25 - 0s - loss: 6.6256e-06 - mean_absolute_error: 0.0019 - val_loss: 6.0606e-06 - val_mean_absolute_error: 0.0019 - 160ms/epoch - 6ms/step\n",
            "Epoch 79/500\n",
            " Train time0:00:17**best**-25/25 - 0s - loss: 6.3123e-06 - mean_absolute_error: 0.0019 - val_loss: 5.1627e-06 - val_mean_absolute_error: 0.0017 - 176ms/epoch - 7ms/step\n",
            "Epoch 80/500\n",
            " Train time0:00:17**best**-25/25 - 0s - loss: 6.1926e-06 - mean_absolute_error: 0.0019 - val_loss: 4.7555e-06 - val_mean_absolute_error: 0.0017 - 177ms/epoch - 7ms/step\n",
            "Epoch 81/500\n",
            " Train time0:00:18**best**-25/25 - 0s - loss: 5.9233e-06 - mean_absolute_error: 0.0018 - val_loss: 4.5812e-06 - val_mean_absolute_error: 0.0017 - 177ms/epoch - 7ms/step\n",
            "Epoch 82/500\n",
            " Train time0:00:18-25/25 - 0s - loss: 5.2819e-06 - mean_absolute_error: 0.0018 - val_loss: 4.7472e-06 - val_mean_absolute_error: 0.0017 - 146ms/epoch - 6ms/step\n",
            "Epoch 83/500\n",
            " Train time0:00:18**best**-25/25 - 0s - loss: 5.3549e-06 - mean_absolute_error: 0.0018 - val_loss: 4.4221e-06 - val_mean_absolute_error: 0.0017 - 178ms/epoch - 7ms/step\n",
            "Epoch 84/500\n",
            " Train time0:00:18**best**-25/25 - 0s - loss: 5.3531e-06 - mean_absolute_error: 0.0018 - val_loss: 4.3941e-06 - val_mean_absolute_error: 0.0017 - 181ms/epoch - 7ms/step\n",
            "Epoch 85/500\n",
            " Train time0:00:18-25/25 - 0s - loss: 5.1257e-06 - mean_absolute_error: 0.0017 - val_loss: 7.4388e-06 - val_mean_absolute_error: 0.0020 - 144ms/epoch - 6ms/step\n",
            "Epoch 86/500\n",
            " Train time0:00:18-25/25 - 0s - loss: 5.2406e-06 - mean_absolute_error: 0.0017 - val_loss: 4.8860e-06 - val_mean_absolute_error: 0.0017 - 141ms/epoch - 6ms/step\n",
            "Epoch 87/500\n",
            " Train time0:00:19-25/25 - 0s - loss: 5.1348e-06 - mean_absolute_error: 0.0017 - val_loss: 4.7195e-06 - val_mean_absolute_error: 0.0017 - 142ms/epoch - 6ms/step\n",
            "Epoch 88/500\n",
            " Train time0:00:19**best**-25/25 - 0s - loss: 4.7598e-06 - mean_absolute_error: 0.0017 - val_loss: 4.1781e-06 - val_mean_absolute_error: 0.0016 - 182ms/epoch - 7ms/step\n",
            "Epoch 89/500\n",
            " Train time0:00:19**best**-25/25 - 0s - loss: 4.9781e-06 - mean_absolute_error: 0.0017 - val_loss: 3.8461e-06 - val_mean_absolute_error: 0.0015 - 183ms/epoch - 7ms/step\n",
            "Epoch 90/500\n",
            " Train time0:00:19-25/25 - 0s - loss: 4.6494e-06 - mean_absolute_error: 0.0016 - val_loss: 4.5193e-06 - val_mean_absolute_error: 0.0016 - 161ms/epoch - 6ms/step\n",
            "Epoch 91/500\n",
            " Train time0:00:19-25/25 - 0s - loss: 5.0821e-06 - mean_absolute_error: 0.0017 - val_loss: 1.0456e-05 - val_mean_absolute_error: 0.0024 - 143ms/epoch - 6ms/step\n",
            "Epoch 92/500\n",
            " Train time0:00:19**best**-25/25 - 0s - loss: 5.3699e-06 - mean_absolute_error: 0.0017 - val_loss: 3.6039e-06 - val_mean_absolute_error: 0.0015 - 178ms/epoch - 7ms/step\n",
            "Epoch 93/500\n",
            " Train time0:00:20**best**-25/25 - 0s - loss: 4.2649e-06 - mean_absolute_error: 0.0016 - val_loss: 3.5727e-06 - val_mean_absolute_error: 0.0015 - 180ms/epoch - 7ms/step\n",
            "Epoch 94/500\n",
            " Train time0:00:20**best**-25/25 - 0s - loss: 4.0672e-06 - mean_absolute_error: 0.0015 - val_loss: 3.3351e-06 - val_mean_absolute_error: 0.0014 - 180ms/epoch - 7ms/step\n",
            "Epoch 95/500\n",
            " Train time0:00:20**best**-25/25 - 0s - loss: 4.6485e-06 - mean_absolute_error: 0.0016 - val_loss: 3.2818e-06 - val_mean_absolute_error: 0.0014 - 183ms/epoch - 7ms/step\n",
            "Epoch 96/500\n",
            " Train time0:00:20**best**-25/25 - 0s - loss: 4.3678e-06 - mean_absolute_error: 0.0016 - val_loss: 3.1790e-06 - val_mean_absolute_error: 0.0014 - 202ms/epoch - 8ms/step\n",
            "Epoch 97/500\n",
            " Train time0:00:20-25/25 - 0s - loss: 5.2157e-06 - mean_absolute_error: 0.0017 - val_loss: 4.6726e-06 - val_mean_absolute_error: 0.0016 - 142ms/epoch - 6ms/step\n",
            "Epoch 98/500\n",
            " Train time0:00:20-25/25 - 0s - loss: 4.1812e-06 - mean_absolute_error: 0.0015 - val_loss: 4.2105e-06 - val_mean_absolute_error: 0.0015 - 143ms/epoch - 6ms/step\n",
            "Epoch 99/500\n",
            " Train time0:00:21**best**-25/25 - 0s - loss: 3.9680e-06 - mean_absolute_error: 0.0015 - val_loss: 3.1730e-06 - val_mean_absolute_error: 0.0014 - 177ms/epoch - 7ms/step\n",
            "Epoch 100/500\n",
            " Train time0:00:21-25/25 - 0s - loss: 3.8602e-06 - mean_absolute_error: 0.0014 - val_loss: 3.4680e-06 - val_mean_absolute_error: 0.0014 - 146ms/epoch - 6ms/step\n",
            "Epoch 101/500\n",
            " Train time0:00:21**best**-25/25 - 0s - loss: 3.9945e-06 - mean_absolute_error: 0.0015 - val_loss: 2.9570e-06 - val_mean_absolute_error: 0.0013 - 179ms/epoch - 7ms/step\n",
            "Epoch 102/500\n",
            " Train time0:00:21-25/25 - 0s - loss: 4.2075e-06 - mean_absolute_error: 0.0015 - val_loss: 7.0130e-06 - val_mean_absolute_error: 0.0019 - 152ms/epoch - 6ms/step\n",
            "Epoch 103/500\n",
            " Train time0:00:21-25/25 - 0s - loss: 4.9832e-06 - mean_absolute_error: 0.0016 - val_loss: 4.9519e-06 - val_mean_absolute_error: 0.0016 - 141ms/epoch - 6ms/step\n",
            "Epoch 104/500\n",
            " Train time0:00:21**best**-25/25 - 0s - loss: 3.4923e-06 - mean_absolute_error: 0.0014 - val_loss: 2.8528e-06 - val_mean_absolute_error: 0.0013 - 181ms/epoch - 7ms/step\n",
            "Epoch 105/500\n",
            " Train time0:00:22**best**-25/25 - 0s - loss: 3.3731e-06 - mean_absolute_error: 0.0013 - val_loss: 2.5585e-06 - val_mean_absolute_error: 0.0012 - 178ms/epoch - 7ms/step\n",
            "Epoch 106/500\n",
            " Train time0:00:22**best**-25/25 - 0s - loss: 3.3420e-06 - mean_absolute_error: 0.0013 - val_loss: 2.5062e-06 - val_mean_absolute_error: 0.0012 - 183ms/epoch - 7ms/step\n",
            "Epoch 107/500\n",
            " Train time0:00:22-25/25 - 0s - loss: 3.1541e-06 - mean_absolute_error: 0.0013 - val_loss: 2.9718e-06 - val_mean_absolute_error: 0.0012 - 143ms/epoch - 6ms/step\n",
            "Epoch 108/500\n",
            " Train time0:00:22**best**-25/25 - 0s - loss: 3.0670e-06 - mean_absolute_error: 0.0013 - val_loss: 2.4886e-06 - val_mean_absolute_error: 0.0012 - 179ms/epoch - 7ms/step\n",
            "Epoch 109/500\n",
            " Train time0:00:22-25/25 - 0s - loss: 2.8915e-06 - mean_absolute_error: 0.0012 - val_loss: 2.5143e-06 - val_mean_absolute_error: 0.0012 - 144ms/epoch - 6ms/step\n",
            "Epoch 110/500\n",
            " Train time0:00:22**best**-25/25 - 0s - loss: 2.9012e-06 - mean_absolute_error: 0.0012 - val_loss: 2.4572e-06 - val_mean_absolute_error: 0.0012 - 177ms/epoch - 7ms/step\n",
            "Epoch 111/500\n",
            " Train time0:00:23**best**-25/25 - 0s - loss: 3.1000e-06 - mean_absolute_error: 0.0013 - val_loss: 2.3628e-06 - val_mean_absolute_error: 0.0012 - 180ms/epoch - 7ms/step\n",
            "Epoch 112/500\n",
            " Train time0:00:23**best**-25/25 - 0s - loss: 2.7926e-06 - mean_absolute_error: 0.0012 - val_loss: 2.2711e-06 - val_mean_absolute_error: 0.0011 - 182ms/epoch - 7ms/step\n",
            "Epoch 113/500\n",
            " Train time0:00:23**best**-25/25 - 0s - loss: 2.5756e-06 - mean_absolute_error: 0.0012 - val_loss: 2.1849e-06 - val_mean_absolute_error: 0.0011 - 177ms/epoch - 7ms/step\n",
            "Epoch 114/500\n",
            " Train time0:00:23**best**-25/25 - 0s - loss: 2.4744e-06 - mean_absolute_error: 0.0012 - val_loss: 2.0000e-06 - val_mean_absolute_error: 0.0011 - 195ms/epoch - 8ms/step\n",
            "Epoch 115/500\n",
            " Train time0:00:23-25/25 - 0s - loss: 2.4847e-06 - mean_absolute_error: 0.0011 - val_loss: 2.2387e-06 - val_mean_absolute_error: 0.0011 - 142ms/epoch - 6ms/step\n",
            "Epoch 116/500\n",
            " Train time0:00:23-25/25 - 0s - loss: 3.1318e-06 - mean_absolute_error: 0.0012 - val_loss: 2.1318e-06 - val_mean_absolute_error: 0.0010 - 144ms/epoch - 6ms/step\n",
            "Epoch 117/500\n",
            " Train time0:00:24-25/25 - 0s - loss: 2.5825e-06 - mean_absolute_error: 0.0011 - val_loss: 2.3219e-06 - val_mean_absolute_error: 0.0011 - 142ms/epoch - 6ms/step\n",
            "Epoch 118/500\n",
            " Train time0:00:24**best**-25/25 - 0s - loss: 2.9626e-06 - mean_absolute_error: 0.0012 - val_loss: 1.7682e-06 - val_mean_absolute_error: 9.9916e-04 - 182ms/epoch - 7ms/step\n",
            "Epoch 119/500\n",
            " Train time0:00:24-25/25 - 0s - loss: 2.6864e-06 - mean_absolute_error: 0.0012 - val_loss: 1.8988e-06 - val_mean_absolute_error: 0.0010 - 148ms/epoch - 6ms/step\n",
            "Epoch 120/500\n",
            " Train time0:00:24-25/25 - 0s - loss: 2.2673e-06 - mean_absolute_error: 0.0011 - val_loss: 2.5323e-06 - val_mean_absolute_error: 0.0011 - 142ms/epoch - 6ms/step\n",
            "Epoch 121/500\n",
            " Train time0:00:24-25/25 - 0s - loss: 2.1604e-06 - mean_absolute_error: 0.0010 - val_loss: 1.9955e-06 - val_mean_absolute_error: 0.0010 - 145ms/epoch - 6ms/step\n",
            "Epoch 122/500\n",
            " Train time0:00:24-25/25 - 0s - loss: 2.3569e-06 - mean_absolute_error: 0.0011 - val_loss: 2.9098e-06 - val_mean_absolute_error: 0.0012 - 144ms/epoch - 6ms/step\n",
            "Epoch 123/500\n",
            " Train time0:00:25**best**-25/25 - 0s - loss: 2.1856e-06 - mean_absolute_error: 0.0010 - val_loss: 1.6628e-06 - val_mean_absolute_error: 9.3193e-04 - 180ms/epoch - 7ms/step\n",
            "Epoch 124/500\n",
            " Train time0:00:25**best**-25/25 - 0s - loss: 2.2094e-06 - mean_absolute_error: 0.0010 - val_loss: 1.6460e-06 - val_mean_absolute_error: 9.1272e-04 - 181ms/epoch - 7ms/step\n",
            "Epoch 125/500\n",
            " Train time0:00:25**best**-25/25 - 0s - loss: 2.0631e-06 - mean_absolute_error: 0.0010 - val_loss: 1.5847e-06 - val_mean_absolute_error: 9.2741e-04 - 178ms/epoch - 7ms/step\n",
            "Epoch 126/500\n",
            " Train time0:00:25**best**-25/25 - 0s - loss: 1.9551e-06 - mean_absolute_error: 9.7961e-04 - val_loss: 1.5347e-06 - val_mean_absolute_error: 8.9662e-04 - 187ms/epoch - 7ms/step\n",
            "Epoch 127/500\n",
            " Train time0:00:25**best**-25/25 - 0s - loss: 1.9857e-06 - mean_absolute_error: 9.9134e-04 - val_loss: 1.4441e-06 - val_mean_absolute_error: 8.8261e-04 - 177ms/epoch - 7ms/step\n",
            "Epoch 128/500\n",
            " Train time0:00:25-25/25 - 0s - loss: 1.8713e-06 - mean_absolute_error: 9.5922e-04 - val_loss: 1.4756e-06 - val_mean_absolute_error: 8.7035e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 129/500\n",
            " Train time0:00:26-25/25 - 0s - loss: 1.7966e-06 - mean_absolute_error: 9.4060e-04 - val_loss: 1.6462e-06 - val_mean_absolute_error: 8.9800e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 130/500\n",
            " Train time0:00:26**best**-25/25 - 0s - loss: 1.9570e-06 - mean_absolute_error: 9.7303e-04 - val_loss: 1.3424e-06 - val_mean_absolute_error: 8.4856e-04 - 180ms/epoch - 7ms/step\n",
            "Epoch 131/500\n",
            " Train time0:00:26**best**-25/25 - 0s - loss: 1.7321e-06 - mean_absolute_error: 9.1973e-04 - val_loss: 1.3145e-06 - val_mean_absolute_error: 8.3325e-04 - 186ms/epoch - 7ms/step\n",
            "Epoch 132/500\n",
            " Train time0:00:26**best**-25/25 - 0s - loss: 1.7088e-06 - mean_absolute_error: 9.1370e-04 - val_loss: 1.2547e-06 - val_mean_absolute_error: 8.1631e-04 - 193ms/epoch - 8ms/step\n",
            "Epoch 133/500\n",
            " Train time0:00:26-25/25 - 0s - loss: 2.1343e-06 - mean_absolute_error: 0.0010 - val_loss: 1.3844e-06 - val_mean_absolute_error: 8.1703e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 134/500\n",
            " Train time0:00:26-25/25 - 0s - loss: 1.5795e-06 - mean_absolute_error: 8.7295e-04 - val_loss: 1.2948e-06 - val_mean_absolute_error: 8.0211e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 135/500\n",
            " Train time0:00:27**best**-25/25 - 0s - loss: 1.6204e-06 - mean_absolute_error: 8.9136e-04 - val_loss: 1.1306e-06 - val_mean_absolute_error: 7.6239e-04 - 179ms/epoch - 7ms/step\n",
            "Epoch 136/500\n",
            " Train time0:00:27-25/25 - 0s - loss: 1.6044e-06 - mean_absolute_error: 8.7699e-04 - val_loss: 1.2113e-06 - val_mean_absolute_error: 7.9821e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 137/500\n",
            " Train time0:00:27-25/25 - 0s - loss: 2.2157e-06 - mean_absolute_error: 0.0010 - val_loss: 1.4044e-06 - val_mean_absolute_error: 8.2587e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 138/500\n",
            " Train time0:00:27-25/25 - 0s - loss: 1.5906e-06 - mean_absolute_error: 8.8507e-04 - val_loss: 1.1580e-06 - val_mean_absolute_error: 7.7198e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 139/500\n",
            " Train time0:00:27**best**-25/25 - 0s - loss: 1.5325e-06 - mean_absolute_error: 8.4969e-04 - val_loss: 1.0360e-06 - val_mean_absolute_error: 7.2538e-04 - 186ms/epoch - 7ms/step\n",
            "Epoch 140/500\n",
            " Train time0:00:27-25/25 - 0s - loss: 1.6752e-06 - mean_absolute_error: 8.8265e-04 - val_loss: 1.2871e-06 - val_mean_absolute_error: 7.8455e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 141/500\n",
            " Train time0:00:28-25/25 - 0s - loss: 1.4644e-06 - mean_absolute_error: 8.5294e-04 - val_loss: 1.1672e-06 - val_mean_absolute_error: 8.2517e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 142/500\n",
            " Train time0:00:28-25/25 - 0s - loss: 1.3981e-06 - mean_absolute_error: 8.2296e-04 - val_loss: 1.0509e-06 - val_mean_absolute_error: 7.3343e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 143/500\n",
            " Train time0:00:28-25/25 - 0s - loss: 1.5012e-06 - mean_absolute_error: 8.4466e-04 - val_loss: 2.1920e-06 - val_mean_absolute_error: 0.0011 - 147ms/epoch - 6ms/step\n",
            "Epoch 144/500\n",
            " Train time0:00:28-25/25 - 0s - loss: 1.4339e-06 - mean_absolute_error: 8.4068e-04 - val_loss: 1.2186e-06 - val_mean_absolute_error: 8.2874e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 145/500\n",
            " Train time0:00:28**best**-25/25 - 0s - loss: 1.4553e-06 - mean_absolute_error: 8.3439e-04 - val_loss: 9.5834e-07 - val_mean_absolute_error: 7.0080e-04 - 195ms/epoch - 8ms/step\n",
            "Epoch 146/500\n",
            " Train time0:00:28-25/25 - 0s - loss: 1.7351e-06 - mean_absolute_error: 8.9611e-04 - val_loss: 1.0302e-06 - val_mean_absolute_error: 7.4398e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 147/500\n",
            " Train time0:00:29-25/25 - 0s - loss: 1.5044e-06 - mean_absolute_error: 8.3992e-04 - val_loss: 1.0467e-06 - val_mean_absolute_error: 7.2152e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 148/500\n",
            " Train time0:00:29-25/25 - 0s - loss: 1.7742e-06 - mean_absolute_error: 9.2404e-04 - val_loss: 1.6468e-06 - val_mean_absolute_error: 8.9463e-04 - 140ms/epoch - 6ms/step\n",
            "Epoch 149/500\n",
            " Train time0:00:29-25/25 - 0s - loss: 1.8397e-06 - mean_absolute_error: 9.4331e-04 - val_loss: 1.1454e-06 - val_mean_absolute_error: 7.8207e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 150/500\n",
            " Train time0:00:29-25/25 - 0s - loss: 1.7113e-06 - mean_absolute_error: 9.0979e-04 - val_loss: 1.2044e-06 - val_mean_absolute_error: 8.1856e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 151/500\n",
            " Train time0:00:29-25/25 - 0s - loss: 1.8898e-06 - mean_absolute_error: 9.6567e-04 - val_loss: 3.7148e-06 - val_mean_absolute_error: 0.0015 - 141ms/epoch - 6ms/step\n",
            "Epoch 152/500\n",
            " Train time0:00:29-25/25 - 0s - loss: 2.4969e-06 - mean_absolute_error: 0.0011 - val_loss: 1.3511e-06 - val_mean_absolute_error: 8.7494e-04 - 163ms/epoch - 7ms/step\n",
            "Epoch 153/500\n",
            " Train time0:00:29**best**-25/25 - 0s - loss: 1.6069e-06 - mean_absolute_error: 8.9584e-04 - val_loss: 8.6971e-07 - val_mean_absolute_error: 6.6787e-04 - 182ms/epoch - 7ms/step\n",
            "Epoch 154/500\n",
            " Train time0:00:30-25/25 - 0s - loss: 1.4258e-06 - mean_absolute_error: 8.3272e-04 - val_loss: 9.4775e-07 - val_mean_absolute_error: 6.8400e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 155/500\n",
            " Train time0:00:30-25/25 - 0s - loss: 1.0899e-06 - mean_absolute_error: 7.4804e-04 - val_loss: 1.0413e-06 - val_mean_absolute_error: 7.4964e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 156/500\n",
            " Train time0:00:30-25/25 - 0s - loss: 1.4526e-06 - mean_absolute_error: 8.4597e-04 - val_loss: 1.6149e-06 - val_mean_absolute_error: 8.7059e-04 - 153ms/epoch - 6ms/step\n",
            "Epoch 157/500\n",
            " Train time0:00:30-25/25 - 0s - loss: 1.3743e-06 - mean_absolute_error: 8.2805e-04 - val_loss: 9.5433e-07 - val_mean_absolute_error: 6.8966e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 158/500\n",
            " Train time0:00:30-25/25 - 0s - loss: 1.4138e-06 - mean_absolute_error: 8.4112e-04 - val_loss: 2.0204e-06 - val_mean_absolute_error: 0.0011 - 143ms/epoch - 6ms/step\n",
            "Epoch 159/500\n",
            " Train time0:00:30-25/25 - 0s - loss: 1.7751e-06 - mean_absolute_error: 9.4521e-04 - val_loss: 1.1494e-06 - val_mean_absolute_error: 7.4062e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 160/500\n",
            " Train time0:00:31**best**-25/25 - 0s - loss: 1.3535e-06 - mean_absolute_error: 8.1739e-04 - val_loss: 7.7545e-07 - val_mean_absolute_error: 6.5966e-04 - 177ms/epoch - 7ms/step\n",
            "Epoch 161/500\n",
            " Train time0:00:31-25/25 - 0s - loss: 1.0416e-06 - mean_absolute_error: 7.3659e-04 - val_loss: 9.6062e-07 - val_mean_absolute_error: 7.2777e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 162/500\n",
            " Train time0:00:31-25/25 - 0s - loss: 2.0320e-06 - mean_absolute_error: 0.0010 - val_loss: 5.5492e-06 - val_mean_absolute_error: 0.0020 - 144ms/epoch - 6ms/step\n",
            "Epoch 163/500\n",
            " Train time0:00:31-25/25 - 0s - loss: 2.9361e-06 - mean_absolute_error: 0.0013 - val_loss: 2.3104e-06 - val_mean_absolute_error: 0.0011 - 143ms/epoch - 6ms/step\n",
            "Epoch 164/500\n",
            " Train time0:00:31**best**-25/25 - 0s - loss: 1.0734e-06 - mean_absolute_error: 7.5246e-04 - val_loss: 7.3083e-07 - val_mean_absolute_error: 6.3819e-04 - 178ms/epoch - 7ms/step\n",
            "Epoch 165/500\n",
            " Train time0:00:31-25/25 - 0s - loss: 1.4758e-06 - mean_absolute_error: 8.6857e-04 - val_loss: 2.3687e-06 - val_mean_absolute_error: 0.0012 - 145ms/epoch - 6ms/step\n",
            "Epoch 166/500\n",
            " Train time0:00:31**best**-25/25 - 0s - loss: 1.3785e-06 - mean_absolute_error: 8.5027e-04 - val_loss: 7.0222e-07 - val_mean_absolute_error: 6.2830e-04 - 176ms/epoch - 7ms/step\n",
            "Epoch 167/500\n",
            " Train time0:00:32-25/25 - 0s - loss: 1.3220e-06 - mean_absolute_error: 8.3288e-04 - val_loss: 8.3524e-07 - val_mean_absolute_error: 6.6785e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 168/500\n",
            " Train time0:00:32-25/25 - 0s - loss: 1.2759e-06 - mean_absolute_error: 8.2747e-04 - val_loss: 1.3740e-06 - val_mean_absolute_error: 8.8806e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 169/500\n",
            " Train time0:00:32-25/25 - 0s - loss: 1.2163e-06 - mean_absolute_error: 7.9881e-04 - val_loss: 8.3213e-07 - val_mean_absolute_error: 7.0059e-04 - 140ms/epoch - 6ms/step\n",
            "Epoch 170/500\n",
            " Train time0:00:32-25/25 - 0s - loss: 9.8867e-07 - mean_absolute_error: 7.3556e-04 - val_loss: 2.6658e-06 - val_mean_absolute_error: 0.0013 - 146ms/epoch - 6ms/step\n",
            "Epoch 171/500\n",
            " Train time0:00:32-25/25 - 0s - loss: 1.3389e-06 - mean_absolute_error: 8.2988e-04 - val_loss: 1.4747e-06 - val_mean_absolute_error: 8.8395e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 172/500\n",
            " Train time0:00:32-25/25 - 0s - loss: 1.9980e-06 - mean_absolute_error: 0.0010 - val_loss: 9.1984e-07 - val_mean_absolute_error: 7.2224e-04 - 154ms/epoch - 6ms/step\n",
            "Epoch 173/500\n",
            " Train time0:00:33-25/25 - 0s - loss: 1.1275e-06 - mean_absolute_error: 7.7413e-04 - val_loss: 7.2014e-07 - val_mean_absolute_error: 6.5780e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 174/500\n",
            " Train time0:00:33-25/25 - 0s - loss: 1.0833e-06 - mean_absolute_error: 7.6566e-04 - val_loss: 1.8757e-06 - val_mean_absolute_error: 0.0011 - 143ms/epoch - 6ms/step\n",
            "Epoch 175/500\n",
            " Train time0:00:33-25/25 - 0s - loss: 1.6115e-06 - mean_absolute_error: 9.1431e-04 - val_loss: 1.5161e-06 - val_mean_absolute_error: 8.7615e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 176/500\n",
            " Train time0:00:33-25/25 - 0s - loss: 3.2342e-06 - mean_absolute_error: 0.0013 - val_loss: 2.5653e-06 - val_mean_absolute_error: 0.0012 - 143ms/epoch - 6ms/step\n",
            "Epoch 177/500\n",
            " Train time0:00:33-25/25 - 0s - loss: 1.2964e-06 - mean_absolute_error: 8.2533e-04 - val_loss: 8.5064e-07 - val_mean_absolute_error: 6.9501e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 178/500\n",
            " Train time0:00:33**best**-25/25 - 0s - loss: 1.1109e-06 - mean_absolute_error: 7.8868e-04 - val_loss: 6.8098e-07 - val_mean_absolute_error: 6.5224e-04 - 180ms/epoch - 7ms/step\n",
            "Epoch 179/500\n",
            " Train time0:00:33-25/25 - 0s - loss: 1.2062e-06 - mean_absolute_error: 8.1086e-04 - val_loss: 9.3486e-07 - val_mean_absolute_error: 7.0631e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 180/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 1.5939e-06 - mean_absolute_error: 9.2387e-04 - val_loss: 1.2122e-06 - val_mean_absolute_error: 8.0430e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 181/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 1.1393e-06 - mean_absolute_error: 7.9633e-04 - val_loss: 6.8713e-07 - val_mean_absolute_error: 6.5391e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 182/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 1.1731e-06 - mean_absolute_error: 8.0322e-04 - val_loss: 8.3154e-07 - val_mean_absolute_error: 6.8913e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 183/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 1.4262e-06 - mean_absolute_error: 8.8461e-04 - val_loss: 1.7857e-06 - val_mean_absolute_error: 9.6182e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 184/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 1.9865e-06 - mean_absolute_error: 0.0010 - val_loss: 5.8198e-06 - val_mean_absolute_error: 0.0020 - 144ms/epoch - 6ms/step\n",
            "Epoch 185/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 4.0594e-06 - mean_absolute_error: 0.0015 - val_loss: 1.0528e-06 - val_mean_absolute_error: 7.8246e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 186/500\n",
            " Train time0:00:34-25/25 - 0s - loss: 1.4569e-06 - mean_absolute_error: 8.9965e-04 - val_loss: 7.1134e-07 - val_mean_absolute_error: 6.6573e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 187/500\n",
            " Train time0:00:35-25/25 - 0s - loss: 2.1958e-06 - mean_absolute_error: 0.0011 - val_loss: 3.6748e-06 - val_mean_absolute_error: 0.0015 - 141ms/epoch - 6ms/step\n",
            "Epoch 188/500\n",
            " Train time0:00:35-25/25 - 0s - loss: 3.8652e-06 - mean_absolute_error: 0.0015 - val_loss: 1.0086e-06 - val_mean_absolute_error: 7.1880e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 189/500\n",
            " Train time0:00:35-25/25 - 0s - loss: 9.0872e-07 - mean_absolute_error: 7.1682e-04 - val_loss: 1.7746e-06 - val_mean_absolute_error: 0.0010 - 146ms/epoch - 6ms/step\n",
            "Epoch 190/500\n",
            " Train time0:00:35-25/25 - 0s - loss: 1.1589e-06 - mean_absolute_error: 8.0662e-04 - val_loss: 7.1071e-07 - val_mean_absolute_error: 6.6441e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 191/500\n",
            " Train time0:00:35-25/25 - 0s - loss: 1.2594e-06 - mean_absolute_error: 8.3051e-04 - val_loss: 7.8214e-07 - val_mean_absolute_error: 6.8920e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 192/500\n",
            " Train time0:00:35-25/25 - 0s - loss: 1.1957e-06 - mean_absolute_error: 8.1219e-04 - val_loss: 6.8582e-07 - val_mean_absolute_error: 6.4337e-04 - 155ms/epoch - 6ms/step\n",
            "Epoch 193/500\n",
            " Train time0:00:36**best**-25/25 - 0s - loss: 1.1824e-06 - mean_absolute_error: 8.0580e-04 - val_loss: 6.7372e-07 - val_mean_absolute_error: 6.7751e-04 - 183ms/epoch - 7ms/step\n",
            "Epoch 194/500\n",
            " Train time0:00:36-25/25 - 0s - loss: 1.3045e-06 - mean_absolute_error: 8.4852e-04 - val_loss: 7.4168e-07 - val_mean_absolute_error: 6.6636e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 195/500\n",
            " Train time0:00:36-25/25 - 0s - loss: 1.6834e-06 - mean_absolute_error: 9.7699e-04 - val_loss: 1.1953e-06 - val_mean_absolute_error: 8.4813e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 196/500\n",
            " Train time0:00:36-25/25 - 0s - loss: 1.6633e-06 - mean_absolute_error: 9.6613e-04 - val_loss: 1.5454e-06 - val_mean_absolute_error: 0.0010 - 146ms/epoch - 6ms/step\n",
            "Epoch 197/500\n",
            " Train time0:00:36-25/25 - 0s - loss: 3.3275e-06 - mean_absolute_error: 0.0013 - val_loss: 1.5104e-06 - val_mean_absolute_error: 8.7242e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 198/500\n",
            " Train time0:00:36-25/25 - 0s - loss: 1.5097e-06 - mean_absolute_error: 9.2190e-04 - val_loss: 9.1347e-07 - val_mean_absolute_error: 7.4701e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 199/500\n",
            " Train time0:00:36-25/25 - 0s - loss: 2.0755e-06 - mean_absolute_error: 0.0010 - val_loss: 1.4745e-06 - val_mean_absolute_error: 8.9455e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 200/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 2.7070e-06 - mean_absolute_error: 0.0013 - val_loss: 7.9920e-07 - val_mean_absolute_error: 6.6968e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 201/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 2.4980e-06 - mean_absolute_error: 0.0012 - val_loss: 1.1106e-06 - val_mean_absolute_error: 7.7201e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 202/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 3.6989e-06 - mean_absolute_error: 0.0015 - val_loss: 9.9981e-07 - val_mean_absolute_error: 7.5987e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 203/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 9.5869e-07 - mean_absolute_error: 7.4596e-04 - val_loss: 7.8441e-07 - val_mean_absolute_error: 6.7135e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 204/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 1.7237e-06 - mean_absolute_error: 9.7017e-04 - val_loss: 1.5132e-06 - val_mean_absolute_error: 9.1490e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 205/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 1.9558e-06 - mean_absolute_error: 0.0010 - val_loss: 2.7879e-06 - val_mean_absolute_error: 0.0013 - 148ms/epoch - 6ms/step\n",
            "Epoch 206/500\n",
            " Train time0:00:37-25/25 - 0s - loss: 2.2651e-06 - mean_absolute_error: 0.0011 - val_loss: 4.3696e-06 - val_mean_absolute_error: 0.0016 - 152ms/epoch - 6ms/step\n",
            "Epoch 207/500\n",
            " Train time0:00:38-25/25 - 0s - loss: 4.9967e-06 - mean_absolute_error: 0.0016 - val_loss: 3.8938e-06 - val_mean_absolute_error: 0.0017 - 142ms/epoch - 6ms/step\n",
            "Epoch 208/500\n",
            " Train time0:00:38-25/25 - 0s - loss: 1.6419e-06 - mean_absolute_error: 9.4604e-04 - val_loss: 6.8533e-06 - val_mean_absolute_error: 0.0021 - 143ms/epoch - 6ms/step\n",
            "Epoch 209/500\n",
            " Train time0:00:38-25/25 - 0s - loss: 2.9379e-06 - mean_absolute_error: 0.0013 - val_loss: 2.0543e-06 - val_mean_absolute_error: 0.0012 - 147ms/epoch - 6ms/step\n",
            "Epoch 210/500\n",
            " Train time0:00:38-25/25 - 0s - loss: 2.2498e-06 - mean_absolute_error: 0.0011 - val_loss: 2.7735e-06 - val_mean_absolute_error: 0.0012 - 145ms/epoch - 6ms/step\n",
            "Epoch 211/500\n",
            " Train time0:00:38-25/25 - 0s - loss: 1.9304e-06 - mean_absolute_error: 0.0010 - val_loss: 6.9109e-07 - val_mean_absolute_error: 6.3548e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 212/500\n",
            " Train time0:00:38-25/25 - 0s - loss: 1.0520e-06 - mean_absolute_error: 7.6962e-04 - val_loss: 1.8744e-06 - val_mean_absolute_error: 0.0011 - 147ms/epoch - 6ms/step\n",
            "Epoch 213/500\n",
            " Train time0:00:39-25/25 - 0s - loss: 1.5061e-06 - mean_absolute_error: 9.2422e-04 - val_loss: 7.1099e-07 - val_mean_absolute_error: 6.8831e-04 - 157ms/epoch - 6ms/step\n",
            "Epoch 214/500\n",
            " Train time0:00:39-25/25 - 0s - loss: 1.2244e-06 - mean_absolute_error: 8.2615e-04 - val_loss: 1.3320e-06 - val_mean_absolute_error: 8.9667e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 215/500\n",
            " Train time0:00:39**best**-25/25 - 0s - loss: 1.5309e-06 - mean_absolute_error: 9.1017e-04 - val_loss: 6.1234e-07 - val_mean_absolute_error: 6.2598e-04 - 181ms/epoch - 7ms/step\n",
            "Epoch 216/500\n",
            " Train time0:00:39-25/25 - 0s - loss: 3.8796e-06 - mean_absolute_error: 0.0015 - val_loss: 1.1588e-05 - val_mean_absolute_error: 0.0030 - 145ms/epoch - 6ms/step\n",
            "Epoch 217/500\n",
            " Train time0:00:39-25/25 - 0s - loss: 3.6590e-06 - mean_absolute_error: 0.0014 - val_loss: 2.9782e-06 - val_mean_absolute_error: 0.0013 - 142ms/epoch - 6ms/step\n",
            "Epoch 218/500\n",
            " Train time0:00:39-25/25 - 0s - loss: 1.4949e-06 - mean_absolute_error: 9.1038e-04 - val_loss: 1.4825e-06 - val_mean_absolute_error: 9.2279e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 219/500\n",
            " Train time0:00:39**best**-25/25 - 0s - loss: 8.9196e-07 - mean_absolute_error: 7.1427e-04 - val_loss: 6.0044e-07 - val_mean_absolute_error: 5.9852e-04 - 186ms/epoch - 7ms/step\n",
            "Epoch 220/500\n",
            " Train time0:00:40-25/25 - 0s - loss: 4.6866e-06 - mean_absolute_error: 0.0016 - val_loss: 7.2499e-07 - val_mean_absolute_error: 6.4972e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 221/500\n",
            " Train time0:00:40-25/25 - 0s - loss: 2.6848e-06 - mean_absolute_error: 0.0012 - val_loss: 3.5670e-06 - val_mean_absolute_error: 0.0016 - 144ms/epoch - 6ms/step\n",
            "Epoch 222/500\n",
            " Train time0:00:40-25/25 - 0s - loss: 3.1840e-06 - mean_absolute_error: 0.0013 - val_loss: 1.0889e-05 - val_mean_absolute_error: 0.0028 - 144ms/epoch - 6ms/step\n",
            "Epoch 223/500\n",
            " Train time0:00:40-25/25 - 0s - loss: 9.0860e-06 - mean_absolute_error: 0.0023 - val_loss: 8.9639e-07 - val_mean_absolute_error: 6.8460e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 224/500\n",
            " Train time0:00:40-25/25 - 0s - loss: 6.5154e-06 - mean_absolute_error: 0.0019 - val_loss: 3.4861e-06 - val_mean_absolute_error: 0.0014 - 144ms/epoch - 6ms/step\n",
            "Epoch 225/500\n",
            " Train time0:00:40-25/25 - 0s - loss: 1.3880e-06 - mean_absolute_error: 8.6532e-04 - val_loss: 1.6163e-06 - val_mean_absolute_error: 0.0010 - 145ms/epoch - 6ms/step\n",
            "Epoch 226/500\n",
            " Train time0:00:41-25/25 - 0s - loss: 1.3249e-06 - mean_absolute_error: 8.6812e-04 - val_loss: 7.5501e-07 - val_mean_absolute_error: 6.8453e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 227/500\n",
            " Train time0:00:41-25/25 - 0s - loss: 1.0419e-06 - mean_absolute_error: 7.6299e-04 - val_loss: 1.4994e-06 - val_mean_absolute_error: 9.1168e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 228/500\n",
            " Train time0:00:41-25/25 - 0s - loss: 1.9773e-06 - mean_absolute_error: 0.0010 - val_loss: 2.4403e-06 - val_mean_absolute_error: 0.0013 - 144ms/epoch - 6ms/step\n",
            "Epoch 229/500\n",
            " Train time0:00:41-25/25 - 0s - loss: 6.0344e-06 - mean_absolute_error: 0.0018 - val_loss: 6.8861e-07 - val_mean_absolute_error: 6.3505e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 230/500\n",
            " Train time0:00:41-25/25 - 0s - loss: 3.2796e-06 - mean_absolute_error: 0.0014 - val_loss: 1.6312e-05 - val_mean_absolute_error: 0.0034 - 146ms/epoch - 6ms/step\n",
            "Epoch 231/500\n",
            " Train time0:00:41-25/25 - 0s - loss: 5.9974e-06 - mean_absolute_error: 0.0018 - val_loss: 2.1387e-06 - val_mean_absolute_error: 0.0011 - 143ms/epoch - 6ms/step\n",
            "Epoch 232/500\n",
            " Train time0:00:41**best**-25/25 - 0s - loss: 3.9480e-06 - mean_absolute_error: 0.0015 - val_loss: 5.9061e-07 - val_mean_absolute_error: 5.8136e-04 - 179ms/epoch - 7ms/step\n",
            "Epoch 233/500\n",
            " Train time0:00:42**best**-25/25 - 0s - loss: 1.1820e-06 - mean_absolute_error: 8.1058e-04 - val_loss: 5.6758e-07 - val_mean_absolute_error: 6.0038e-04 - 194ms/epoch - 8ms/step\n",
            "Epoch 234/500\n",
            " Train time0:00:42-25/25 - 0s - loss: 1.2955e-06 - mean_absolute_error: 8.3846e-04 - val_loss: 5.4510e-06 - val_mean_absolute_error: 0.0019 - 140ms/epoch - 6ms/step\n",
            "Epoch 235/500\n",
            " Train time0:00:42-25/25 - 0s - loss: 2.3156e-06 - mean_absolute_error: 0.0011 - val_loss: 1.1162e-06 - val_mean_absolute_error: 7.4761e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 236/500\n",
            " Train time0:00:42-25/25 - 0s - loss: 7.7349e-06 - mean_absolute_error: 0.0018 - val_loss: 2.3452e-05 - val_mean_absolute_error: 0.0043 - 142ms/epoch - 6ms/step\n",
            "Epoch 237/500\n",
            " Train time0:00:42-25/25 - 0s - loss: 6.3503e-06 - mean_absolute_error: 0.0019 - val_loss: 1.4125e-06 - val_mean_absolute_error: 9.6172e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 238/500\n",
            " Train time0:00:42-25/25 - 0s - loss: 1.6162e-06 - mean_absolute_error: 9.2401e-04 - val_loss: 6.2696e-06 - val_mean_absolute_error: 0.0022 - 142ms/epoch - 6ms/step\n",
            "Epoch 239/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 2.1707e-06 - mean_absolute_error: 0.0011 - val_loss: 3.9253e-06 - val_mean_absolute_error: 0.0016 - 142ms/epoch - 6ms/step\n",
            "Epoch 240/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 2.8970e-06 - mean_absolute_error: 0.0012 - val_loss: 1.2398e-06 - val_mean_absolute_error: 8.5928e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 241/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 4.9658e-06 - mean_absolute_error: 0.0016 - val_loss: 8.4012e-07 - val_mean_absolute_error: 6.8563e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 242/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 4.9505e-06 - mean_absolute_error: 0.0017 - val_loss: 1.2601e-05 - val_mean_absolute_error: 0.0032 - 144ms/epoch - 6ms/step\n",
            "Epoch 243/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 5.7448e-06 - mean_absolute_error: 0.0019 - val_loss: 2.9510e-06 - val_mean_absolute_error: 0.0015 - 141ms/epoch - 6ms/step\n",
            "Epoch 244/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 4.4655e-06 - mean_absolute_error: 0.0016 - val_loss: 8.8082e-07 - val_mean_absolute_error: 6.9184e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 245/500\n",
            " Train time0:00:43-25/25 - 0s - loss: 1.7035e-06 - mean_absolute_error: 9.6864e-04 - val_loss: 2.0827e-06 - val_mean_absolute_error: 0.0011 - 141ms/epoch - 6ms/step\n",
            "Epoch 246/500\n",
            " Train time0:00:44-25/25 - 0s - loss: 2.9082e-06 - mean_absolute_error: 0.0012 - val_loss: 5.7693e-06 - val_mean_absolute_error: 0.0021 - 149ms/epoch - 6ms/step\n",
            "Epoch 247/500\n",
            " Train time0:00:44-25/25 - 0s - loss: 5.7981e-06 - mean_absolute_error: 0.0018 - val_loss: 4.5942e-06 - val_mean_absolute_error: 0.0016 - 142ms/epoch - 6ms/step\n",
            "Epoch 248/500\n",
            " Train time0:00:44-25/25 - 0s - loss: 2.0300e-06 - mean_absolute_error: 9.9977e-04 - val_loss: 6.6452e-07 - val_mean_absolute_error: 5.9780e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 249/500\n",
            " Train time0:00:44**best**-25/25 - 0s - loss: 1.2891e-06 - mean_absolute_error: 8.3460e-04 - val_loss: 5.3605e-07 - val_mean_absolute_error: 5.8570e-04 - 179ms/epoch - 7ms/step\n",
            "Epoch 250/500\n",
            " Train time0:00:44-25/25 - 0s - loss: 1.5895e-06 - mean_absolute_error: 9.3294e-04 - val_loss: 8.5545e-07 - val_mean_absolute_error: 6.6386e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 251/500\n",
            " Train time0:00:44-25/25 - 0s - loss: 1.1073e-06 - mean_absolute_error: 7.7599e-04 - val_loss: 6.1857e-07 - val_mean_absolute_error: 6.2102e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 252/500\n",
            " Train time0:00:44-25/25 - 0s - loss: 2.1634e-06 - mean_absolute_error: 0.0011 - val_loss: 6.9071e-07 - val_mean_absolute_error: 6.1741e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 253/500\n",
            " Train time0:00:45-25/25 - 0s - loss: 1.7880e-06 - mean_absolute_error: 9.8727e-04 - val_loss: 2.3368e-06 - val_mean_absolute_error: 0.0013 - 156ms/epoch - 6ms/step\n",
            "Epoch 254/500\n",
            " Train time0:00:45-25/25 - 0s - loss: 1.3112e-05 - mean_absolute_error: 0.0026 - val_loss: 1.3625e-05 - val_mean_absolute_error: 0.0032 - 142ms/epoch - 6ms/step\n",
            "Epoch 255/500\n",
            " Train time0:00:45-25/25 - 0s - loss: 5.6173e-06 - mean_absolute_error: 0.0017 - val_loss: 2.7417e-06 - val_mean_absolute_error: 0.0012 - 146ms/epoch - 6ms/step\n",
            "Epoch 256/500\n",
            " Train time0:00:45-25/25 - 0s - loss: 5.3922e-06 - mean_absolute_error: 0.0018 - val_loss: 8.2531e-06 - val_mean_absolute_error: 0.0025 - 146ms/epoch - 6ms/step\n",
            "Epoch 257/500\n",
            " Train time0:00:45-25/25 - 0s - loss: 2.3195e-06 - mean_absolute_error: 0.0011 - val_loss: 1.2909e-06 - val_mean_absolute_error: 8.9318e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 258/500\n",
            " Train time0:00:45-25/25 - 0s - loss: 1.5861e-06 - mean_absolute_error: 9.2098e-04 - val_loss: 5.5863e-07 - val_mean_absolute_error: 5.7341e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 259/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 1.5753e-06 - mean_absolute_error: 9.2748e-04 - val_loss: 3.4532e-06 - val_mean_absolute_error: 0.0015 - 144ms/epoch - 6ms/step\n",
            "Epoch 260/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 2.0332e-06 - mean_absolute_error: 0.0011 - val_loss: 7.2947e-07 - val_mean_absolute_error: 6.3569e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 261/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 3.3217e-06 - mean_absolute_error: 0.0013 - val_loss: 6.8324e-06 - val_mean_absolute_error: 0.0022 - 144ms/epoch - 6ms/step\n",
            "Epoch 262/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 1.0435e-05 - mean_absolute_error: 0.0025 - val_loss: 1.0926e-05 - val_mean_absolute_error: 0.0027 - 143ms/epoch - 6ms/step\n",
            "Epoch 263/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 4.3759e-06 - mean_absolute_error: 0.0015 - val_loss: 7.9980e-07 - val_mean_absolute_error: 7.2256e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 264/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 1.2950e-06 - mean_absolute_error: 8.4585e-04 - val_loss: 7.8913e-06 - val_mean_absolute_error: 0.0024 - 147ms/epoch - 6ms/step\n",
            "Epoch 265/500\n",
            " Train time0:00:46-25/25 - 0s - loss: 3.0355e-06 - mean_absolute_error: 0.0013 - val_loss: 7.6615e-07 - val_mean_absolute_error: 6.2811e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 266/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 9.3377e-07 - mean_absolute_error: 7.2032e-04 - val_loss: 2.5640e-06 - val_mean_absolute_error: 0.0012 - 140ms/epoch - 6ms/step\n",
            "Epoch 267/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 1.3138e-06 - mean_absolute_error: 8.4041e-04 - val_loss: 2.1936e-06 - val_mean_absolute_error: 0.0012 - 159ms/epoch - 6ms/step\n",
            "Epoch 268/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 2.5811e-06 - mean_absolute_error: 0.0012 - val_loss: 6.3950e-06 - val_mean_absolute_error: 0.0022 - 140ms/epoch - 6ms/step\n",
            "Epoch 269/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 6.5892e-06 - mean_absolute_error: 0.0020 - val_loss: 1.1802e-06 - val_mean_absolute_error: 7.6103e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 270/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 4.8633e-06 - mean_absolute_error: 0.0017 - val_loss: 8.6147e-07 - val_mean_absolute_error: 7.2990e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 271/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 7.4899e-06 - mean_absolute_error: 0.0021 - val_loss: 7.8314e-07 - val_mean_absolute_error: 7.0539e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 272/500\n",
            " Train time0:00:47-25/25 - 0s - loss: 2.4352e-06 - mean_absolute_error: 0.0012 - val_loss: 3.0671e-06 - val_mean_absolute_error: 0.0015 - 143ms/epoch - 6ms/step\n",
            "Epoch 273/500\n",
            " Train time0:00:48-25/25 - 0s - loss: 4.1850e-06 - mean_absolute_error: 0.0015 - val_loss: 8.9620e-07 - val_mean_absolute_error: 7.4080e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 274/500\n",
            " Train time0:00:48-25/25 - 0s - loss: 2.0713e-05 - mean_absolute_error: 0.0034 - val_loss: 1.6650e-06 - val_mean_absolute_error: 9.8324e-04 - 162ms/epoch - 6ms/step\n",
            "Epoch 275/500\n",
            " Train time0:00:48**best**-25/25 - 0s - loss: 6.7098e-06 - mean_absolute_error: 0.0020 - val_loss: 4.7991e-07 - val_mean_absolute_error: 5.2397e-04 - 181ms/epoch - 7ms/step\n",
            "Epoch 276/500\n",
            " Train time0:00:48-25/25 - 0s - loss: 5.8138e-06 - mean_absolute_error: 0.0017 - val_loss: 5.6021e-06 - val_mean_absolute_error: 0.0019 - 150ms/epoch - 6ms/step\n",
            "Epoch 277/500\n",
            " Train time0:00:48-25/25 - 0s - loss: 4.8259e-06 - mean_absolute_error: 0.0017 - val_loss: 7.1419e-06 - val_mean_absolute_error: 0.0023 - 163ms/epoch - 7ms/step\n",
            "Epoch 278/500\n",
            " Train time0:00:48-25/25 - 0s - loss: 3.6460e-06 - mean_absolute_error: 0.0014 - val_loss: 7.7856e-06 - val_mean_absolute_error: 0.0024 - 153ms/epoch - 6ms/step\n",
            "Epoch 279/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 1.0610e-05 - mean_absolute_error: 0.0025 - val_loss: 7.5671e-06 - val_mean_absolute_error: 0.0023 - 152ms/epoch - 6ms/step\n",
            "Epoch 280/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 3.8662e-06 - mean_absolute_error: 0.0015 - val_loss: 8.5966e-07 - val_mean_absolute_error: 7.3177e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 281/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 2.1394e-06 - mean_absolute_error: 0.0011 - val_loss: 5.4675e-06 - val_mean_absolute_error: 0.0020 - 144ms/epoch - 6ms/step\n",
            "Epoch 282/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 6.3435e-06 - mean_absolute_error: 0.0019 - val_loss: 7.6654e-07 - val_mean_absolute_error: 6.7365e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 283/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 4.1331e-06 - mean_absolute_error: 0.0015 - val_loss: 9.7081e-07 - val_mean_absolute_error: 7.7976e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 284/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 2.4337e-06 - mean_absolute_error: 0.0012 - val_loss: 5.1691e-06 - val_mean_absolute_error: 0.0017 - 145ms/epoch - 6ms/step\n",
            "Epoch 285/500\n",
            " Train time0:00:49-25/25 - 0s - loss: 2.6502e-06 - mean_absolute_error: 0.0012 - val_loss: 3.9688e-06 - val_mean_absolute_error: 0.0017 - 156ms/epoch - 6ms/step\n",
            "Epoch 286/500\n",
            " Train time0:00:50-25/25 - 0s - loss: 4.4439e-06 - mean_absolute_error: 0.0016 - val_loss: 1.4750e-05 - val_mean_absolute_error: 0.0032 - 160ms/epoch - 6ms/step\n",
            "Epoch 287/500\n",
            " Train time0:00:50-25/25 - 0s - loss: 3.2397e-06 - mean_absolute_error: 0.0013 - val_loss: 5.0641e-07 - val_mean_absolute_error: 5.3230e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 288/500\n",
            " Train time0:00:50-25/25 - 0s - loss: 2.4732e-06 - mean_absolute_error: 0.0012 - val_loss: 2.8069e-06 - val_mean_absolute_error: 0.0015 - 143ms/epoch - 6ms/step\n",
            "Epoch 289/500\n",
            " Train time0:00:50-25/25 - 0s - loss: 2.1793e-06 - mean_absolute_error: 0.0011 - val_loss: 2.1596e-06 - val_mean_absolute_error: 0.0010 - 151ms/epoch - 6ms/step\n",
            "Epoch 290/500\n",
            " Train time0:00:50-25/25 - 0s - loss: 2.2875e-06 - mean_absolute_error: 0.0011 - val_loss: 6.6175e-07 - val_mean_absolute_error: 6.2612e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 291/500\n",
            " Train time0:00:50-25/25 - 0s - loss: 3.4917e-06 - mean_absolute_error: 0.0014 - val_loss: 4.1495e-06 - val_mean_absolute_error: 0.0015 - 152ms/epoch - 6ms/step\n",
            "Epoch 292/500\n",
            " Train time0:00:51-25/25 - 0s - loss: 8.9601e-06 - mean_absolute_error: 0.0022 - val_loss: 4.4908e-06 - val_mean_absolute_error: 0.0018 - 146ms/epoch - 6ms/step\n",
            "Epoch 293/500\n",
            " Train time0:00:51-25/25 - 0s - loss: 3.7762e-06 - mean_absolute_error: 0.0015 - val_loss: 1.9884e-06 - val_mean_absolute_error: 0.0011 - 158ms/epoch - 6ms/step\n",
            "Epoch 294/500\n",
            " Train time0:00:51-25/25 - 0s - loss: 4.4996e-06 - mean_absolute_error: 0.0016 - val_loss: 1.5404e-06 - val_mean_absolute_error: 9.0550e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 295/500\n",
            " Train time0:00:51**best**-25/25 - 0s - loss: 3.5456e-06 - mean_absolute_error: 0.0014 - val_loss: 4.6139e-07 - val_mean_absolute_error: 5.1955e-04 - 186ms/epoch - 7ms/step\n",
            "Epoch 296/500\n",
            " Train time0:00:51-25/25 - 0s - loss: 1.3903e-06 - mean_absolute_error: 8.8038e-04 - val_loss: 6.2550e-07 - val_mean_absolute_error: 5.7737e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 297/500\n",
            " Train time0:00:51-25/25 - 0s - loss: 7.4654e-07 - mean_absolute_error: 6.5439e-04 - val_loss: 9.1473e-07 - val_mean_absolute_error: 7.0444e-04 - 153ms/epoch - 6ms/step\n",
            "Epoch 298/500\n",
            " Train time0:00:52-25/25 - 0s - loss: 2.6942e-06 - mean_absolute_error: 0.0012 - val_loss: 9.1787e-06 - val_mean_absolute_error: 0.0027 - 167ms/epoch - 7ms/step\n",
            "Epoch 299/500\n",
            " Train time0:00:52**best**-25/25 - 0s - loss: 2.6035e-06 - mean_absolute_error: 0.0012 - val_loss: 4.0576e-07 - val_mean_absolute_error: 4.9317e-04 - 186ms/epoch - 7ms/step\n",
            "Epoch 300/500\n",
            " Train time0:00:52-25/25 - 0s - loss: 9.2185e-07 - mean_absolute_error: 7.1024e-04 - val_loss: 7.0371e-07 - val_mean_absolute_error: 6.3172e-04 - 163ms/epoch - 7ms/step\n",
            "Epoch 301/500\n",
            " Train time0:00:52-25/25 - 0s - loss: 1.2914e-06 - mean_absolute_error: 8.4358e-04 - val_loss: 9.7472e-07 - val_mean_absolute_error: 7.2788e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 302/500\n",
            " Train time0:00:52-25/25 - 0s - loss: 1.7188e-06 - mean_absolute_error: 9.6654e-04 - val_loss: 1.2138e-06 - val_mean_absolute_error: 8.1767e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 303/500\n",
            " Train time0:00:52-25/25 - 0s - loss: 9.5728e-07 - mean_absolute_error: 7.3380e-04 - val_loss: 4.9160e-07 - val_mean_absolute_error: 5.6079e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 304/500\n",
            " Train time0:00:52-25/25 - 0s - loss: 1.2860e-06 - mean_absolute_error: 8.4238e-04 - val_loss: 5.1250e-07 - val_mean_absolute_error: 5.7429e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 305/500\n",
            " Train time0:00:53-25/25 - 0s - loss: 1.2127e-06 - mean_absolute_error: 8.1866e-04 - val_loss: 1.7151e-06 - val_mean_absolute_error: 0.0010 - 158ms/epoch - 6ms/step\n",
            "Epoch 306/500\n",
            " Train time0:00:53-25/25 - 0s - loss: 5.7371e-06 - mean_absolute_error: 0.0018 - val_loss: 5.6693e-06 - val_mean_absolute_error: 0.0021 - 162ms/epoch - 6ms/step\n",
            "Epoch 307/500\n",
            " Train time0:00:53-25/25 - 0s - loss: 1.6580e-06 - mean_absolute_error: 9.1352e-04 - val_loss: 4.0048e-06 - val_mean_absolute_error: 0.0017 - 149ms/epoch - 6ms/step\n",
            "Epoch 308/500\n",
            " Train time0:00:53-25/25 - 0s - loss: 7.1640e-06 - mean_absolute_error: 0.0019 - val_loss: 3.9454e-06 - val_mean_absolute_error: 0.0017 - 149ms/epoch - 6ms/step\n",
            "Epoch 309/500\n",
            " Train time0:00:53-25/25 - 0s - loss: 2.2724e-06 - mean_absolute_error: 0.0011 - val_loss: 9.5585e-07 - val_mean_absolute_error: 8.0844e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 310/500\n",
            " Train time0:00:53-25/25 - 0s - loss: 1.3146e-05 - mean_absolute_error: 0.0026 - val_loss: 1.5978e-06 - val_mean_absolute_error: 0.0010 - 145ms/epoch - 6ms/step\n",
            "Epoch 311/500\n",
            " Train time0:00:54-25/25 - 0s - loss: 1.2188e-06 - mean_absolute_error: 8.2199e-04 - val_loss: 1.7948e-06 - val_mean_absolute_error: 0.0010 - 153ms/epoch - 6ms/step\n",
            "Epoch 312/500\n",
            " Train time0:00:54-25/25 - 0s - loss: 9.7721e-07 - mean_absolute_error: 7.2884e-04 - val_loss: 1.1772e-06 - val_mean_absolute_error: 8.0493e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 313/500\n",
            " Train time0:00:54-25/25 - 0s - loss: 7.5677e-06 - mean_absolute_error: 0.0017 - val_loss: 1.3660e-05 - val_mean_absolute_error: 0.0034 - 172ms/epoch - 7ms/step\n",
            "Epoch 314/500\n",
            " Train time0:00:54-25/25 - 0s - loss: 8.2999e-06 - mean_absolute_error: 0.0022 - val_loss: 1.1364e-06 - val_mean_absolute_error: 8.6907e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 315/500\n",
            " Train time0:00:54**best**-25/25 - 0s - loss: 2.5317e-06 - mean_absolute_error: 0.0011 - val_loss: 3.9837e-07 - val_mean_absolute_error: 4.9835e-04 - 186ms/epoch - 7ms/step\n",
            "Epoch 316/500\n",
            " Train time0:00:54-25/25 - 0s - loss: 2.5708e-06 - mean_absolute_error: 0.0012 - val_loss: 1.1683e-06 - val_mean_absolute_error: 8.5370e-04 - 154ms/epoch - 6ms/step\n",
            "Epoch 317/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 2.2615e-06 - mean_absolute_error: 0.0011 - val_loss: 9.0693e-07 - val_mean_absolute_error: 7.3924e-04 - 154ms/epoch - 6ms/step\n",
            "Epoch 318/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 7.4340e-06 - mean_absolute_error: 0.0018 - val_loss: 3.8301e-05 - val_mean_absolute_error: 0.0053 - 157ms/epoch - 6ms/step\n",
            "Epoch 319/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 4.6536e-06 - mean_absolute_error: 0.0014 - val_loss: 5.1258e-07 - val_mean_absolute_error: 5.4814e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 320/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 8.2038e-07 - mean_absolute_error: 6.8115e-04 - val_loss: 4.1069e-07 - val_mean_absolute_error: 4.9640e-04 - 154ms/epoch - 6ms/step\n",
            "Epoch 321/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 1.0501e-06 - mean_absolute_error: 7.5732e-04 - val_loss: 4.1111e-06 - val_mean_absolute_error: 0.0016 - 157ms/epoch - 6ms/step\n",
            "Epoch 322/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 1.1872e-06 - mean_absolute_error: 7.7109e-04 - val_loss: 4.4196e-07 - val_mean_absolute_error: 5.2789e-04 - 164ms/epoch - 7ms/step\n",
            "Epoch 323/500\n",
            " Train time0:00:55-25/25 - 0s - loss: 7.5184e-07 - mean_absolute_error: 6.3755e-04 - val_loss: 1.9791e-06 - val_mean_absolute_error: 0.0012 - 145ms/epoch - 6ms/step\n",
            "Epoch 324/500\n",
            " Train time0:00:56-25/25 - 0s - loss: 5.4386e-06 - mean_absolute_error: 0.0017 - val_loss: 2.7452e-05 - val_mean_absolute_error: 0.0045 - 149ms/epoch - 6ms/step\n",
            "Epoch 325/500\n",
            " Train time0:00:56-25/25 - 0s - loss: 1.0148e-05 - mean_absolute_error: 0.0023 - val_loss: 2.4366e-06 - val_mean_absolute_error: 0.0012 - 152ms/epoch - 6ms/step\n",
            "Epoch 326/500\n",
            " Train time0:00:56-25/25 - 0s - loss: 6.9975e-06 - mean_absolute_error: 0.0020 - val_loss: 7.4231e-07 - val_mean_absolute_error: 6.8019e-04 - 173ms/epoch - 7ms/step\n",
            "Epoch 327/500\n",
            " Train time0:00:56-25/25 - 0s - loss: 1.7921e-06 - mean_absolute_error: 9.8850e-04 - val_loss: 6.5364e-06 - val_mean_absolute_error: 0.0023 - 148ms/epoch - 6ms/step\n",
            "Epoch 328/500\n",
            " Train time0:00:56-25/25 - 0s - loss: 3.6478e-06 - mean_absolute_error: 0.0014 - val_loss: 2.2104e-06 - val_mean_absolute_error: 0.0012 - 145ms/epoch - 6ms/step\n",
            "Epoch 329/500\n",
            " Train time0:00:56-25/25 - 0s - loss: 2.6587e-06 - mean_absolute_error: 0.0012 - val_loss: 2.9543e-05 - val_mean_absolute_error: 0.0046 - 146ms/epoch - 6ms/step\n",
            "Epoch 330/500\n",
            " Train time0:00:57-25/25 - 0s - loss: 3.9078e-06 - mean_absolute_error: 0.0014 - val_loss: 4.5938e-07 - val_mean_absolute_error: 5.2564e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 331/500\n",
            " Train time0:00:57-25/25 - 0s - loss: 1.5481e-06 - mean_absolute_error: 9.4216e-04 - val_loss: 5.5183e-07 - val_mean_absolute_error: 5.6450e-04 - 163ms/epoch - 7ms/step\n",
            "Epoch 332/500\n",
            " Train time0:00:57-25/25 - 0s - loss: 1.1643e-06 - mean_absolute_error: 7.5785e-04 - val_loss: 2.1164e-06 - val_mean_absolute_error: 0.0013 - 164ms/epoch - 7ms/step\n",
            "Epoch 333/500\n",
            " Train time0:00:57-25/25 - 0s - loss: 1.6696e-05 - mean_absolute_error: 0.0031 - val_loss: 1.8388e-05 - val_mean_absolute_error: 0.0037 - 149ms/epoch - 6ms/step\n",
            "Epoch 334/500\n",
            " Train time0:00:57-25/25 - 0s - loss: 6.5515e-06 - mean_absolute_error: 0.0019 - val_loss: 1.1509e-06 - val_mean_absolute_error: 8.0201e-04 - 151ms/epoch - 6ms/step\n",
            "Epoch 335/500\n",
            " Train time0:00:57-25/25 - 0s - loss: 1.4011e-06 - mean_absolute_error: 8.6984e-04 - val_loss: 1.1165e-06 - val_mean_absolute_error: 8.8147e-04 - 167ms/epoch - 7ms/step\n",
            "Epoch 336/500\n",
            " Train time0:00:58-25/25 - 0s - loss: 1.4603e-06 - mean_absolute_error: 8.7240e-04 - val_loss: 1.3480e-06 - val_mean_absolute_error: 9.2769e-04 - 164ms/epoch - 7ms/step\n",
            "Epoch 337/500\n",
            " Train time0:00:58-25/25 - 0s - loss: 4.7505e-06 - mean_absolute_error: 0.0016 - val_loss: 3.3576e-06 - val_mean_absolute_error: 0.0014 - 161ms/epoch - 6ms/step\n",
            "Epoch 338/500\n",
            " Train time0:00:58-25/25 - 0s - loss: 1.3529e-06 - mean_absolute_error: 8.4385e-04 - val_loss: 6.1766e-06 - val_mean_absolute_error: 0.0021 - 157ms/epoch - 6ms/step\n",
            "Epoch 339/500\n",
            " Train time0:00:58-25/25 - 0s - loss: 4.2132e-06 - mean_absolute_error: 0.0016 - val_loss: 2.4996e-06 - val_mean_absolute_error: 0.0012 - 161ms/epoch - 6ms/step\n",
            "Epoch 340/500\n",
            " Train time0:00:58-25/25 - 0s - loss: 2.9701e-06 - mean_absolute_error: 0.0013 - val_loss: 1.0757e-05 - val_mean_absolute_error: 0.0027 - 157ms/epoch - 6ms/step\n",
            "Epoch 341/500\n",
            " Train time0:00:58-25/25 - 0s - loss: 6.7923e-06 - mean_absolute_error: 0.0021 - val_loss: 4.8301e-06 - val_mean_absolute_error: 0.0019 - 151ms/epoch - 6ms/step\n",
            "Epoch 342/500\n",
            " Train time0:00:59**best**-25/25 - 0s - loss: 3.3168e-06 - mean_absolute_error: 0.0014 - val_loss: 3.6846e-07 - val_mean_absolute_error: 4.6731e-04 - 190ms/epoch - 8ms/step\n",
            "Epoch 343/500\n",
            " Train time0:00:59-25/25 - 0s - loss: 2.9962e-06 - mean_absolute_error: 0.0013 - val_loss: 3.8158e-07 - val_mean_absolute_error: 4.7606e-04 - 181ms/epoch - 7ms/step\n",
            "Epoch 344/500\n",
            " Train time0:00:59-25/25 - 0s - loss: 1.1484e-05 - mean_absolute_error: 0.0026 - val_loss: 9.6889e-06 - val_mean_absolute_error: 0.0025 - 167ms/epoch - 7ms/step\n",
            "Epoch 345/500\n",
            " Train time0:00:59-25/25 - 0s - loss: 9.5293e-06 - mean_absolute_error: 0.0023 - val_loss: 1.6701e-06 - val_mean_absolute_error: 0.0012 - 148ms/epoch - 6ms/step\n",
            "Epoch 346/500\n",
            " Train time0:00:59-25/25 - 0s - loss: 2.6310e-06 - mean_absolute_error: 0.0012 - val_loss: 7.5387e-06 - val_mean_absolute_error: 0.0025 - 146ms/epoch - 6ms/step\n",
            "Epoch 347/500\n",
            " Train time0:00:59-25/25 - 0s - loss: 3.0446e-06 - mean_absolute_error: 0.0013 - val_loss: 6.1008e-07 - val_mean_absolute_error: 6.0389e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 348/500\n",
            " Train time0:01:00-25/25 - 0s - loss: 2.6431e-06 - mean_absolute_error: 0.0012 - val_loss: 6.1430e-06 - val_mean_absolute_error: 0.0021 - 147ms/epoch - 6ms/step\n",
            "Epoch 349/500\n",
            " Train time0:01:00-25/25 - 0s - loss: 1.3304e-05 - mean_absolute_error: 0.0028 - val_loss: 8.9174e-06 - val_mean_absolute_error: 0.0028 - 147ms/epoch - 6ms/step\n",
            "Epoch 350/500\n",
            " Train time0:01:00-25/25 - 0s - loss: 4.5846e-06 - mean_absolute_error: 0.0015 - val_loss: 7.1486e-07 - val_mean_absolute_error: 6.1782e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 351/500\n",
            " Train time0:01:00**best**-25/25 - 0s - loss: 1.0991e-06 - mean_absolute_error: 7.5948e-04 - val_loss: 3.6809e-07 - val_mean_absolute_error: 4.6625e-04 - 207ms/epoch - 8ms/step\n",
            "Epoch 352/500\n",
            " Train time0:01:00-25/25 - 0s - loss: 1.6039e-06 - mean_absolute_error: 9.0354e-04 - val_loss: 1.0737e-05 - val_mean_absolute_error: 0.0028 - 164ms/epoch - 7ms/step\n",
            "Epoch 353/500\n",
            " Train time0:01:00-25/25 - 0s - loss: 7.8141e-06 - mean_absolute_error: 0.0021 - val_loss: 4.0595e-07 - val_mean_absolute_error: 5.0700e-04 - 169ms/epoch - 7ms/step\n",
            "Epoch 354/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 1.2522e-06 - mean_absolute_error: 8.0502e-04 - val_loss: 1.6811e-06 - val_mean_absolute_error: 9.9099e-04 - 155ms/epoch - 6ms/step\n",
            "Epoch 355/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 4.7441e-06 - mean_absolute_error: 0.0016 - val_loss: 1.4291e-05 - val_mean_absolute_error: 0.0033 - 155ms/epoch - 6ms/step\n",
            "Epoch 356/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 3.4235e-06 - mean_absolute_error: 0.0013 - val_loss: 5.3997e-07 - val_mean_absolute_error: 5.7937e-04 - 159ms/epoch - 6ms/step\n",
            "Epoch 357/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 1.7189e-06 - mean_absolute_error: 9.7352e-04 - val_loss: 1.2380e-06 - val_mean_absolute_error: 8.8124e-04 - 163ms/epoch - 7ms/step\n",
            "Epoch 358/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 3.4197e-06 - mean_absolute_error: 0.0014 - val_loss: 2.3261e-06 - val_mean_absolute_error: 0.0012 - 153ms/epoch - 6ms/step\n",
            "Epoch 359/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 2.1618e-06 - mean_absolute_error: 0.0011 - val_loss: 4.0221e-07 - val_mean_absolute_error: 4.9428e-04 - 156ms/epoch - 6ms/step\n",
            "Epoch 360/500\n",
            " Train time0:01:01-25/25 - 0s - loss: 1.4809e-06 - mean_absolute_error: 9.0619e-04 - val_loss: 1.0425e-06 - val_mean_absolute_error: 7.6752e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 361/500\n",
            " Train time0:01:02-25/25 - 0s - loss: 9.9521e-07 - mean_absolute_error: 7.3465e-04 - val_loss: 4.5020e-07 - val_mean_absolute_error: 5.2673e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 362/500\n",
            " Train time0:01:02**best**-25/25 - 0s - loss: 3.4820e-06 - mean_absolute_error: 0.0013 - val_loss: 3.5561e-07 - val_mean_absolute_error: 4.5860e-04 - 190ms/epoch - 8ms/step\n",
            "Epoch 363/500\n",
            " Train time0:01:02-25/25 - 0s - loss: 1.5649e-06 - mean_absolute_error: 8.8856e-04 - val_loss: 7.0400e-06 - val_mean_absolute_error: 0.0022 - 154ms/epoch - 6ms/step\n",
            "Epoch 364/500\n",
            " Train time0:01:02-25/25 - 0s - loss: 3.0039e-06 - mean_absolute_error: 0.0013 - val_loss: 4.7657e-06 - val_mean_absolute_error: 0.0018 - 153ms/epoch - 6ms/step\n",
            "Epoch 365/500\n",
            " Train time0:01:02-25/25 - 0s - loss: 5.2126e-06 - mean_absolute_error: 0.0016 - val_loss: 3.6527e-06 - val_mean_absolute_error: 0.0014 - 145ms/epoch - 6ms/step\n",
            "Epoch 366/500\n",
            " Train time0:01:02-25/25 - 0s - loss: 1.0280e-05 - mean_absolute_error: 0.0025 - val_loss: 1.7552e-06 - val_mean_absolute_error: 0.0010 - 147ms/epoch - 6ms/step\n",
            "Epoch 367/500\n",
            " Train time0:01:03-25/25 - 0s - loss: 2.4111e-06 - mean_absolute_error: 0.0012 - val_loss: 5.8572e-07 - val_mean_absolute_error: 5.6275e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 368/500\n",
            " Train time0:01:03-25/25 - 0s - loss: 8.4195e-07 - mean_absolute_error: 6.9982e-04 - val_loss: 9.2867e-07 - val_mean_absolute_error: 7.3472e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 369/500\n",
            " Train time0:01:03-25/25 - 0s - loss: 3.0507e-06 - mean_absolute_error: 0.0012 - val_loss: 1.8247e-06 - val_mean_absolute_error: 0.0011 - 146ms/epoch - 6ms/step\n",
            "Epoch 370/500\n",
            " Train time0:01:03-25/25 - 0s - loss: 2.5805e-06 - mean_absolute_error: 0.0013 - val_loss: 1.9927e-05 - val_mean_absolute_error: 0.0041 - 166ms/epoch - 7ms/step\n",
            "Epoch 371/500\n",
            " Train time0:01:03-25/25 - 0s - loss: 3.2271e-05 - mean_absolute_error: 0.0039 - val_loss: 5.3219e-06 - val_mean_absolute_error: 0.0020 - 149ms/epoch - 6ms/step\n",
            "Epoch 372/500\n",
            " Train time0:01:03-25/25 - 0s - loss: 3.8327e-05 - mean_absolute_error: 0.0044 - val_loss: 1.1995e-05 - val_mean_absolute_error: 0.0031 - 146ms/epoch - 6ms/step\n",
            "Epoch 373/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 6.9610e-06 - mean_absolute_error: 0.0020 - val_loss: 9.8394e-06 - val_mean_absolute_error: 0.0028 - 149ms/epoch - 6ms/step\n",
            "Epoch 374/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 6.0388e-06 - mean_absolute_error: 0.0019 - val_loss: 3.0902e-06 - val_mean_absolute_error: 0.0015 - 146ms/epoch - 6ms/step\n",
            "Epoch 375/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 1.3328e-06 - mean_absolute_error: 8.2475e-04 - val_loss: 6.4792e-07 - val_mean_absolute_error: 5.7073e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 376/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 8.0092e-07 - mean_absolute_error: 6.5634e-04 - val_loss: 4.3576e-07 - val_mean_absolute_error: 5.2033e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 377/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 7.5577e-07 - mean_absolute_error: 6.2894e-04 - val_loss: 6.3480e-07 - val_mean_absolute_error: 5.7052e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 378/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 9.5862e-07 - mean_absolute_error: 7.3497e-04 - val_loss: 4.0727e-07 - val_mean_absolute_error: 4.6641e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 379/500\n",
            " Train time0:01:04-25/25 - 0s - loss: 1.1923e-06 - mean_absolute_error: 7.9737e-04 - val_loss: 9.7095e-07 - val_mean_absolute_error: 7.4389e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 380/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 2.8854e-06 - mean_absolute_error: 0.0012 - val_loss: 3.1071e-06 - val_mean_absolute_error: 0.0013 - 146ms/epoch - 6ms/step\n",
            "Epoch 381/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 1.6361e-06 - mean_absolute_error: 9.1294e-04 - val_loss: 9.1393e-07 - val_mean_absolute_error: 7.1575e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 382/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 7.8577e-07 - mean_absolute_error: 6.5926e-04 - val_loss: 4.6667e-07 - val_mean_absolute_error: 5.0009e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 383/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 7.4358e-07 - mean_absolute_error: 6.3087e-04 - val_loss: 9.0642e-07 - val_mean_absolute_error: 7.5664e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 384/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 9.4353e-07 - mean_absolute_error: 6.9751e-04 - val_loss: 2.6768e-06 - val_mean_absolute_error: 0.0012 - 156ms/epoch - 6ms/step\n",
            "Epoch 385/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 2.6421e-06 - mean_absolute_error: 0.0012 - val_loss: 4.9982e-06 - val_mean_absolute_error: 0.0019 - 150ms/epoch - 6ms/step\n",
            "Epoch 386/500\n",
            " Train time0:01:05-25/25 - 0s - loss: 2.6937e-06 - mean_absolute_error: 0.0012 - val_loss: 1.9562e-06 - val_mean_absolute_error: 0.0011 - 150ms/epoch - 6ms/step\n",
            "Epoch 387/500\n",
            " Train time0:01:06-25/25 - 0s - loss: 3.3155e-06 - mean_absolute_error: 0.0013 - val_loss: 5.0109e-06 - val_mean_absolute_error: 0.0019 - 149ms/epoch - 6ms/step\n",
            "Epoch 388/500\n",
            " Train time0:01:06-25/25 - 0s - loss: 9.9971e-06 - mean_absolute_error: 0.0024 - val_loss: 4.6768e-07 - val_mean_absolute_error: 4.9907e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 389/500\n",
            " Train time0:01:06-25/25 - 0s - loss: 4.2772e-06 - mean_absolute_error: 0.0015 - val_loss: 1.6639e-06 - val_mean_absolute_error: 0.0011 - 148ms/epoch - 6ms/step\n",
            "Epoch 390/500\n",
            " Train time0:01:06-25/25 - 0s - loss: 1.3904e-06 - mean_absolute_error: 8.6795e-04 - val_loss: 6.9448e-07 - val_mean_absolute_error: 6.1582e-04 - 165ms/epoch - 7ms/step\n",
            "Epoch 391/500\n",
            " Train time0:01:06-25/25 - 0s - loss: 1.1477e-06 - mean_absolute_error: 8.0161e-04 - val_loss: 1.3538e-06 - val_mean_absolute_error: 8.9570e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 392/500\n",
            " Train time0:01:06-25/25 - 0s - loss: 4.6698e-06 - mean_absolute_error: 0.0016 - val_loss: 3.5894e-06 - val_mean_absolute_error: 0.0016 - 149ms/epoch - 6ms/step\n",
            "Epoch 393/500\n",
            " Train time0:01:07-25/25 - 0s - loss: 1.3531e-06 - mean_absolute_error: 8.5424e-04 - val_loss: 4.3605e-07 - val_mean_absolute_error: 5.1430e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 394/500\n",
            " Train time0:01:07-25/25 - 0s - loss: 1.5038e-06 - mean_absolute_error: 8.5247e-04 - val_loss: 4.4969e-07 - val_mean_absolute_error: 5.4556e-04 - 157ms/epoch - 6ms/step\n",
            "Epoch 395/500\n",
            " Train time0:01:07-25/25 - 0s - loss: 7.6539e-07 - mean_absolute_error: 6.2583e-04 - val_loss: 8.4615e-07 - val_mean_absolute_error: 7.8612e-04 - 155ms/epoch - 6ms/step\n",
            "Epoch 396/500\n",
            " Train time0:01:07-25/25 - 0s - loss: 1.7008e-06 - mean_absolute_error: 8.8111e-04 - val_loss: 5.6283e-07 - val_mean_absolute_error: 5.8493e-04 - 157ms/epoch - 6ms/step\n",
            "Epoch 397/500\n",
            " Train time0:01:07-25/25 - 0s - loss: 2.3018e-06 - mean_absolute_error: 0.0010 - val_loss: 9.3512e-07 - val_mean_absolute_error: 7.6022e-04 - 160ms/epoch - 6ms/step\n",
            "Epoch 398/500\n",
            " Train time0:01:07-25/25 - 0s - loss: 4.3038e-06 - mean_absolute_error: 0.0015 - val_loss: 4.4140e-06 - val_mean_absolute_error: 0.0016 - 156ms/epoch - 6ms/step\n",
            "Epoch 399/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 1.2219e-05 - mean_absolute_error: 0.0026 - val_loss: 1.0304e-05 - val_mean_absolute_error: 0.0030 - 155ms/epoch - 6ms/step\n",
            "Epoch 400/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 1.0886e-05 - mean_absolute_error: 0.0025 - val_loss: 1.0799e-06 - val_mean_absolute_error: 7.3375e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 401/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 2.8930e-06 - mean_absolute_error: 0.0014 - val_loss: 1.2216e-06 - val_mean_absolute_error: 9.0087e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 402/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 1.8314e-06 - mean_absolute_error: 0.0010 - val_loss: 6.1953e-07 - val_mean_absolute_error: 6.2917e-04 - 162ms/epoch - 6ms/step\n",
            "Epoch 403/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 9.1594e-06 - mean_absolute_error: 0.0022 - val_loss: 3.3701e-06 - val_mean_absolute_error: 0.0016 - 142ms/epoch - 6ms/step\n",
            "Epoch 404/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 1.0850e-05 - mean_absolute_error: 0.0025 - val_loss: 8.2805e-07 - val_mean_absolute_error: 6.7805e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 405/500\n",
            " Train time0:01:08-25/25 - 0s - loss: 3.4376e-06 - mean_absolute_error: 0.0013 - val_loss: 1.0181e-06 - val_mean_absolute_error: 8.5126e-04 - 163ms/epoch - 7ms/step\n",
            "Epoch 406/500\n",
            " Train time0:01:09-25/25 - 0s - loss: 9.3191e-07 - mean_absolute_error: 7.1595e-04 - val_loss: 3.9533e-07 - val_mean_absolute_error: 4.7753e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 407/500\n",
            " Train time0:01:09-25/25 - 0s - loss: 1.0734e-06 - mean_absolute_error: 7.7258e-04 - val_loss: 2.8834e-06 - val_mean_absolute_error: 0.0014 - 146ms/epoch - 6ms/step\n",
            "Epoch 408/500\n",
            " Train time0:01:09-25/25 - 0s - loss: 3.0449e-06 - mean_absolute_error: 0.0013 - val_loss: 6.3799e-06 - val_mean_absolute_error: 0.0020 - 150ms/epoch - 6ms/step\n",
            "Epoch 409/500\n",
            " Train time0:01:09-25/25 - 0s - loss: 1.3698e-06 - mean_absolute_error: 8.1984e-04 - val_loss: 3.9045e-07 - val_mean_absolute_error: 4.7367e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 410/500\n",
            " Train time0:01:09-25/25 - 0s - loss: 2.3040e-06 - mean_absolute_error: 0.0011 - val_loss: 4.1729e-06 - val_mean_absolute_error: 0.0017 - 173ms/epoch - 7ms/step\n",
            "Epoch 411/500\n",
            " Train time0:01:09-25/25 - 0s - loss: 1.3046e-06 - mean_absolute_error: 8.3999e-04 - val_loss: 1.8440e-06 - val_mean_absolute_error: 0.0011 - 162ms/epoch - 6ms/step\n",
            "Epoch 412/500\n",
            " Train time0:01:10-25/25 - 0s - loss: 8.7255e-07 - mean_absolute_error: 7.0600e-04 - val_loss: 2.8424e-06 - val_mean_absolute_error: 0.0014 - 151ms/epoch - 6ms/step\n",
            "Epoch 413/500\n",
            " Train time0:01:10-25/25 - 0s - loss: 7.0162e-07 - mean_absolute_error: 6.1166e-04 - val_loss: 7.3848e-07 - val_mean_absolute_error: 6.3751e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 414/500\n",
            " Train time0:01:10**best**-25/25 - 0s - loss: 9.0084e-07 - mean_absolute_error: 7.1196e-04 - val_loss: 3.3981e-07 - val_mean_absolute_error: 4.5617e-04 - 195ms/epoch - 8ms/step\n",
            "Epoch 415/500\n",
            " Train time0:01:10**best**-25/25 - 0s - loss: 6.5547e-07 - mean_absolute_error: 5.9603e-04 - val_loss: 3.3458e-07 - val_mean_absolute_error: 4.5663e-04 - 196ms/epoch - 8ms/step\n",
            "Epoch 416/500\n",
            " Train time0:01:10-25/25 - 0s - loss: 2.1042e-06 - mean_absolute_error: 9.7545e-04 - val_loss: 2.0010e-05 - val_mean_absolute_error: 0.0039 - 150ms/epoch - 6ms/step\n",
            "Epoch 417/500\n",
            " Train time0:01:10-25/25 - 0s - loss: 7.1624e-06 - mean_absolute_error: 0.0020 - val_loss: 9.6980e-06 - val_mean_absolute_error: 0.0024 - 150ms/epoch - 6ms/step\n",
            "Epoch 418/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 2.9695e-06 - mean_absolute_error: 0.0013 - val_loss: 2.4803e-06 - val_mean_absolute_error: 0.0014 - 147ms/epoch - 6ms/step\n",
            "Epoch 419/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 1.5193e-06 - mean_absolute_error: 8.9939e-04 - val_loss: 7.8829e-07 - val_mean_absolute_error: 6.8702e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 420/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 1.2770e-06 - mean_absolute_error: 8.6247e-04 - val_loss: 7.8291e-07 - val_mean_absolute_error: 7.0070e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 421/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 1.8099e-06 - mean_absolute_error: 9.7876e-04 - val_loss: 3.6793e-06 - val_mean_absolute_error: 0.0016 - 147ms/epoch - 6ms/step\n",
            "Epoch 422/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 4.0829e-06 - mean_absolute_error: 0.0016 - val_loss: 1.3232e-06 - val_mean_absolute_error: 8.7534e-04 - 151ms/epoch - 6ms/step\n",
            "Epoch 423/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 5.2980e-06 - mean_absolute_error: 0.0018 - val_loss: 3.0015e-06 - val_mean_absolute_error: 0.0016 - 157ms/epoch - 6ms/step\n",
            "Epoch 424/500\n",
            " Train time0:01:11-25/25 - 0s - loss: 1.2893e-06 - mean_absolute_error: 8.4989e-04 - val_loss: 4.6361e-07 - val_mean_absolute_error: 4.9112e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 425/500\n",
            " Train time0:01:12-25/25 - 0s - loss: 1.4660e-06 - mean_absolute_error: 8.0516e-04 - val_loss: 8.2048e-06 - val_mean_absolute_error: 0.0025 - 153ms/epoch - 6ms/step\n",
            "Epoch 426/500\n",
            " Train time0:01:12-25/25 - 0s - loss: 1.9658e-06 - mean_absolute_error: 9.8112e-04 - val_loss: 4.0554e-07 - val_mean_absolute_error: 5.2724e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 427/500\n",
            " Train time0:01:12-25/25 - 0s - loss: 2.9401e-06 - mean_absolute_error: 0.0012 - val_loss: 2.2483e-06 - val_mean_absolute_error: 0.0011 - 148ms/epoch - 6ms/step\n",
            "Epoch 428/500\n",
            " Train time0:01:12-25/25 - 0s - loss: 7.6444e-06 - mean_absolute_error: 0.0020 - val_loss: 8.3487e-07 - val_mean_absolute_error: 6.6499e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 429/500\n",
            " Train time0:01:12-25/25 - 0s - loss: 1.6146e-06 - mean_absolute_error: 9.4197e-04 - val_loss: 5.9150e-06 - val_mean_absolute_error: 0.0020 - 165ms/epoch - 7ms/step\n",
            "Epoch 430/500\n",
            " Train time0:01:12-25/25 - 0s - loss: 3.1449e-06 - mean_absolute_error: 0.0014 - val_loss: 5.0735e-07 - val_mean_absolute_error: 5.5333e-04 - 150ms/epoch - 6ms/step\n",
            "Epoch 431/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 6.9424e-06 - mean_absolute_error: 0.0020 - val_loss: 1.1349e-05 - val_mean_absolute_error: 0.0028 - 151ms/epoch - 6ms/step\n",
            "Epoch 432/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 2.3280e-06 - mean_absolute_error: 0.0011 - val_loss: 7.8088e-07 - val_mean_absolute_error: 6.7959e-04 - 149ms/epoch - 6ms/step\n",
            "Epoch 433/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 1.3010e-06 - mean_absolute_error: 8.2432e-04 - val_loss: 2.1569e-06 - val_mean_absolute_error: 0.0011 - 148ms/epoch - 6ms/step\n",
            "Epoch 434/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 1.9470e-06 - mean_absolute_error: 0.0010 - val_loss: 3.1487e-06 - val_mean_absolute_error: 0.0015 - 150ms/epoch - 6ms/step\n",
            "Epoch 435/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 3.2539e-06 - mean_absolute_error: 0.0014 - val_loss: 1.3549e-05 - val_mean_absolute_error: 0.0033 - 149ms/epoch - 6ms/step\n",
            "Epoch 436/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 1.6620e-06 - mean_absolute_error: 8.9443e-04 - val_loss: 6.1415e-07 - val_mean_absolute_error: 5.6666e-04 - 152ms/epoch - 6ms/step\n",
            "Epoch 437/500\n",
            " Train time0:01:13-25/25 - 0s - loss: 1.9987e-06 - mean_absolute_error: 9.8225e-04 - val_loss: 5.1172e-07 - val_mean_absolute_error: 5.6679e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 438/500\n",
            " Train time0:01:14-25/25 - 0s - loss: 6.6535e-06 - mean_absolute_error: 0.0018 - val_loss: 4.8774e-07 - val_mean_absolute_error: 5.0905e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 439/500\n",
            " Train time0:01:14-25/25 - 0s - loss: 1.0703e-06 - mean_absolute_error: 7.3186e-04 - val_loss: 1.9851e-06 - val_mean_absolute_error: 0.0012 - 154ms/epoch - 6ms/step\n",
            "Epoch 440/500\n",
            " Train time0:01:14-25/25 - 0s - loss: 2.5439e-06 - mean_absolute_error: 0.0012 - val_loss: 7.1997e-07 - val_mean_absolute_error: 6.4952e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 441/500\n",
            " Train time0:01:14-25/25 - 0s - loss: 1.2062e-06 - mean_absolute_error: 7.9260e-04 - val_loss: 3.5709e-07 - val_mean_absolute_error: 4.6129e-04 - 148ms/epoch - 6ms/step\n",
            "Epoch 442/500\n",
            " Train time0:01:14-25/25 - 0s - loss: 8.2713e-07 - mean_absolute_error: 6.7307e-04 - val_loss: 3.1415e-06 - val_mean_absolute_error: 0.0014 - 149ms/epoch - 6ms/step\n",
            "Epoch 443/500\n",
            " Train time0:01:14-25/25 - 0s - loss: 2.6084e-06 - mean_absolute_error: 0.0012 - val_loss: 2.5519e-06 - val_mean_absolute_error: 0.0012 - 162ms/epoch - 6ms/step\n",
            "Epoch 444/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 3.7934e-05 - mean_absolute_error: 0.0044 - val_loss: 2.3166e-05 - val_mean_absolute_error: 0.0035 - 145ms/epoch - 6ms/step\n",
            "Epoch 445/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 2.0959e-05 - mean_absolute_error: 0.0034 - val_loss: 7.6180e-06 - val_mean_absolute_error: 0.0025 - 147ms/epoch - 6ms/step\n",
            "Epoch 446/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 3.1768e-06 - mean_absolute_error: 0.0013 - val_loss: 9.4892e-07 - val_mean_absolute_error: 8.1742e-04 - 153ms/epoch - 6ms/step\n",
            "Epoch 447/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 4.7349e-07 - mean_absolute_error: 5.0171e-04 - val_loss: 5.3810e-07 - val_mean_absolute_error: 5.3352e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 448/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 1.7613e-06 - mean_absolute_error: 9.8333e-04 - val_loss: 3.6227e-07 - val_mean_absolute_error: 4.7118e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 449/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 1.3441e-06 - mean_absolute_error: 8.6574e-04 - val_loss: 1.8131e-06 - val_mean_absolute_error: 0.0012 - 165ms/epoch - 7ms/step\n",
            "Epoch 450/500\n",
            " Train time0:01:15-25/25 - 0s - loss: 3.8389e-06 - mean_absolute_error: 0.0015 - val_loss: 1.0828e-05 - val_mean_absolute_error: 0.0031 - 151ms/epoch - 6ms/step\n",
            "Epoch 451/500\n",
            " Train time0:01:16-25/25 - 0s - loss: 5.5286e-06 - mean_absolute_error: 0.0018 - val_loss: 1.4444e-06 - val_mean_absolute_error: 0.0010 - 148ms/epoch - 6ms/step\n",
            "Epoch 452/500\n",
            " Train time0:01:16-25/25 - 0s - loss: 5.3316e-07 - mean_absolute_error: 5.4240e-04 - val_loss: 3.5773e-07 - val_mean_absolute_error: 4.5993e-04 - 151ms/epoch - 6ms/step\n",
            "Epoch 453/500\n",
            " Train time0:01:16-25/25 - 0s - loss: 5.6192e-07 - mean_absolute_error: 5.4780e-04 - val_loss: 5.2838e-07 - val_mean_absolute_error: 5.9185e-04 - 147ms/epoch - 6ms/step\n",
            "Epoch 454/500\n",
            " Train time0:01:16-25/25 - 0s - loss: 4.9944e-07 - mean_absolute_error: 5.2514e-04 - val_loss: 1.0858e-06 - val_mean_absolute_error: 7.4790e-04 - 155ms/epoch - 6ms/step\n",
            "Epoch 455/500\n",
            " Train time0:01:16-25/25 - 0s - loss: 1.1722e-06 - mean_absolute_error: 7.8923e-04 - val_loss: 1.1541e-06 - val_mean_absolute_error: 8.2838e-04 - 154ms/epoch - 6ms/step\n",
            "Epoch 456/500\n",
            " Train time0:01:16**best**-25/25 - 0s - loss: 9.3596e-07 - mean_absolute_error: 7.1421e-04 - val_loss: 2.7870e-07 - val_mean_absolute_error: 3.9847e-04 - 183ms/epoch - 7ms/step\n",
            "Epoch 457/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 1.5966e-06 - mean_absolute_error: 9.3637e-04 - val_loss: 4.3649e-06 - val_mean_absolute_error: 0.0018 - 143ms/epoch - 6ms/step\n",
            "Epoch 458/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 2.1391e-06 - mean_absolute_error: 0.0011 - val_loss: 3.5744e-06 - val_mean_absolute_error: 0.0014 - 142ms/epoch - 6ms/step\n",
            "Epoch 459/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 1.5764e-06 - mean_absolute_error: 9.1793e-04 - val_loss: 4.8834e-07 - val_mean_absolute_error: 5.5253e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 460/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 8.8279e-07 - mean_absolute_error: 7.1353e-04 - val_loss: 3.2987e-07 - val_mean_absolute_error: 4.3722e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 461/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 5.3734e-07 - mean_absolute_error: 5.5075e-04 - val_loss: 1.5560e-06 - val_mean_absolute_error: 0.0011 - 145ms/epoch - 6ms/step\n",
            "Epoch 462/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 8.0811e-07 - mean_absolute_error: 6.7842e-04 - val_loss: 6.1014e-07 - val_mean_absolute_error: 5.8016e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 463/500\n",
            " Train time0:01:17-25/25 - 0s - loss: 1.4880e-06 - mean_absolute_error: 8.6149e-04 - val_loss: 4.4850e-06 - val_mean_absolute_error: 0.0018 - 141ms/epoch - 6ms/step\n",
            "Epoch 464/500\n",
            " Train time0:01:18-25/25 - 0s - loss: 4.2781e-06 - mean_absolute_error: 0.0016 - val_loss: 1.0921e-06 - val_mean_absolute_error: 8.2404e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 465/500\n",
            " Train time0:01:18-25/25 - 0s - loss: 2.3469e-06 - mean_absolute_error: 0.0011 - val_loss: 1.0185e-06 - val_mean_absolute_error: 8.2609e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 466/500\n",
            " Train time0:01:18-25/25 - 0s - loss: 1.3714e-06 - mean_absolute_error: 8.7650e-04 - val_loss: 1.3194e-06 - val_mean_absolute_error: 0.0010 - 142ms/epoch - 6ms/step\n",
            "Epoch 467/500\n",
            " Train time0:01:18-25/25 - 0s - loss: 1.6248e-05 - mean_absolute_error: 0.0030 - val_loss: 4.4737e-05 - val_mean_absolute_error: 0.0055 - 147ms/epoch - 6ms/step\n",
            "Epoch 468/500\n",
            " Train time0:01:18-25/25 - 0s - loss: 1.1977e-05 - mean_absolute_error: 0.0025 - val_loss: 1.6468e-06 - val_mean_absolute_error: 0.0010 - 143ms/epoch - 6ms/step\n",
            "Epoch 469/500\n",
            " Train time0:01:18-25/25 - 0s - loss: 4.0406e-06 - mean_absolute_error: 0.0016 - val_loss: 1.9076e-06 - val_mean_absolute_error: 0.0010 - 157ms/epoch - 6ms/step\n",
            "Epoch 470/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 2.1689e-05 - mean_absolute_error: 0.0035 - val_loss: 1.8535e-05 - val_mean_absolute_error: 0.0041 - 147ms/epoch - 6ms/step\n",
            "Epoch 471/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 1.1909e-05 - mean_absolute_error: 0.0027 - val_loss: 5.0177e-06 - val_mean_absolute_error: 0.0017 - 154ms/epoch - 6ms/step\n",
            "Epoch 472/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 1.8117e-06 - mean_absolute_error: 8.8376e-04 - val_loss: 6.7024e-07 - val_mean_absolute_error: 5.7691e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 473/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 9.5460e-07 - mean_absolute_error: 6.9290e-04 - val_loss: 1.4738e-06 - val_mean_absolute_error: 0.0011 - 144ms/epoch - 6ms/step\n",
            "Epoch 474/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 2.0199e-06 - mean_absolute_error: 0.0011 - val_loss: 3.9447e-07 - val_mean_absolute_error: 4.5163e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 475/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 3.6817e-06 - mean_absolute_error: 0.0015 - val_loss: 6.5535e-06 - val_mean_absolute_error: 0.0020 - 145ms/epoch - 6ms/step\n",
            "Epoch 476/500\n",
            " Train time0:01:19-25/25 - 0s - loss: 7.6419e-06 - mean_absolute_error: 0.0021 - val_loss: 1.2680e-05 - val_mean_absolute_error: 0.0032 - 142ms/epoch - 6ms/step\n",
            "Epoch 477/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 6.7999e-06 - mean_absolute_error: 0.0021 - val_loss: 4.2745e-06 - val_mean_absolute_error: 0.0019 - 142ms/epoch - 6ms/step\n",
            "Epoch 478/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 7.3384e-06 - mean_absolute_error: 0.0021 - val_loss: 3.4347e-06 - val_mean_absolute_error: 0.0014 - 140ms/epoch - 6ms/step\n",
            "Epoch 479/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 1.1348e-05 - mean_absolute_error: 0.0024 - val_loss: 3.0155e-06 - val_mean_absolute_error: 0.0014 - 144ms/epoch - 6ms/step\n",
            "Epoch 480/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 6.4468e-06 - mean_absolute_error: 0.0019 - val_loss: 1.0658e-06 - val_mean_absolute_error: 8.3270e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 481/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 1.1255e-06 - mean_absolute_error: 7.9573e-04 - val_loss: 4.6021e-07 - val_mean_absolute_error: 5.2876e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 482/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 5.3380e-07 - mean_absolute_error: 5.3989e-04 - val_loss: 1.1303e-06 - val_mean_absolute_error: 7.7085e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 483/500\n",
            " Train time0:01:20-25/25 - 0s - loss: 5.9561e-07 - mean_absolute_error: 5.6510e-04 - val_loss: 3.6940e-07 - val_mean_absolute_error: 4.7764e-04 - 151ms/epoch - 6ms/step\n",
            "Epoch 484/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 5.6958e-07 - mean_absolute_error: 5.6531e-04 - val_loss: 4.8055e-07 - val_mean_absolute_error: 5.7022e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 485/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 8.2946e-07 - mean_absolute_error: 6.6230e-04 - val_loss: 2.6353e-06 - val_mean_absolute_error: 0.0014 - 143ms/epoch - 6ms/step\n",
            "Epoch 486/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 1.4070e-06 - mean_absolute_error: 8.6855e-04 - val_loss: 3.9155e-07 - val_mean_absolute_error: 4.5866e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 487/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 6.3606e-07 - mean_absolute_error: 5.8341e-04 - val_loss: 4.2426e-07 - val_mean_absolute_error: 5.0585e-04 - 144ms/epoch - 6ms/step\n",
            "Epoch 488/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 2.1176e-06 - mean_absolute_error: 0.0011 - val_loss: 2.1855e-06 - val_mean_absolute_error: 0.0010 - 146ms/epoch - 6ms/step\n",
            "Epoch 489/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 1.4279e-06 - mean_absolute_error: 8.1463e-04 - val_loss: 4.7765e-06 - val_mean_absolute_error: 0.0018 - 143ms/epoch - 6ms/step\n",
            "Epoch 490/500\n",
            " Train time0:01:21-25/25 - 0s - loss: 1.7453e-06 - mean_absolute_error: 0.0010 - val_loss: 8.4422e-07 - val_mean_absolute_error: 7.0980e-04 - 154ms/epoch - 6ms/step\n",
            "Epoch 491/500\n",
            " Train time0:01:22-25/25 - 0s - loss: 9.4032e-07 - mean_absolute_error: 7.4265e-04 - val_loss: 1.6889e-06 - val_mean_absolute_error: 0.0011 - 144ms/epoch - 6ms/step\n",
            "Epoch 492/500\n",
            " Train time0:01:22-25/25 - 0s - loss: 1.5318e-06 - mean_absolute_error: 9.3395e-04 - val_loss: 4.6316e-07 - val_mean_absolute_error: 5.2966e-04 - 141ms/epoch - 6ms/step\n",
            "Epoch 493/500\n",
            " Train time0:01:22-25/25 - 0s - loss: 1.2074e-06 - mean_absolute_error: 8.0450e-04 - val_loss: 6.3619e-06 - val_mean_absolute_error: 0.0023 - 145ms/epoch - 6ms/step\n",
            "Epoch 494/500\n",
            " Train time0:01:22-25/25 - 0s - loss: 3.4723e-06 - mean_absolute_error: 0.0015 - val_loss: 1.7709e-06 - val_mean_absolute_error: 0.0011 - 143ms/epoch - 6ms/step\n",
            "Epoch 495/500\n",
            " Train time0:01:22-25/25 - 0s - loss: 8.1327e-07 - mean_absolute_error: 6.2875e-04 - val_loss: 4.5476e-07 - val_mean_absolute_error: 5.4256e-04 - 145ms/epoch - 6ms/step\n",
            "Epoch 496/500\n",
            " Train time0:01:22**best**-25/25 - 0s - loss: 4.3272e-07 - mean_absolute_error: 4.9695e-04 - val_loss: 2.1296e-07 - val_mean_absolute_error: 3.6161e-04 - 181ms/epoch - 7ms/step\n",
            "Epoch 497/500\n",
            " Train time0:01:23-25/25 - 0s - loss: 1.1414e-06 - mean_absolute_error: 7.7203e-04 - val_loss: 2.5667e-07 - val_mean_absolute_error: 3.9465e-04 - 142ms/epoch - 6ms/step\n",
            "Epoch 498/500\n",
            " Train time0:01:23-25/25 - 0s - loss: 1.2252e-06 - mean_absolute_error: 8.0979e-04 - val_loss: 8.9411e-07 - val_mean_absolute_error: 7.7009e-04 - 146ms/epoch - 6ms/step\n",
            "Epoch 499/500\n",
            " Train time0:01:23-25/25 - 0s - loss: 5.0541e-07 - mean_absolute_error: 5.3036e-04 - val_loss: 4.9626e-07 - val_mean_absolute_error: 5.7414e-04 - 143ms/epoch - 6ms/step\n",
            "Epoch 500/500\n",
            " Train time0:01:23-25/25 - 0s - loss: 5.5391e-07 - mean_absolute_error: 5.5453e-04 - val_loss: 4.9491e-07 - val_mean_absolute_error: 5.7118e-04 - 146ms/epoch - 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_ex6.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtUJXDqrvqMf",
        "outputId": "e2911abf-94c8-41b2-d8d7-b2f896d84a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training and validation loss values\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot( hist_ex6.history['loss'])\n",
        "plt.plot( hist_ex6.history['val_loss'])\n",
        "plt.title('Model loss mean squared error')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train','val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "U9k72QzYv6L5",
        "outputId": "29842d6b-c949-464b-cd7d-148b4f9bd532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training and validation loss values\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot( hist_ex6.history['mean_absolute_error'])\n",
        "plt.plot( hist_ex6.history['val_mean_absolute_error'])\n",
        "plt.title('Model evaluate : MAE')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train','val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KPfFLhAfv6Tu",
        "outputId": "05344dfc-3833-4202-d1dd-eb24b72fee31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4 Evaluation"
      ],
      "metadata": {
        "id": "-o-A5qbj933z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In actual inferencing, the unified model of **seq2seq_model** is no use but **encoder_model** and ***decoder_model*** are bot applied for autoregressive decoding. Hence, the actual model evaluation should be done in the autoregressive manner like in Inference section"
      ],
      "metadata": {
        "id": "_La7HBt6wffi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the best epoch (minimum val_loss)\n",
        "bestmodel_file = max([ f for f in os.listdir(\".\") if f.startswith('RNN_ex6_bestmodel_') and f.endswith(\".hdf5\")])\n",
        "print( f\"The best model : {bestmodel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14d7c23-3828-42e3-e13e-d06e666b6d5b",
        "id": "bv3qfx1uxTOe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model : RNN_ex6_bestmodel_epoch496.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex6_rnn_best = tf.keras.models.load_model(bestmodel_file, compile=True )"
      ],
      "metadata": {
        "id": "hV_--YT1xTOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from last epoch\n",
        "score = seq2seq_model.evaluate([encoder_x_test_norm, decoder_x_test_norm], decoder_y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):  \n",
        "  print(f\"Test results (model from the last epoch) :{[(seq2seq_model.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the last epoch) :{[(seq2seq_model.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22c9551-1e36-4983-cf13-48c96f9a20c9",
        "id": "zz3iPivcxTOf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the last epoch) :[('loss', 4.556383714771073e-07), ('mean_absolute_error', 0.000543230795301497)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model from best epoch\n",
        "score = ex6_rnn_best.evaluate([encoder_x_test_norm, decoder_x_test_norm], decoder_y_test_norm, verbose=0)\n",
        "if hasattr(score,'__len__'):\n",
        "  print(f\"Test results (model from the best epoch) :{[(ex6_rnn_best.metrics_names[i],score[i]) for i in range(len(score))]}\")\n",
        "else :\n",
        "   print(f\"Test results (model from the best epoch) :{[(ex6_rnn_best.metrics_names[0],score)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09337cff-024a-4bd1-c3a4-8505f0b9dbd1",
        "id": "EaouL9zgxTOf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results (model from the best epoch) :[('loss', 2.2060039839288947e-07), ('mean_absolute_error', 0.0003713608894031495)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.5 Inference"
      ],
      "metadata": {
        "id": "mx6PTW47LEps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the best encoder and decoder model"
      ],
      "metadata": {
        "id": "PA1tJdVPykIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the encoder and decoder models corresponding to best epoch (minimum val_loss)\n",
        "best_encoder = tf.keras.models.load_model(f\"RNN_ex6_bestencoder.hdf5\", compile=False)\n",
        "best_decoder = tf.keras.models.load_model(f\"RNN_ex6_bestdecoder.hdf5\", compile=False)"
      ],
      "metadata": {
        "id": "vpWV796zzPHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a fuction for autoregressive decoding"
      ],
      "metadata": {
        "id": "oB2CNyM7ylFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def autoregressive_decode( encoder_inf, decoder_inf, input_seq, n_step_out, n_out_feature=1, start_token=0):\n",
        "  \"\"\"\n",
        "  Input arguments:\n",
        "    endcoder_inf (model) : the encoder model to be used during inferencing\n",
        "    decoder_inf (model)  : the decoder model to be used during inferencing\n",
        "    input_seq (a sequence of numbers) : an input sequence (input_dim=1) for the model to predit the next numbers\n",
        "    n_step_out (int) : for how the number of features for one output (in our example)\n",
        "    n_out_feature (int) : the number of feature for one output (in out example, it is 1)\n",
        "  \"\"\"\n",
        "  # Encode\n",
        "  state = encoder_inf.predict(input_seq)\n",
        "\n",
        "  # Create the first input of the decoder (= the start token)\n",
        "  target_seq = np.zeros(n_out_feature).reshape(1, 1, n_out_feature)\n",
        "  target_seq[0, 0, :] = start_token\n",
        "\n",
        "  # Collect prediction from autoregressive decoding\n",
        "  output = []\n",
        "  for i in range(n_step_out):\n",
        "    # Predict the next number\n",
        "    y_pred, state = decoder_inf.predict( [target_seq, state] )\n",
        "\n",
        "    # Store prediction\n",
        "    output.append( y_pred[0, 0, :] )\n",
        "\n",
        "    # Update target sequence\n",
        "    target_seq =y_pred\n",
        "\n",
        "  return np.array( output )\n"
      ],
      "metadata": {
        "id": "TJKIQAN11iQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use auoregression decoding"
      ],
      "metadata": {
        "id": "_aQInTKhyliU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the models on the train set"
      ],
      "metadata": {
        "id": "kf5QVMnE_DdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10 # evaluate the first n data of train set\n",
        "mae_loss_norm = 0.0\n",
        "mae_loss = 0.0\n",
        "n_step_out = n_output_timesteps #Here we use the same timesteps as in decoder_y for easy loss evaluation\n",
        "\n",
        "for i in range(n):\n",
        "  ypred_norm = autoregressive_decode( best_encoder, best_decoder, \n",
        "                                     np.expand_dims( encoder_x_train_norm[i], axis=0),\n",
        "                                     n_step_out,\n",
        "                                     1,\n",
        "                                     start_token)\n",
        "  ypred = minmax_norm.inverse_transform(ypred_norm)\n",
        "  \n",
        "  mae_loss_norm += np.absolute(ypred_norm - decoder_y_train_norm[i]).sum(axis=None)\n",
        "  mae_loss += np.absolute( ypred - decoder_y_train[i] ).sum(axis=None)\n",
        "\n",
        "  print(f\"encoder_x_train[{i}] => {encoder_x_train[i]}, decoder_y_train[{i}] => {decoder_y_train[i]}, predict = {np.around(ypred.reshape(-1))}\")\n",
        "\n",
        "mae_loss_norm /= ( n * n_step_out )\n",
        "mae_loss /= ( n * n_step_out )\n",
        "print(f\"Total loss (Mean absolate Error) per one sample of Normalized train data = {mae_loss_norm}\")\n",
        "print(f\"Total loss (Mean absolate Error) per one sample of Unnormalized train data = {mae_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SMmbRr2zBR7",
        "outputId": "359a007e-ad44-4998-8876-2bf87d3fc185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_x_train[0] => [-3033 -3031 -3029 -3027 -3025], decoder_y_train[0] => [-3023 -3021 -3019], predict = [-3023. -3021. -3019.]\n",
            "encoder_x_train[1] => [-3372 -3370 -3368 -3366 -3364], decoder_y_train[1] => [-3362 -3360 -3358], predict = [-3361. -3359. -3357.]\n",
            "encoder_x_train[2] => [-3423 -3421 -3419 -3417 -3415], decoder_y_train[2] => [-3413 -3411 -3409], predict = [-3413. -3410. -3408.]\n",
            "encoder_x_train[3] => [-3911 -3909 -3907 -3905 -3903], decoder_y_train[3] => [-3901 -3899 -3897], predict = [-3901. -3900. -3898.]\n",
            "encoder_x_train[4] => [-2829 -2827 -2825 -2823 -2821], decoder_y_train[4] => [-2819 -2817 -2815], predict = [-2818. -2817. -2815.]\n",
            "encoder_x_train[5] => [-3464 -3462 -3460 -3458 -3456], decoder_y_train[5] => [-3454 -3452 -3450], predict = [-3453. -3451. -3449.]\n",
            "encoder_x_train[6] => [-2288 -2286 -2284 -2282 -2280], decoder_y_train[6] => [-2278 -2276 -2274], predict = [-2277. -2275. -2273.]\n",
            "encoder_x_train[7] => [-3808 -3806 -3804 -3802 -3800], decoder_y_train[7] => [-3798 -3796 -3794], predict = [-3798. -3796. -3795.]\n",
            "encoder_x_train[8] => [-2013 -2011 -2009 -2007 -2005], decoder_y_train[8] => [-2003 -2001 -1999], predict = [-2005. -2003. -2002.]\n",
            "encoder_x_train[9] => [-2036 -2034 -2032 -2030 -2028], decoder_y_train[9] => [-2026 -2024 -2022], predict = [-2028. -2026. -2025.]\n",
            "Total loss (Mean absolate Error) per one sample of Normalized train data = 0.00047794505953788755\n",
            "Total loss (Mean absolate Error) per one sample of Unnormalized train data = 6.135567220052083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the models on the test set"
      ],
      "metadata": {
        "id": "YfLZ2uIM_Exy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10 # evaluate the first n data of train set\n",
        "mae_loss_norm = 0.0\n",
        "mae_loss = 0.0\n",
        "n_step_out = n_output_timesteps #Here we use the same timesteps as in decoder_y for easy loss evaluation\n",
        "\n",
        "for i in range(n):\n",
        "  ypred_norm = autoregressive_decode( best_encoder, best_decoder, \n",
        "                                     np.expand_dims( encoder_x_test_norm[i], axis=0),\n",
        "                                     n_step_out,\n",
        "                                     1,\n",
        "                                     start_token)\n",
        "  ypred = minmax_norm.inverse_transform(ypred_norm)\n",
        "  \n",
        "  mae_loss_norm += np.absolute(ypred_norm - decoder_y_test_norm[i]).sum(axis=None)\n",
        "  mae_loss += np.absolute( ypred - decoder_y_test[i] ).sum(axis=None)\n",
        "\n",
        "  print(f\"encoder_x_test[{i}] => {encoder_x_test[i]}, decoder_y_test[{i}] => {decoder_y_test[i]}, predict = {np.around(ypred.reshape(-1))}\")\n",
        "\n",
        "mae_loss_norm /= ( n * n_step_out )\n",
        "mae_loss /= ( n * n_step_out )\n",
        "print(f\"Total loss (Mean absolate Error) per one sample of Normalized test data = {mae_loss_norm}\")\n",
        "print(f\"Total loss (Mean absolate Error) per one sample of Unnormalized test data = {mae_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Up2KIuf9rgv",
        "outputId": "f6e0480c-b3a6-49c4-a830-7bda850c550a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_x_test[0] => [-2126 -2124 -2122 -2120 -2118], decoder_y_test[0] => [-2116 -2114 -2112], predict = [-2116. -2115. -2112.]\n",
            "encoder_x_test[1] => [-3343 -3341 -3339 -3337 -3335], decoder_y_test[1] => [-3333 -3331 -3329], predict = [-3333. -3330. -3328.]\n",
            "encoder_x_test[2] => [-3710 -3708 -3706 -3704 -3702], decoder_y_test[2] => [-3700 -3698 -3696], predict = [-3700. -3698. -3696.]\n",
            "encoder_x_test[3] => [-3995 -3993 -3991 -3989 -3987], decoder_y_test[3] => [-3985 -3983 -3981], predict = [-3985. -3984. -3983.]\n",
            "encoder_x_test[4] => [-2885 -2883 -2881 -2879 -2877], decoder_y_test[4] => [-2875 -2873 -2871], predict = [-2875. -2874. -2872.]\n",
            "encoder_x_test[5] => [-2148 -2146 -2144 -2142 -2140], decoder_y_test[5] => [-2138 -2136 -2134], predict = [-2137. -2136. -2134.]\n",
            "encoder_x_test[6] => [-3022 -3020 -3018 -3016 -3014], decoder_y_test[6] => [-3012 -3010 -3008], predict = [-3012. -3010. -3009.]\n",
            "encoder_x_test[7] => [-2034 -2032 -2030 -2028 -2026], decoder_y_test[7] => [-2024 -2022 -2020], predict = [-2026. -2024. -2023.]\n",
            "encoder_x_test[8] => [-3707 -3705 -3703 -3701 -3699], decoder_y_test[8] => [-3697 -3695 -3693], predict = [-3697. -3695. -3693.]\n",
            "encoder_x_test[9] => [-3232 -3230 -3228 -3226 -3224], decoder_y_test[9] => [-3222 -3220 -3218], predict = [-3221. -3219. -3217.]\n",
            "Total loss (Mean absolate Error) per one sample of Normalized test data = 0.00031810950798292955\n",
            "Total loss (Mean absolate Error) per one sample of Unnormalized test data = 5.68348388671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kU3mxatB_nnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}